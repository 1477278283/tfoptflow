{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PWC-Net-small model pre-training (with cyclical learning rate schedule)\n",
    "==========================================================\n",
    "\n",
    "In this notebook we:\n",
    "- Use a small model (no dense or residual connections), 6 level pyramid, uspample level 1 by 2 as the final flow prediction\n",
    "- Pre-train the PWC-Net-small model on the `FlyingChairs` dataset using a Cyclic<sub>long</sub> schedule of our own\n",
    "- **ABANDONED** Finetune the pre-trained PWC-Net-small model on the `FlyingThings3D` using the Cyclic<sub>fine</sub> schedule\n",
    "\n",
    "The third step below was skipped after observing that uspampling level 1 by 2 instead of uspampling level 2 by 4 doesn't lead to a reduction in EPE while incurring longer training times (batch of 2 instead of 8 due to larger model size) -> dropped.\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[2018a]<a name=\"2018a\"></a> Sun et al. 2018. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume. [[arXiv]](https://arxiv.org/abs/1709.02371) [[web]](http://research.nvidia.com/publication/2018-02_PWC-Net%3A-CNNs-for) [[PyTorch (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/PyTorch) [[Caffe (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/Caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_train.ipynb\n",
    "\n",
    "PWC-Net model training.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Tensorboard:\n",
    "    [win] tensorboard --logdir=E:\\\\repos\\\\tf-optflow\\\\tfoptflow\\\\pwcnet-sm-6-1-cyclic-chairs\n",
    "    [ubu] tensorboard --logdir=/media/EDrive/repos/tf-optflow/tfoptflow/pwcnet-sm-6-1-cyclic-chairs\n",
    "then,    \n",
    "    [win] tensorboard --logdir=E:\\\\repos\\\\tf-optflow\\\\tfoptflow\\\\pwcnet-sm-6-1-cyclic-chairs-things\n",
    "    [ubu] tensorboard --logdir=/media/EDrive/repos/tf-optflow/tfoptflow/pwcnet-sm-6-1-cyclic-chairs-things\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "from dataset import FlyingChairsDataset, _DEFAULT_DS_TRAIN_OPTIONS, FlyingThings3DDataset, _DEFAULT_DS_TUNE_OPTIONS\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_TRAIN_OPTIONS, _DEFAULT_PWCNET_FINETUNE_OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    _DATASET_ROOT = 'E:/datasets/'\n",
    "    _FLYINGTHINGS3D_ROOT = '//naspro/devt/Datasets/FlyingThings3D'\n",
    "else:\n",
    "    _DATASET_ROOT = '/media/EDrive/datasets/'\n",
    "    _FLYINGTHINGS3D_ROOT = '/media/YDrive/datasets/FlyingThings3D'\n",
    "_FLYINGCHAIRS_ROOT = _DATASET_ROOT + 'FlyingChairs_release'\n",
    "    \n",
    "# TODO: You MUST adjust the settings below based on the number of GPU(s) used for training\n",
    "# Set controller device and devices\n",
    "# A one-gpu setup would be something like controller='/device:GPU:0' and gpu_devices=['/device:GPU:0']\n",
    "# Here, we use a dual-GPU setup, as shown below\n",
    "gpu_devices = ['/device:GPU:0', '/device:GPU:1']\n",
    "controller = '/device:CPU:0'\n",
    "\n",
    "# TODO: You MUST adjust this setting below based on the amount of memory on your GPU(s)\n",
    "# Batch size\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train on `FlyingChairs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set the batch size based on the capabilities of your GPU(s) \n",
    "#  Load train dataset\n",
    "ds_opts = deepcopy(_DEFAULT_DS_TRAIN_OPTIONS)\n",
    "ds_opts['in_memory'] = False                          # Too many samples to keep in memory at once, so don't preload them\n",
    "ds_opts['aug_type'] = 'heavy'                         # Apply all supported augmentations\n",
    "ds_opts['batch_size'] = batch_size * len(gpu_devices) # Multiply by number of GPUs (Titan X & 1080 Ti)\n",
    "ds_opts['crop_preproc'] = (384, 448)                  # Crop to a smaller input size\n",
    "ds = FlyingChairsDataset(mode='train_with_val', ds_root=_FLYINGCHAIRS_ROOT, options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration:\n",
      "  verbose              False\n",
      "  in_memory            False\n",
      "  crop_preproc         (384, 448)\n",
      "  scale_preproc        None\n",
      "  input_channels       3\n",
      "  tb_test_imgs         False\n",
      "  random_seed          1969\n",
      "  val_split            0.03\n",
      "  aug_type             heavy\n",
      "  aug_labels           True\n",
      "  fliplr               0.5\n",
      "  flipud               0.5\n",
      "  translate            (0.5, 0.05)\n",
      "  scale                (0.5, 0.05)\n",
      "  batch_size           4\n",
      "  mode                 train_with_val\n",
      "  train size           22232\n",
      "  val size             640\n"
     ]
    }
   ],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_TRAIN_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_dir'] = './pwcnet-sm-6-1-cyclic-chairs/'\n",
    "nn_opts['batch_size'] = ds_opts['batch_size']\n",
    "nn_opts['x_shape'] = [2, ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 3]\n",
    "nn_opts['y_shape'] = [ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 2]\n",
    "nn_opts['use_tf_data'] = True # Use tf.data reader\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# Use the PWC-Net-small model in high-res mode\n",
    "nn_opts['use_dense_cx'] = False\n",
    "nn_opts['use_res_cx'] = False\n",
    "nn_opts['flow_pred_lvl'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate schedule. This schedule is for a single GPU using a batch size of 8.\n",
    "nn_opts['lr_policy'] = 'cyclic'\n",
    "nn_opts['cyclic_lr_max'] = 4e-04\n",
    "nn_opts['cyclic_lr_base'] = 1e-05\n",
    "nn_opts['cyclic_lr_stepsize'] = 10000\n",
    "nn_opts['max_steps'] = 100000\n",
    "\n",
    "# Below, we adjust the schedule to the size of the batch and our number of GPUs (2).\n",
    "nn_opts['cyclic_lr_stepsize'] /= len(gpu_devices)\n",
    "nn_opts['max_steps'] /= len(gpu_devices)\n",
    "nn_opts['cyclic_lr_stepsize'] = int(nn_opts['cyclic_lr_stepsize'] / (float(ds_opts['batch_size']) / 8))\n",
    "nn_opts['max_steps'] = int(nn_opts['max_steps'] / (float(ds_opts['batch_size']) / 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model towers...\n",
      "  Building tower_0...\n",
      "WARNING:tensorflow:From e:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "  ...tower_0 built.\n",
      "  Building tower_1...\n",
      "  ...tower_1 built.\n",
      "... model towers built.\n",
      "Initializing model with random values for initial training...\n",
      "\n",
      "... model initialized\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_dir               ./pwcnet-sm-6-1-cyclic-chairs/\n",
      "  max_to_keep            10\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, 384, 448, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [384, 448, 2]\n",
      "  train_mode             train\n",
      "  display_step           100\n",
      "  snapshot_step          1000\n",
      "  val_step               1000\n",
      "  val_batch_size         -1\n",
      "  tb_val_imgs            pyramid\n",
      "  tb_test_imgs           None\n",
      "  gpu_devices            ['/device:GPU:0', '/device:GPU:1']\n",
      "  controller             /device:CPU:0\n",
      "  use_tf_data            True\n",
      "  batch_size             4\n",
      "  lr_policy              cyclic\n",
      "  max_steps              100000\n",
      "  cyclic_lr_max          0.0004\n",
      "  cyclic_lr_base         1e-05\n",
      "  cyclic_lr_stepsize     10000\n",
      "  loss_fn                loss_multiscale\n",
      "  alphas                 [0.32, 0.08, 0.02, 0.01, 0.005, 0.0025]\n",
      "  gamma                  0.0004\n",
      "  q                      1.0\n",
      "  epsilon                0.0\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          1\n",
      "  search_range           4\n",
      "  use_dense_cx           False\n",
      "  use_res_cx             False\n",
      "  mode                   train_with_val\n",
      "  trainable params       5155310\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and display the model configuration\n",
    "nn = ModelPWCNet(mode='train_with_val', options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training from scratch...\n",
      "2018-09-06 13:33:45 Iter 100 [Train]: loss=1141.15, epe=15.81, lr=0.000014, samples/sec=5.6, sec/step=1.418, eta=1 day, 15:20:17\n",
      "2018-09-06 13:34:51 Iter 200 [Train]: loss=1140.38, epe=15.80, lr=0.000018, samples/sec=13.0, sec/step=0.616, eta=17:04:56\n",
      "2018-09-06 13:35:57 Iter 300 [Train]: loss=1123.94, epe=15.58, lr=0.000022, samples/sec=12.7, sec/step=0.629, eta=17:24:32\n",
      "2018-09-06 13:37:02 Iter 400 [Train]: loss=1155.73, epe=16.02, lr=0.000026, samples/sec=13.1, sec/step=0.612, eta=16:56:29\n",
      "2018-09-06 13:38:06 Iter 500 [Train]: loss=1187.41, epe=16.46, lr=0.000029, samples/sec=13.2, sec/step=0.608, eta=16:48:40\n",
      "2018-09-06 13:39:10 Iter 600 [Train]: loss=1118.06, epe=15.50, lr=0.000033, samples/sec=13.1, sec/step=0.609, eta=16:48:37\n",
      "2018-09-06 13:40:15 Iter 700 [Train]: loss=1132.66, epe=15.69, lr=0.000037, samples/sec=13.2, sec/step=0.608, eta=16:46:50\n",
      "2018-09-06 13:41:19 Iter 800 [Train]: loss=1147.07, epe=15.85, lr=0.000041, samples/sec=13.2, sec/step=0.607, eta=16:44:10\n",
      "2018-09-06 13:42:23 Iter 900 [Train]: loss=1089.49, epe=14.98, lr=0.000045, samples/sec=13.1, sec/step=0.609, eta=16:46:28\n",
      "2018-09-06 13:43:28 Iter 1000 [Train]: loss=1053.69, epe=14.43, lr=0.000049, samples/sec=13.1, sec/step=0.609, eta=16:45:01\n",
      "2018-09-06 13:43:55 Iter 1000 1000 [Val]: loss=811.67, epe=11.15\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-1000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-1000\n",
      "2018-09-06 13:45:11 Iter 1100 [Train]: loss=1159.02, epe=15.84, lr=0.000053, samples/sec=13.3, sec/step=0.603, eta=16:33:43\n",
      "2018-09-06 13:46:15 Iter 1200 [Train]: loss=1049.32, epe=14.27, lr=0.000057, samples/sec=13.1, sec/step=0.609, eta=16:42:35\n",
      "2018-09-06 13:47:19 Iter 1300 [Train]: loss=1106.36, epe=14.99, lr=0.000061, samples/sec=13.1, sec/step=0.608, eta=16:40:51\n",
      "2018-09-06 13:48:24 Iter 1400 [Train]: loss=1060.43, epe=14.30, lr=0.000065, samples/sec=13.2, sec/step=0.607, eta=16:38:05\n",
      "2018-09-06 13:49:28 Iter 1500 [Train]: loss=1060.58, epe=14.24, lr=0.000068, samples/sec=13.2, sec/step=0.606, eta=16:34:52\n",
      "2018-09-06 13:50:32 Iter 1600 [Train]: loss=986.57, epe=13.20, lr=0.000072, samples/sec=13.2, sec/step=0.606, eta=16:34:10\n",
      "2018-09-06 13:51:36 Iter 1700 [Train]: loss=1079.23, epe=14.44, lr=0.000076, samples/sec=13.2, sec/step=0.606, eta=16:32:35\n",
      "2018-09-06 13:52:40 Iter 1800 [Train]: loss=1056.74, epe=14.05, lr=0.000080, samples/sec=13.2, sec/step=0.606, eta=16:31:48\n",
      "2018-09-06 13:53:44 Iter 1900 [Train]: loss=1036.44, epe=13.82, lr=0.000084, samples/sec=13.2, sec/step=0.606, eta=16:31:00\n",
      "2018-09-06 13:54:48 Iter 2000 [Train]: loss=996.00, epe=13.22, lr=0.000088, samples/sec=13.2, sec/step=0.605, eta=16:28:05\n",
      "2018-09-06 13:55:08 Iter 2000 2000 [Val]: loss=777.09, epe=10.50\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-2000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-2000\n",
      "2018-09-06 13:56:21 Iter 2100 [Train]: loss=1002.43, epe=13.29, lr=0.000092, samples/sec=13.3, sec/step=0.604, eta=16:24:58\n",
      "2018-09-06 13:57:25 Iter 2200 [Train]: loss=972.01, epe=12.89, lr=0.000096, samples/sec=13.2, sec/step=0.607, eta=16:29:13\n",
      "2018-09-06 13:58:29 Iter 2300 [Train]: loss=1012.81, epe=13.42, lr=0.000100, samples/sec=13.1, sec/step=0.609, eta=16:31:04\n",
      "2018-09-06 13:59:33 Iter 2400 [Train]: loss=986.94, epe=12.99, lr=0.000104, samples/sec=13.2, sec/step=0.608, eta=16:29:27\n",
      "2018-09-06 14:00:37 Iter 2500 [Train]: loss=966.09, epe=12.69, lr=0.000108, samples/sec=13.2, sec/step=0.608, eta=16:27:17\n",
      "2018-09-06 14:01:42 Iter 2600 [Train]: loss=992.42, epe=12.98, lr=0.000111, samples/sec=13.1, sec/step=0.609, eta=16:28:41\n",
      "2018-09-06 14:02:46 Iter 2700 [Train]: loss=957.86, epe=12.53, lr=0.000115, samples/sec=13.2, sec/step=0.606, eta=16:22:03\n",
      "2018-09-06 14:03:50 Iter 2800 [Train]: loss=982.17, epe=12.75, lr=0.000119, samples/sec=13.2, sec/step=0.608, eta=16:24:22\n",
      "2018-09-06 14:04:54 Iter 2900 [Train]: loss=926.80, epe=12.02, lr=0.000123, samples/sec=13.1, sec/step=0.611, eta=16:28:19\n",
      "2018-09-06 14:05:58 Iter 3000 [Train]: loss=919.94, epe=11.97, lr=0.000127, samples/sec=13.2, sec/step=0.608, eta=16:22:33\n",
      "2018-09-06 14:06:19 Iter 3000 3000 [Val]: loss=734.36, epe=9.74\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-3000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-3000\n",
      "2018-09-06 14:07:31 Iter 3100 [Train]: loss=928.40, epe=12.01, lr=0.000131, samples/sec=13.2, sec/step=0.605, eta=16:17:11\n",
      "2018-09-06 14:08:36 Iter 3200 [Train]: loss=943.19, epe=12.16, lr=0.000135, samples/sec=13.1, sec/step=0.609, eta=16:21:46\n",
      "2018-09-06 14:09:40 Iter 3300 [Train]: loss=943.59, epe=12.23, lr=0.000139, samples/sec=13.1, sec/step=0.609, eta=16:20:43\n",
      "2018-09-06 14:10:44 Iter 3400 [Train]: loss=967.89, epe=12.48, lr=0.000143, samples/sec=13.2, sec/step=0.608, eta=16:18:22\n",
      "2018-09-06 14:11:48 Iter 3500 [Train]: loss=928.30, epe=11.85, lr=0.000147, samples/sec=13.1, sec/step=0.608, eta=16:18:29\n",
      "2018-09-06 14:12:52 Iter 3600 [Train]: loss=906.68, epe=11.57, lr=0.000150, samples/sec=13.1, sec/step=0.608, eta=16:17:35\n",
      "2018-09-06 14:13:56 Iter 3700 [Train]: loss=916.99, epe=11.71, lr=0.000154, samples/sec=13.2, sec/step=0.608, eta=16:15:32\n",
      "2018-09-06 14:15:01 Iter 3800 [Train]: loss=926.59, epe=11.90, lr=0.000158, samples/sec=13.1, sec/step=0.610, eta=16:17:23\n",
      "2018-09-06 14:16:05 Iter 3900 [Train]: loss=946.47, epe=12.05, lr=0.000162, samples/sec=13.1, sec/step=0.609, eta=16:14:38\n",
      "2018-09-06 14:17:09 Iter 4000 [Train]: loss=876.32, epe=11.15, lr=0.000166, samples/sec=13.2, sec/step=0.607, eta=16:11:45\n",
      "2018-09-06 14:17:30 Iter 4000 4000 [Val]: loss=705.84, epe=9.23\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-4000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-4000\n",
      "2018-09-06 14:18:43 Iter 4100 [Train]: loss=889.53, epe=11.24, lr=0.000170, samples/sec=13.2, sec/step=0.605, eta=16:07:30\n",
      "2018-09-06 14:19:47 Iter 4200 [Train]: loss=875.60, epe=11.01, lr=0.000174, samples/sec=13.2, sec/step=0.606, eta=16:07:11\n",
      "2018-09-06 14:20:51 Iter 4300 [Train]: loss=894.40, epe=11.28, lr=0.000178, samples/sec=13.2, sec/step=0.607, eta=16:07:46\n",
      "2018-09-06 14:21:56 Iter 4400 [Train]: loss=893.50, epe=11.25, lr=0.000182, samples/sec=13.2, sec/step=0.608, eta=16:09:04\n",
      "2018-09-06 14:23:00 Iter 4500 [Train]: loss=910.42, epe=11.49, lr=0.000186, samples/sec=13.0, sec/step=0.614, eta=16:16:53\n",
      "2018-09-06 14:24:05 Iter 4600 [Train]: loss=852.43, epe=10.68, lr=0.000189, samples/sec=13.1, sec/step=0.609, eta=16:08:22\n",
      "2018-09-06 14:25:09 Iter 4700 [Train]: loss=928.00, epe=11.75, lr=0.000193, samples/sec=13.1, sec/step=0.610, eta=16:08:42\n",
      "2018-09-06 14:26:13 Iter 4800 [Train]: loss=866.34, epe=10.74, lr=0.000197, samples/sec=13.1, sec/step=0.611, eta=16:09:19\n",
      "2018-09-06 14:27:18 Iter 4900 [Train]: loss=850.87, epe=10.65, lr=0.000201, samples/sec=13.0, sec/step=0.613, eta=16:11:46\n",
      "2018-09-06 14:28:22 Iter 5000 [Train]: loss=916.40, epe=11.49, lr=0.000205, samples/sec=13.1, sec/step=0.611, eta=16:06:42\n",
      "2018-09-06 14:28:43 Iter 5000 5000 [Val]: loss=727.48, epe=9.66\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-5000\n",
      "2018-09-06 14:29:56 Iter 5100 [Train]: loss=909.59, epe=11.53, lr=0.000209, samples/sec=13.2, sec/step=0.605, eta=15:56:54\n",
      "2018-09-06 14:31:00 Iter 5200 [Train]: loss=862.64, epe=10.82, lr=0.000213, samples/sec=13.2, sec/step=0.606, eta=15:57:23\n",
      "2018-09-06 14:32:04 Iter 5300 [Train]: loss=879.10, epe=10.97, lr=0.000217, samples/sec=13.2, sec/step=0.607, eta=15:57:47\n",
      "2018-09-06 14:33:08 Iter 5400 [Train]: loss=841.74, epe=10.59, lr=0.000221, samples/sec=13.1, sec/step=0.609, eta=15:59:37\n",
      "2018-09-06 14:34:12 Iter 5500 [Train]: loss=839.69, epe=10.48, lr=0.000224, samples/sec=13.1, sec/step=0.609, eta=15:58:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 14:35:16 Iter 5600 [Train]: loss=864.13, epe=10.75, lr=0.000228, samples/sec=13.2, sec/step=0.606, eta=15:53:56\n",
      "2018-09-06 14:36:20 Iter 5700 [Train]: loss=845.25, epe=10.49, lr=0.000232, samples/sec=13.2, sec/step=0.608, eta=15:55:00\n",
      "2018-09-06 14:37:25 Iter 5800 [Train]: loss=824.78, epe=10.31, lr=0.000236, samples/sec=13.2, sec/step=0.607, eta=15:53:29\n",
      "2018-09-06 14:38:29 Iter 5900 [Train]: loss=797.37, epe=10.03, lr=0.000240, samples/sec=13.2, sec/step=0.606, eta=15:51:09\n",
      "2018-09-06 14:39:33 Iter 6000 [Train]: loss=861.58, epe=10.83, lr=0.000244, samples/sec=13.2, sec/step=0.607, eta=15:51:40\n",
      "2018-09-06 14:39:54 Iter 6000 6000 [Val]: loss=654.54, epe=8.43\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-6000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-6000\n",
      "2018-09-06 14:41:06 Iter 6100 [Train]: loss=795.48, epe=9.88, lr=0.000248, samples/sec=13.2, sec/step=0.604, eta=15:45:57\n",
      "2018-09-06 14:42:10 Iter 6200 [Train]: loss=801.91, epe=10.05, lr=0.000252, samples/sec=13.2, sec/step=0.608, eta=15:50:27\n",
      "2018-09-06 14:43:15 Iter 6300 [Train]: loss=832.72, epe=10.47, lr=0.000256, samples/sec=13.2, sec/step=0.608, eta=15:49:54\n",
      "2018-09-06 14:44:19 Iter 6400 [Train]: loss=812.65, epe=10.19, lr=0.000260, samples/sec=13.1, sec/step=0.609, eta=15:49:38\n",
      "2018-09-06 14:45:23 Iter 6500 [Train]: loss=811.57, epe=10.19, lr=0.000263, samples/sec=13.1, sec/step=0.609, eta=15:48:48\n",
      "2018-09-06 14:46:27 Iter 6600 [Train]: loss=822.58, epe=10.29, lr=0.000267, samples/sec=13.2, sec/step=0.608, eta=15:46:54\n",
      "2018-09-06 14:47:31 Iter 6700 [Train]: loss=771.55, epe=9.71, lr=0.000271, samples/sec=13.2, sec/step=0.608, eta=15:44:54\n",
      "2018-09-06 14:48:35 Iter 6800 [Train]: loss=787.80, epe=9.80, lr=0.000275, samples/sec=13.2, sec/step=0.607, eta=15:43:12\n",
      "2018-09-06 14:49:39 Iter 6900 [Train]: loss=785.73, epe=9.80, lr=0.000279, samples/sec=13.2, sec/step=0.607, eta=15:41:30\n",
      "2018-09-06 14:50:43 Iter 7000 [Train]: loss=838.60, epe=10.68, lr=0.000283, samples/sec=13.2, sec/step=0.607, eta=15:41:29\n",
      "2018-09-06 14:51:04 Iter 7000 7000 [Val]: loss=657.67, epe=8.54\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-7000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-7000\n",
      "2018-09-06 14:52:17 Iter 7100 [Train]: loss=777.66, epe=9.64, lr=0.000287, samples/sec=13.2, sec/step=0.605, eta=15:36:31\n",
      "2018-09-06 14:53:21 Iter 7200 [Train]: loss=728.28, epe=9.02, lr=0.000291, samples/sec=13.2, sec/step=0.606, eta=15:37:59\n",
      "2018-09-06 14:54:25 Iter 7300 [Train]: loss=761.27, epe=9.52, lr=0.000295, samples/sec=13.2, sec/step=0.607, eta=15:37:21\n",
      "2018-09-06 14:55:29 Iter 7400 [Train]: loss=725.35, epe=9.03, lr=0.000299, samples/sec=13.2, sec/step=0.606, eta=15:34:56\n",
      "2018-09-06 14:56:34 Iter 7500 [Train]: loss=782.81, epe=9.81, lr=0.000303, samples/sec=13.1, sec/step=0.609, eta=15:39:31\n",
      "2018-09-06 14:57:38 Iter 7600 [Train]: loss=759.78, epe=9.60, lr=0.000306, samples/sec=13.2, sec/step=0.606, eta=15:32:31\n",
      "2018-09-06 14:58:42 Iter 7700 [Train]: loss=775.80, epe=9.73, lr=0.000310, samples/sec=13.1, sec/step=0.608, eta=15:36:00\n",
      "2018-09-06 14:59:46 Iter 7800 [Train]: loss=742.54, epe=9.32, lr=0.000314, samples/sec=13.2, sec/step=0.606, eta=15:31:53\n",
      "2018-09-06 15:00:50 Iter 7900 [Train]: loss=728.48, epe=9.19, lr=0.000318, samples/sec=13.2, sec/step=0.606, eta=15:29:39\n",
      "2018-09-06 15:01:54 Iter 8000 [Train]: loss=744.57, epe=9.34, lr=0.000322, samples/sec=13.2, sec/step=0.605, eta=15:28:20\n",
      "2018-09-06 15:02:15 Iter 8000 8000 [Val]: loss=608.84, epe=7.90\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-8000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-8000\n",
      "2018-09-06 15:03:27 Iter 8100 [Train]: loss=736.28, epe=9.28, lr=0.000326, samples/sec=13.3, sec/step=0.603, eta=15:24:14\n",
      "2018-09-06 15:04:31 Iter 8200 [Train]: loss=736.29, epe=9.31, lr=0.000330, samples/sec=13.2, sec/step=0.607, eta=15:28:32\n",
      "2018-09-06 15:05:35 Iter 8300 [Train]: loss=667.47, epe=8.48, lr=0.000334, samples/sec=13.2, sec/step=0.607, eta=15:27:36\n",
      "2018-09-06 15:06:39 Iter 8400 [Train]: loss=697.59, epe=8.86, lr=0.000338, samples/sec=13.2, sec/step=0.607, eta=15:26:41\n",
      "2018-09-06 15:07:44 Iter 8500 [Train]: loss=682.68, epe=8.79, lr=0.000341, samples/sec=13.2, sec/step=0.606, eta=15:24:47\n",
      "2018-09-06 15:08:48 Iter 8600 [Train]: loss=685.08, epe=8.73, lr=0.000345, samples/sec=13.1, sec/step=0.608, eta=15:26:53\n",
      "2018-09-06 15:09:52 Iter 8700 [Train]: loss=665.37, epe=8.53, lr=0.000349, samples/sec=13.2, sec/step=0.608, eta=15:25:12\n",
      "2018-09-06 15:10:56 Iter 8800 [Train]: loss=732.28, epe=9.45, lr=0.000353, samples/sec=13.2, sec/step=0.607, eta=15:22:08\n",
      "2018-09-06 15:12:00 Iter 8900 [Train]: loss=734.54, epe=9.51, lr=0.000357, samples/sec=13.2, sec/step=0.607, eta=15:21:30\n",
      "2018-09-06 15:13:04 Iter 9000 [Train]: loss=656.68, epe=8.46, lr=0.000361, samples/sec=13.2, sec/step=0.608, eta=15:21:24\n",
      "2018-09-06 15:13:25 Iter 9000 9000 [Val]: loss=567.12, epe=7.31\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-9000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-9000\n",
      "2018-09-06 15:14:38 Iter 9100 [Train]: loss=649.15, epe=8.32, lr=0.000365, samples/sec=13.2, sec/step=0.605, eta=15:16:37\n",
      "2018-09-06 15:15:42 Iter 9200 [Train]: loss=658.67, epe=8.51, lr=0.000369, samples/sec=13.2, sec/step=0.608, eta=15:19:32\n",
      "2018-09-06 15:16:46 Iter 9300 [Train]: loss=690.20, epe=8.93, lr=0.000373, samples/sec=13.2, sec/step=0.607, eta=15:17:49\n",
      "2018-09-06 15:17:50 Iter 9400 [Train]: loss=641.67, epe=8.26, lr=0.000377, samples/sec=13.1, sec/step=0.609, eta=15:19:20\n",
      "2018-09-06 15:18:54 Iter 9500 [Train]: loss=631.43, epe=8.18, lr=0.000381, samples/sec=13.2, sec/step=0.608, eta=15:16:23\n",
      "2018-09-06 15:19:58 Iter 9600 [Train]: loss=652.67, epe=8.43, lr=0.000384, samples/sec=13.2, sec/step=0.606, eta=15:12:52\n",
      "2018-09-06 15:21:03 Iter 9700 [Train]: loss=657.74, epe=8.49, lr=0.000388, samples/sec=13.2, sec/step=0.607, eta=15:13:13\n",
      "2018-09-06 15:22:07 Iter 9800 [Train]: loss=655.94, epe=8.45, lr=0.000392, samples/sec=13.2, sec/step=0.606, eta=15:10:27\n",
      "2018-09-06 15:23:11 Iter 9900 [Train]: loss=613.42, epe=7.91, lr=0.000396, samples/sec=13.2, sec/step=0.606, eta=15:10:17\n",
      "2018-09-06 15:24:15 Iter 10000 [Train]: loss=638.87, epe=8.28, lr=0.000400, samples/sec=13.2, sec/step=0.608, eta=15:12:12\n",
      "2018-09-06 15:24:35 Iter 10000 10000 [Val]: loss=519.64, epe=6.81\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-10000\n",
      "2018-09-06 15:25:48 Iter 10100 [Train]: loss=606.04, epe=7.79, lr=0.000396, samples/sec=13.3, sec/step=0.603, eta=15:03:58\n",
      "2018-09-06 15:26:52 Iter 10200 [Train]: loss=605.95, epe=7.81, lr=0.000392, samples/sec=13.2, sec/step=0.607, eta=15:07:55\n",
      "2018-09-06 15:27:57 Iter 10300 [Train]: loss=606.37, epe=7.87, lr=0.000388, samples/sec=13.2, sec/step=0.608, eta=15:08:21\n",
      "2018-09-06 15:29:01 Iter 10400 [Train]: loss=617.27, epe=8.03, lr=0.000384, samples/sec=13.2, sec/step=0.608, eta=15:08:09\n",
      "2018-09-06 15:30:05 Iter 10500 [Train]: loss=605.26, epe=7.86, lr=0.000381, samples/sec=13.2, sec/step=0.606, eta=15:04:39\n",
      "2018-09-06 15:31:09 Iter 10600 [Train]: loss=599.00, epe=7.79, lr=0.000377, samples/sec=13.2, sec/step=0.606, eta=15:03:28\n",
      "2018-09-06 15:32:13 Iter 10700 [Train]: loss=621.39, epe=8.02, lr=0.000373, samples/sec=13.2, sec/step=0.607, eta=15:03:20\n",
      "2018-09-06 15:33:17 Iter 10800 [Train]: loss=605.50, epe=7.86, lr=0.000369, samples/sec=13.2, sec/step=0.607, eta=15:02:07\n",
      "2018-09-06 15:34:21 Iter 10900 [Train]: loss=587.88, epe=7.59, lr=0.000365, samples/sec=13.2, sec/step=0.607, eta=15:01:42\n",
      "2018-09-06 15:35:26 Iter 11000 [Train]: loss=555.25, epe=7.15, lr=0.000361, samples/sec=13.2, sec/step=0.606, eta=14:59:03\n",
      "2018-09-06 15:35:46 Iter 11000 11000 [Val]: loss=517.36, epe=6.76\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-11000 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-11000\n",
      "2018-09-06 15:37:00 Iter 11100 [Train]: loss=578.36, epe=7.49, lr=0.000357, samples/sec=13.2, sec/step=0.605, eta=14:55:48\n",
      "2018-09-06 15:38:04 Iter 11200 [Train]: loss=561.84, epe=7.24, lr=0.000353, samples/sec=13.2, sec/step=0.608, eta=14:59:34\n",
      "2018-09-06 15:39:08 Iter 11300 [Train]: loss=529.67, epe=6.82, lr=0.000349, samples/sec=13.1, sec/step=0.609, eta=14:59:36\n",
      "2018-09-06 15:40:12 Iter 11400 [Train]: loss=556.94, epe=7.16, lr=0.000345, samples/sec=13.1, sec/step=0.610, eta=15:00:02\n",
      "2018-09-06 15:41:17 Iter 11500 [Train]: loss=550.88, epe=7.08, lr=0.000342, samples/sec=13.2, sec/step=0.608, eta=14:57:05\n",
      "2018-09-06 15:42:21 Iter 11600 [Train]: loss=559.79, epe=7.24, lr=0.000338, samples/sec=13.2, sec/step=0.606, eta=14:53:20\n",
      "2018-09-06 15:43:25 Iter 11700 [Train]: loss=561.15, epe=7.25, lr=0.000334, samples/sec=13.2, sec/step=0.606, eta=14:51:14\n",
      "2018-09-06 15:44:29 Iter 11800 [Train]: loss=536.05, epe=6.95, lr=0.000330, samples/sec=13.1, sec/step=0.609, eta=14:54:48\n",
      "2018-09-06 15:45:33 Iter 11900 [Train]: loss=529.15, epe=6.83, lr=0.000326, samples/sec=13.2, sec/step=0.608, eta=14:52:41\n",
      "2018-09-06 15:46:37 Iter 12000 [Train]: loss=561.64, epe=7.19, lr=0.000322, samples/sec=13.2, sec/step=0.607, eta=14:50:59\n",
      "2018-09-06 15:46:58 Iter 12000 12000 [Val]: loss=635.00, epe=8.51\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-12000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-12000\n",
      "2018-09-06 15:48:11 Iter 12100 [Train]: loss=838.20, epe=10.91, lr=0.000318, samples/sec=13.2, sec/step=0.605, eta=14:46:21\n",
      "2018-09-06 15:49:15 Iter 12200 [Train]: loss=678.60, epe=8.71, lr=0.000314, samples/sec=13.2, sec/step=0.608, eta=14:49:23\n",
      "2018-09-06 15:50:19 Iter 12300 [Train]: loss=614.25, epe=7.86, lr=0.000310, samples/sec=13.2, sec/step=0.608, eta=14:48:07\n",
      "2018-09-06 15:51:23 Iter 12400 [Train]: loss=573.06, epe=7.26, lr=0.000306, samples/sec=13.2, sec/step=0.608, eta=14:48:00\n",
      "2018-09-06 15:52:27 Iter 12500 [Train]: loss=572.85, epe=7.32, lr=0.000303, samples/sec=13.1, sec/step=0.609, eta=14:47:42\n",
      "2018-09-06 15:53:32 Iter 12600 [Train]: loss=594.14, epe=7.57, lr=0.000299, samples/sec=13.2, sec/step=0.607, eta=14:44:05\n",
      "2018-09-06 15:54:36 Iter 12700 [Train]: loss=532.03, epe=6.71, lr=0.000295, samples/sec=13.2, sec/step=0.607, eta=14:43:40\n",
      "2018-09-06 15:55:40 Iter 12800 [Train]: loss=532.09, epe=6.76, lr=0.000291, samples/sec=13.2, sec/step=0.604, eta=14:38:18\n",
      "2018-09-06 15:56:44 Iter 12900 [Train]: loss=493.58, epe=6.27, lr=0.000287, samples/sec=13.2, sec/step=0.608, eta=14:41:56\n",
      "2018-09-06 15:57:48 Iter 13000 [Train]: loss=542.43, epe=6.94, lr=0.000283, samples/sec=13.2, sec/step=0.607, eta=14:39:56\n",
      "2018-09-06 15:58:09 Iter 13000 13000 [Val]: loss=462.49, epe=6.00\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-13000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-13000\n",
      "2018-09-06 15:59:22 Iter 13100 [Train]: loss=496.05, epe=6.30, lr=0.000279, samples/sec=13.2, sec/step=0.605, eta=14:35:52\n",
      "2018-09-06 16:00:26 Iter 13200 [Train]: loss=492.31, epe=6.28, lr=0.000275, samples/sec=13.2, sec/step=0.606, eta=14:37:17\n",
      "2018-09-06 16:01:30 Iter 13300 [Train]: loss=497.02, epe=6.32, lr=0.000271, samples/sec=13.2, sec/step=0.607, eta=14:37:29\n",
      "2018-09-06 16:02:34 Iter 13400 [Train]: loss=537.85, epe=6.83, lr=0.000267, samples/sec=13.2, sec/step=0.605, eta=14:33:44\n",
      "2018-09-06 16:03:38 Iter 13500 [Train]: loss=531.29, epe=6.82, lr=0.000263, samples/sec=13.2, sec/step=0.608, eta=14:35:49\n",
      "2018-09-06 16:04:42 Iter 13600 [Train]: loss=499.34, epe=6.34, lr=0.000260, samples/sec=13.2, sec/step=0.608, eta=14:34:57\n",
      "2018-09-06 16:05:46 Iter 13700 [Train]: loss=509.81, epe=6.52, lr=0.000256, samples/sec=13.2, sec/step=0.607, eta=14:32:30\n",
      "2018-09-06 16:06:51 Iter 13800 [Train]: loss=515.55, epe=6.61, lr=0.000252, samples/sec=13.2, sec/step=0.608, eta=14:33:18\n",
      "2018-09-06 16:07:55 Iter 13900 [Train]: loss=498.51, epe=6.36, lr=0.000248, samples/sec=13.2, sec/step=0.608, eta=14:31:56\n",
      "2018-09-06 16:08:59 Iter 14000 [Train]: loss=488.36, epe=6.22, lr=0.000244, samples/sec=13.1, sec/step=0.608, eta=14:32:06\n",
      "2018-09-06 16:09:20 Iter 14000 14000 [Val]: loss=441.97, epe=5.66\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-14000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-14000\n",
      "2018-09-06 16:10:33 Iter 14100 [Train]: loss=481.38, epe=6.13, lr=0.000240, samples/sec=13.2, sec/step=0.605, eta=14:25:43\n",
      "2018-09-06 16:11:37 Iter 14200 [Train]: loss=469.29, epe=5.95, lr=0.000236, samples/sec=13.2, sec/step=0.607, eta=14:28:42\n",
      "2018-09-06 16:12:41 Iter 14300 [Train]: loss=451.21, epe=5.71, lr=0.000232, samples/sec=13.2, sec/step=0.607, eta=14:26:51\n",
      "2018-09-06 16:13:45 Iter 14400 [Train]: loss=465.82, epe=5.88, lr=0.000228, samples/sec=13.2, sec/step=0.607, eta=14:26:28\n",
      "2018-09-06 16:14:49 Iter 14500 [Train]: loss=497.92, epe=6.34, lr=0.000225, samples/sec=13.2, sec/step=0.608, eta=14:26:39\n",
      "2018-09-06 16:15:53 Iter 14600 [Train]: loss=485.71, epe=6.17, lr=0.000221, samples/sec=13.2, sec/step=0.608, eta=14:25:34\n",
      "2018-09-06 16:16:58 Iter 14700 [Train]: loss=464.13, epe=5.89, lr=0.000217, samples/sec=13.1, sec/step=0.609, eta=14:26:02\n",
      "2018-09-06 16:18:02 Iter 14800 [Train]: loss=480.50, epe=6.10, lr=0.000213, samples/sec=13.2, sec/step=0.608, eta=14:23:32\n",
      "2018-09-06 16:19:06 Iter 14900 [Train]: loss=462.53, epe=5.86, lr=0.000209, samples/sec=13.2, sec/step=0.607, eta=14:20:24\n",
      "2018-09-06 16:20:10 Iter 15000 [Train]: loss=485.62, epe=6.17, lr=0.000205, samples/sec=13.2, sec/step=0.608, eta=14:20:53\n",
      "2018-09-06 16:20:31 Iter 15000 15000 [Val]: loss=418.67, epe=5.41\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-15000\n",
      "2018-09-06 16:21:44 Iter 15100 [Train]: loss=458.49, epe=5.83, lr=0.000201, samples/sec=13.2, sec/step=0.606, eta=14:17:17\n",
      "2018-09-06 16:22:48 Iter 15200 [Train]: loss=418.88, epe=5.27, lr=0.000197, samples/sec=13.2, sec/step=0.608, eta=14:18:45\n",
      "2018-09-06 16:23:52 Iter 15300 [Train]: loss=462.53, epe=5.84, lr=0.000193, samples/sec=13.2, sec/step=0.607, eta=14:17:24\n",
      "2018-09-06 16:24:57 Iter 15400 [Train]: loss=447.06, epe=5.64, lr=0.000189, samples/sec=13.1, sec/step=0.609, eta=14:18:42\n",
      "2018-09-06 16:26:01 Iter 15500 [Train]: loss=445.95, epe=5.65, lr=0.000186, samples/sec=13.2, sec/step=0.607, eta=14:15:14\n",
      "2018-09-06 16:27:05 Iter 15600 [Train]: loss=442.45, epe=5.59, lr=0.000182, samples/sec=13.2, sec/step=0.607, eta=14:13:46\n",
      "2018-09-06 16:28:09 Iter 15700 [Train]: loss=463.14, epe=5.89, lr=0.000178, samples/sec=13.2, sec/step=0.607, eta=14:12:27\n",
      "2018-09-06 16:29:14 Iter 15800 [Train]: loss=452.68, epe=5.73, lr=0.000174, samples/sec=13.2, sec/step=0.608, eta=14:12:51\n",
      "2018-09-06 16:30:18 Iter 15900 [Train]: loss=456.80, epe=5.78, lr=0.000170, samples/sec=13.2, sec/step=0.608, eta=14:11:48\n",
      "2018-09-06 16:31:22 Iter 16000 [Train]: loss=447.57, epe=5.67, lr=0.000166, samples/sec=13.1, sec/step=0.609, eta=14:12:11\n",
      "2018-09-06 16:31:43 Iter 16000 16000 [Val]: loss=402.12, epe=5.17\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-16000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-16000\n",
      "2018-09-06 16:32:56 Iter 16100 [Train]: loss=457.07, epe=5.78, lr=0.000162, samples/sec=13.2, sec/step=0.607, eta=14:08:39\n",
      "2018-09-06 16:34:00 Iter 16200 [Train]: loss=429.80, epe=5.41, lr=0.000158, samples/sec=13.2, sec/step=0.607, eta=14:08:05\n",
      "2018-09-06 16:35:04 Iter 16300 [Train]: loss=422.91, epe=5.33, lr=0.000154, samples/sec=13.2, sec/step=0.607, eta=14:06:57\n",
      "2018-09-06 16:36:08 Iter 16400 [Train]: loss=450.32, epe=5.69, lr=0.000150, samples/sec=13.2, sec/step=0.608, eta=14:07:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 16:37:12 Iter 16500 [Train]: loss=456.56, epe=5.79, lr=0.000147, samples/sec=13.2, sec/step=0.606, eta=14:02:56\n",
      "2018-09-06 16:38:16 Iter 16600 [Train]: loss=444.40, epe=5.65, lr=0.000143, samples/sec=13.2, sec/step=0.606, eta=14:02:49\n",
      "2018-09-06 16:39:21 Iter 16700 [Train]: loss=443.72, epe=5.62, lr=0.000139, samples/sec=13.2, sec/step=0.608, eta=14:04:00\n",
      "2018-09-06 16:40:25 Iter 16800 [Train]: loss=423.95, epe=5.34, lr=0.000135, samples/sec=13.2, sec/step=0.608, eta=14:02:55\n",
      "2018-09-06 16:41:29 Iter 16900 [Train]: loss=426.75, epe=5.36, lr=0.000131, samples/sec=13.2, sec/step=0.607, eta=14:00:36\n",
      "2018-09-06 16:42:33 Iter 17000 [Train]: loss=430.72, epe=5.39, lr=0.000127, samples/sec=13.1, sec/step=0.608, eta=14:01:36\n",
      "2018-09-06 16:42:54 Iter 17000 17000 [Val]: loss=384.20, epe=4.92\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-17000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-17000\n",
      "2018-09-06 16:44:07 Iter 17100 [Train]: loss=419.50, epe=5.27, lr=0.000123, samples/sec=13.2, sec/step=0.605, eta=13:55:47\n",
      "2018-09-06 16:45:11 Iter 17200 [Train]: loss=421.26, epe=5.31, lr=0.000119, samples/sec=13.2, sec/step=0.608, eta=13:58:43\n",
      "2018-09-06 16:46:15 Iter 17300 [Train]: loss=417.48, epe=5.26, lr=0.000115, samples/sec=13.2, sec/step=0.607, eta=13:56:55\n",
      "2018-09-06 16:47:20 Iter 17400 [Train]: loss=423.31, epe=5.34, lr=0.000111, samples/sec=13.1, sec/step=0.608, eta=13:57:42\n",
      "2018-09-06 16:48:24 Iter 17500 [Train]: loss=436.02, epe=5.49, lr=0.000108, samples/sec=13.2, sec/step=0.608, eta=13:55:53\n",
      "2018-09-06 16:49:28 Iter 17600 [Train]: loss=444.53, epe=5.62, lr=0.000104, samples/sec=13.2, sec/step=0.608, eta=13:54:26\n",
      "2018-09-06 16:50:32 Iter 17700 [Train]: loss=441.27, epe=5.60, lr=0.000100, samples/sec=13.2, sec/step=0.608, eta=13:53:20\n",
      "2018-09-06 16:51:36 Iter 17800 [Train]: loss=401.32, epe=5.04, lr=0.000096, samples/sec=13.2, sec/step=0.607, eta=13:51:57\n",
      "2018-09-06 16:52:41 Iter 17900 [Train]: loss=439.74, epe=5.51, lr=0.000092, samples/sec=13.2, sec/step=0.608, eta=13:52:24\n",
      "2018-09-06 16:53:45 Iter 18000 [Train]: loss=433.69, epe=5.44, lr=0.000088, samples/sec=13.2, sec/step=0.608, eta=13:50:39\n",
      "2018-09-06 16:54:06 Iter 18000 18000 [Val]: loss=366.53, epe=4.68\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-18000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-18000\n",
      "2018-09-06 16:55:19 Iter 18100 [Train]: loss=419.13, epe=5.24, lr=0.000084, samples/sec=13.2, sec/step=0.605, eta=13:45:40\n",
      "2018-09-06 16:56:23 Iter 18200 [Train]: loss=395.10, epe=4.92, lr=0.000080, samples/sec=13.1, sec/step=0.609, eta=13:49:49\n",
      "2018-09-06 16:57:27 Iter 18300 [Train]: loss=396.15, epe=4.98, lr=0.000076, samples/sec=13.2, sec/step=0.607, eta=13:46:22\n",
      "2018-09-06 16:58:31 Iter 18400 [Train]: loss=399.29, epe=5.00, lr=0.000072, samples/sec=13.2, sec/step=0.607, eta=13:45:10\n",
      "2018-09-06 16:59:35 Iter 18500 [Train]: loss=390.38, epe=4.88, lr=0.000069, samples/sec=13.2, sec/step=0.605, eta=13:42:23\n",
      "2018-09-06 17:00:39 Iter 18600 [Train]: loss=401.55, epe=5.03, lr=0.000065, samples/sec=13.2, sec/step=0.606, eta=13:41:44\n",
      "2018-09-06 17:01:44 Iter 18700 [Train]: loss=395.93, epe=4.93, lr=0.000061, samples/sec=13.2, sec/step=0.607, eta=13:41:59\n",
      "2018-09-06 17:02:48 Iter 18800 [Train]: loss=381.00, epe=4.75, lr=0.000057, samples/sec=13.2, sec/step=0.606, eta=13:40:28\n",
      "2018-09-06 17:03:52 Iter 18900 [Train]: loss=402.57, epe=5.03, lr=0.000053, samples/sec=13.2, sec/step=0.605, eta=13:37:26\n",
      "2018-09-06 17:04:56 Iter 19000 [Train]: loss=367.41, epe=4.55, lr=0.000049, samples/sec=13.2, sec/step=0.606, eta=13:38:08\n",
      "2018-09-06 17:05:17 Iter 19000 19000 [Val]: loss=356.58, epe=4.54\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-19000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-19000\n",
      "2018-09-06 17:06:29 Iter 19100 [Train]: loss=368.37, epe=4.57, lr=0.000045, samples/sec=13.3, sec/step=0.603, eta=13:33:16\n",
      "2018-09-06 17:07:33 Iter 19200 [Train]: loss=396.86, epe=4.98, lr=0.000041, samples/sec=13.2, sec/step=0.606, eta=13:36:11\n",
      "2018-09-06 17:08:37 Iter 19300 [Train]: loss=403.80, epe=5.07, lr=0.000037, samples/sec=13.2, sec/step=0.607, eta=13:36:44\n",
      "2018-09-06 17:09:41 Iter 19400 [Train]: loss=396.18, epe=4.95, lr=0.000033, samples/sec=13.2, sec/step=0.607, eta=13:35:12\n",
      "2018-09-06 17:10:46 Iter 19500 [Train]: loss=372.61, epe=4.62, lr=0.000030, samples/sec=13.2, sec/step=0.607, eta=13:34:31\n",
      "2018-09-06 17:11:50 Iter 19600 [Train]: loss=388.90, epe=4.85, lr=0.000026, samples/sec=13.2, sec/step=0.606, eta=13:31:31\n",
      "2018-09-06 17:12:54 Iter 19700 [Train]: loss=406.01, epe=5.06, lr=0.000022, samples/sec=13.2, sec/step=0.608, eta=13:33:28\n",
      "2018-09-06 17:13:58 Iter 19800 [Train]: loss=377.55, epe=4.70, lr=0.000018, samples/sec=13.2, sec/step=0.607, eta=13:30:54\n",
      "2018-09-06 17:15:02 Iter 19900 [Train]: loss=377.75, epe=4.70, lr=0.000014, samples/sec=13.2, sec/step=0.605, eta=13:28:03\n",
      "2018-09-06 17:16:06 Iter 20000 [Train]: loss=409.18, epe=5.09, lr=0.000010, samples/sec=13.2, sec/step=0.607, eta=13:29:49\n",
      "2018-09-06 17:16:27 Iter 20000 20000 [Val]: loss=351.54, epe=4.47\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-20000\n",
      "2018-09-06 17:17:40 Iter 20100 [Train]: loss=378.89, epe=4.73, lr=0.000012, samples/sec=13.2, sec/step=0.604, eta=13:24:04\n",
      "2018-09-06 17:18:44 Iter 20200 [Train]: loss=374.35, epe=4.65, lr=0.000014, samples/sec=13.2, sec/step=0.606, eta=13:25:22\n",
      "2018-09-06 17:19:49 Iter 20300 [Train]: loss=420.50, epe=5.25, lr=0.000016, samples/sec=13.2, sec/step=0.607, eta=13:26:31\n",
      "2018-09-06 17:20:53 Iter 20400 [Train]: loss=378.28, epe=4.70, lr=0.000018, samples/sec=13.2, sec/step=0.607, eta=13:24:43\n",
      "2018-09-06 17:21:57 Iter 20500 [Train]: loss=380.03, epe=4.73, lr=0.000020, samples/sec=13.2, sec/step=0.608, eta=13:25:13\n",
      "2018-09-06 17:23:01 Iter 20600 [Train]: loss=383.22, epe=4.78, lr=0.000022, samples/sec=13.2, sec/step=0.607, eta=13:23:35\n",
      "2018-09-06 17:24:06 Iter 20700 [Train]: loss=404.84, epe=5.06, lr=0.000024, samples/sec=13.1, sec/step=0.612, eta=13:29:07\n",
      "2018-09-06 17:25:10 Iter 20800 [Train]: loss=381.56, epe=4.75, lr=0.000026, samples/sec=13.1, sec/step=0.610, eta=13:25:29\n",
      "2018-09-06 17:26:15 Iter 20900 [Train]: loss=386.94, epe=4.83, lr=0.000028, samples/sec=13.1, sec/step=0.608, eta=13:22:11\n",
      "2018-09-06 17:27:19 Iter 21000 [Train]: loss=387.88, epe=4.84, lr=0.000029, samples/sec=13.2, sec/step=0.608, eta=13:20:48\n",
      "2018-09-06 17:27:40 Iter 21000 21000 [Val]: loss=350.92, epe=4.46\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-21000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-21000\n",
      "2018-09-06 17:28:54 Iter 21100 [Train]: loss=380.68, epe=4.73, lr=0.000031, samples/sec=13.2, sec/step=0.606, eta=13:16:35\n",
      "2018-09-06 17:29:58 Iter 21200 [Train]: loss=407.55, epe=5.11, lr=0.000033, samples/sec=13.1, sec/step=0.610, eta=13:20:37\n",
      "2018-09-06 17:31:03 Iter 21300 [Train]: loss=369.01, epe=4.57, lr=0.000035, samples/sec=13.1, sec/step=0.609, eta=13:18:55\n",
      "2018-09-06 17:32:07 Iter 21400 [Train]: loss=375.35, epe=4.66, lr=0.000037, samples/sec=13.1, sec/step=0.609, eta=13:17:09\n",
      "2018-09-06 17:33:11 Iter 21500 [Train]: loss=381.25, epe=4.74, lr=0.000039, samples/sec=13.1, sec/step=0.609, eta=13:16:48\n",
      "2018-09-06 17:34:16 Iter 21600 [Train]: loss=362.03, epe=4.50, lr=0.000041, samples/sec=13.1, sec/step=0.609, eta=13:15:49\n",
      "2018-09-06 17:35:20 Iter 21700 [Train]: loss=382.50, epe=4.76, lr=0.000043, samples/sec=13.1, sec/step=0.609, eta=13:14:44\n",
      "2018-09-06 17:36:25 Iter 21800 [Train]: loss=402.86, epe=5.03, lr=0.000045, samples/sec=13.1, sec/step=0.609, eta=13:13:17\n",
      "2018-09-06 17:37:29 Iter 21900 [Train]: loss=389.73, epe=4.87, lr=0.000047, samples/sec=13.1, sec/step=0.609, eta=13:12:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 17:38:34 Iter 22000 [Train]: loss=389.41, epe=4.87, lr=0.000049, samples/sec=13.1, sec/step=0.610, eta=13:12:42\n",
      "2018-09-06 17:38:55 Iter 22000 22000 [Val]: loss=355.85, epe=4.53\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-22000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-22000\n",
      "2018-09-06 17:40:08 Iter 22100 [Train]: loss=401.91, epe=5.02, lr=0.000051, samples/sec=13.2, sec/step=0.606, eta=13:06:28\n",
      "2018-09-06 17:41:13 Iter 22200 [Train]: loss=389.81, epe=4.86, lr=0.000053, samples/sec=13.1, sec/step=0.610, eta=13:10:23\n",
      "2018-09-06 17:42:17 Iter 22300 [Train]: loss=387.47, epe=4.86, lr=0.000055, samples/sec=13.1, sec/step=0.609, eta=13:08:43\n",
      "2018-09-06 17:43:22 Iter 22400 [Train]: loss=390.40, epe=4.87, lr=0.000057, samples/sec=13.1, sec/step=0.610, eta=13:08:44\n",
      "2018-09-06 17:44:26 Iter 22500 [Train]: loss=393.76, epe=4.94, lr=0.000059, samples/sec=13.1, sec/step=0.609, eta=13:07:06\n",
      "2018-09-06 17:45:30 Iter 22600 [Train]: loss=402.98, epe=5.06, lr=0.000061, samples/sec=13.1, sec/step=0.609, eta=13:05:42\n",
      "2018-09-06 17:46:35 Iter 22700 [Train]: loss=388.76, epe=4.87, lr=0.000063, samples/sec=13.1, sec/step=0.609, eta=13:04:59\n",
      "2018-09-06 17:47:39 Iter 22800 [Train]: loss=385.19, epe=4.79, lr=0.000065, samples/sec=13.1, sec/step=0.609, eta=13:04:10\n",
      "2018-09-06 17:48:44 Iter 22900 [Train]: loss=403.25, epe=5.01, lr=0.000067, samples/sec=13.1, sec/step=0.609, eta=13:02:15\n",
      "2018-09-06 17:49:48 Iter 23000 [Train]: loss=386.68, epe=4.83, lr=0.000068, samples/sec=13.1, sec/step=0.609, eta=13:02:02\n",
      "2018-09-06 17:50:09 Iter 23000 23000 [Val]: loss=353.55, epe=4.49\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-23000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-23000\n",
      "2018-09-06 17:51:23 Iter 23100 [Train]: loss=411.96, epe=5.16, lr=0.000070, samples/sec=13.2, sec/step=0.607, eta=12:57:52\n",
      "2018-09-06 17:52:27 Iter 23200 [Train]: loss=364.23, epe=4.55, lr=0.000072, samples/sec=13.1, sec/step=0.609, eta=12:59:54\n",
      "2018-09-06 17:53:32 Iter 23300 [Train]: loss=391.36, epe=4.90, lr=0.000074, samples/sec=13.1, sec/step=0.611, eta=13:00:26\n",
      "2018-09-06 17:54:36 Iter 23400 [Train]: loss=419.31, epe=5.26, lr=0.000076, samples/sec=13.1, sec/step=0.609, eta=12:57:57\n",
      "2018-09-06 17:55:41 Iter 23500 [Train]: loss=387.61, epe=4.83, lr=0.000078, samples/sec=13.1, sec/step=0.610, eta=12:57:12\n",
      "2018-09-06 17:56:45 Iter 23600 [Train]: loss=384.69, epe=4.82, lr=0.000080, samples/sec=13.1, sec/step=0.609, eta=12:55:57\n",
      "2018-09-06 17:57:50 Iter 23700 [Train]: loss=416.25, epe=5.20, lr=0.000082, samples/sec=13.1, sec/step=0.610, eta=12:55:19\n",
      "2018-09-06 17:58:55 Iter 23800 [Train]: loss=401.95, epe=5.05, lr=0.000084, samples/sec=13.0, sec/step=0.614, eta=13:00:25\n",
      "2018-09-06 18:00:00 Iter 23900 [Train]: loss=399.10, epe=4.99, lr=0.000086, samples/sec=13.0, sec/step=0.615, eta=13:00:08\n",
      "2018-09-06 18:01:05 Iter 24000 [Train]: loss=392.61, epe=4.90, lr=0.000088, samples/sec=13.0, sec/step=0.615, eta=12:59:17\n",
      "2018-09-06 18:01:26 Iter 24000 24000 [Val]: loss=351.59, epe=4.47\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-24000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-24000\n",
      "2018-09-06 18:02:39 Iter 24100 [Train]: loss=370.75, epe=4.63, lr=0.000090, samples/sec=13.3, sec/step=0.604, eta=12:43:28\n",
      "2018-09-06 18:03:43 Iter 24200 [Train]: loss=394.99, epe=4.95, lr=0.000092, samples/sec=13.2, sec/step=0.606, eta=12:45:28\n",
      "2018-09-06 18:04:47 Iter 24300 [Train]: loss=352.28, epe=4.38, lr=0.000094, samples/sec=13.2, sec/step=0.607, eta=12:45:52\n",
      "2018-09-06 18:05:51 Iter 24400 [Train]: loss=396.29, epe=4.94, lr=0.000096, samples/sec=13.2, sec/step=0.607, eta=12:45:04\n",
      "2018-09-06 18:06:55 Iter 24500 [Train]: loss=360.07, epe=4.46, lr=0.000098, samples/sec=13.2, sec/step=0.608, eta=12:44:41\n",
      "2018-09-06 18:08:00 Iter 24600 [Train]: loss=380.77, epe=4.75, lr=0.000100, samples/sec=13.2, sec/step=0.608, eta=12:43:58\n",
      "2018-09-06 18:09:04 Iter 24700 [Train]: loss=407.59, epe=5.10, lr=0.000102, samples/sec=13.2, sec/step=0.607, eta=12:42:02\n",
      "2018-09-06 18:10:08 Iter 24800 [Train]: loss=399.04, epe=4.99, lr=0.000104, samples/sec=13.2, sec/step=0.608, eta=12:42:06\n",
      "2018-09-06 18:11:13 Iter 24900 [Train]: loss=381.04, epe=4.75, lr=0.000106, samples/sec=13.2, sec/step=0.606, eta=12:38:32\n",
      "2018-09-06 18:12:17 Iter 25000 [Train]: loss=397.34, epe=4.96, lr=0.000108, samples/sec=13.1, sec/step=0.609, eta=12:40:42\n",
      "2018-09-06 18:12:38 Iter 25000 25000 [Val]: loss=355.03, epe=4.53\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-25000\n",
      "2018-09-06 18:13:51 Iter 25100 [Train]: loss=385.62, epe=4.84, lr=0.000109, samples/sec=13.2, sec/step=0.605, eta=12:34:51\n",
      "2018-09-06 18:14:55 Iter 25200 [Train]: loss=385.27, epe=4.85, lr=0.000111, samples/sec=13.2, sec/step=0.608, eta=12:38:19\n",
      "2018-09-06 18:15:59 Iter 25300 [Train]: loss=392.04, epe=4.91, lr=0.000113, samples/sec=13.1, sec/step=0.609, eta=12:38:00\n",
      "2018-09-06 18:17:03 Iter 25400 [Train]: loss=395.30, epe=4.97, lr=0.000115, samples/sec=13.2, sec/step=0.608, eta=12:35:40\n",
      "2018-09-06 18:18:08 Iter 25500 [Train]: loss=389.46, epe=4.88, lr=0.000117, samples/sec=13.1, sec/step=0.608, eta=12:35:27\n",
      "2018-09-06 18:19:12 Iter 25600 [Train]: loss=377.04, epe=4.70, lr=0.000119, samples/sec=13.1, sec/step=0.609, eta=12:35:18\n",
      "2018-09-06 18:20:16 Iter 25700 [Train]: loss=387.74, epe=4.85, lr=0.000121, samples/sec=13.1, sec/step=0.608, eta=12:33:23\n",
      "2018-09-06 18:21:20 Iter 25800 [Train]: loss=393.85, epe=4.92, lr=0.000123, samples/sec=13.2, sec/step=0.606, eta=12:29:51\n",
      "2018-09-06 18:22:25 Iter 25900 [Train]: loss=412.28, epe=5.19, lr=0.000125, samples/sec=13.2, sec/step=0.608, eta=12:30:33\n",
      "2018-09-06 18:23:29 Iter 26000 [Train]: loss=384.83, epe=4.79, lr=0.000127, samples/sec=13.1, sec/step=0.609, eta=12:31:18\n",
      "2018-09-06 18:23:50 Iter 26000 26000 [Val]: loss=371.83, epe=4.77\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-26000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-26000\n",
      "2018-09-06 18:25:03 Iter 26100 [Train]: loss=390.45, epe=4.88, lr=0.000129, samples/sec=13.2, sec/step=0.606, eta=12:26:00\n",
      "2018-09-06 18:26:07 Iter 26200 [Train]: loss=413.71, epe=5.19, lr=0.000131, samples/sec=13.1, sec/step=0.612, eta=12:32:22\n",
      "2018-09-06 18:27:12 Iter 26300 [Train]: loss=394.54, epe=4.95, lr=0.000133, samples/sec=13.1, sec/step=0.610, eta=12:28:55\n",
      "2018-09-06 18:28:16 Iter 26400 [Train]: loss=388.56, epe=4.87, lr=0.000135, samples/sec=13.2, sec/step=0.605, eta=12:22:39\n",
      "2018-09-06 18:29:21 Iter 26500 [Train]: loss=412.39, epe=5.20, lr=0.000137, samples/sec=13.1, sec/step=0.609, eta=12:25:36\n",
      "2018-09-06 18:30:25 Iter 26600 [Train]: loss=425.76, epe=5.39, lr=0.000139, samples/sec=13.2, sec/step=0.606, eta=12:21:19\n",
      "2018-09-06 18:31:29 Iter 26700 [Train]: loss=399.61, epe=5.05, lr=0.000141, samples/sec=13.2, sec/step=0.605, eta=12:19:39\n",
      "2018-09-06 18:32:33 Iter 26800 [Train]: loss=427.92, epe=5.39, lr=0.000143, samples/sec=13.2, sec/step=0.607, eta=12:20:11\n",
      "2018-09-06 18:33:37 Iter 26900 [Train]: loss=384.66, epe=4.83, lr=0.000145, samples/sec=13.2, sec/step=0.608, eta=12:20:44\n",
      "2018-09-06 18:34:41 Iter 27000 [Train]: loss=375.20, epe=4.69, lr=0.000147, samples/sec=13.2, sec/step=0.606, eta=12:17:23\n",
      "2018-09-06 18:35:02 Iter 27000 27000 [Val]: loss=351.28, epe=4.45\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-27000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-27000\n",
      "2018-09-06 18:36:15 Iter 27100 [Train]: loss=403.91, epe=5.09, lr=0.000148, samples/sec=13.2, sec/step=0.604, eta=12:14:18\n",
      "2018-09-06 18:37:19 Iter 27200 [Train]: loss=377.97, epe=4.70, lr=0.000150, samples/sec=13.2, sec/step=0.607, eta=12:16:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 18:38:24 Iter 27300 [Train]: loss=401.80, epe=5.01, lr=0.000152, samples/sec=13.1, sec/step=0.608, eta=12:17:09\n",
      "2018-09-06 18:39:28 Iter 27400 [Train]: loss=390.39, epe=4.89, lr=0.000154, samples/sec=13.1, sec/step=0.610, eta=12:17:59\n",
      "2018-09-06 18:40:33 Iter 27500 [Train]: loss=389.59, epe=4.88, lr=0.000156, samples/sec=13.1, sec/step=0.609, eta=12:16:16\n",
      "2018-09-06 18:41:37 Iter 27600 [Train]: loss=407.95, epe=5.13, lr=0.000158, samples/sec=13.2, sec/step=0.606, eta=12:11:03\n",
      "2018-09-06 18:42:41 Iter 27700 [Train]: loss=400.08, epe=5.01, lr=0.000160, samples/sec=13.2, sec/step=0.606, eta=12:10:20\n",
      "2018-09-06 18:43:45 Iter 27800 [Train]: loss=365.71, epe=4.54, lr=0.000162, samples/sec=13.2, sec/step=0.606, eta=12:09:35\n",
      "2018-09-06 18:44:49 Iter 27900 [Train]: loss=390.71, epe=4.84, lr=0.000164, samples/sec=13.2, sec/step=0.606, eta=12:07:52\n",
      "2018-09-06 18:45:53 Iter 28000 [Train]: loss=403.25, epe=5.05, lr=0.000166, samples/sec=13.2, sec/step=0.607, eta=12:08:34\n",
      "2018-09-06 18:46:14 Iter 28000 28000 [Val]: loss=355.28, epe=4.52\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-28000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-28000\n",
      "2018-09-06 18:47:27 Iter 28100 [Train]: loss=430.64, epe=5.46, lr=0.000168, samples/sec=13.3, sec/step=0.603, eta=12:03:09\n",
      "2018-09-06 18:48:31 Iter 28200 [Train]: loss=402.95, epe=5.06, lr=0.000170, samples/sec=13.2, sec/step=0.606, eta=12:05:22\n",
      "2018-09-06 18:49:36 Iter 28300 [Train]: loss=361.24, epe=4.48, lr=0.000172, samples/sec=13.2, sec/step=0.607, eta=12:05:16\n",
      "2018-09-06 18:50:40 Iter 28400 [Train]: loss=409.05, epe=5.17, lr=0.000174, samples/sec=13.2, sec/step=0.608, eta=12:05:42\n",
      "2018-09-06 18:51:44 Iter 28500 [Train]: loss=395.23, epe=4.93, lr=0.000176, samples/sec=13.2, sec/step=0.606, eta=12:02:14\n",
      "2018-09-06 18:52:48 Iter 28600 [Train]: loss=386.58, epe=4.80, lr=0.000178, samples/sec=13.2, sec/step=0.607, eta=12:02:23\n",
      "2018-09-06 18:53:52 Iter 28700 [Train]: loss=403.55, epe=5.06, lr=0.000180, samples/sec=13.2, sec/step=0.608, eta=12:02:01\n",
      "2018-09-06 18:54:57 Iter 28800 [Train]: loss=421.29, epe=5.30, lr=0.000182, samples/sec=13.2, sec/step=0.607, eta=12:00:23\n",
      "2018-09-06 18:56:01 Iter 28900 [Train]: loss=408.41, epe=5.14, lr=0.000184, samples/sec=13.2, sec/step=0.606, eta=11:58:23\n",
      "2018-09-06 18:57:05 Iter 29000 [Train]: loss=407.62, epe=5.14, lr=0.000185, samples/sec=13.2, sec/step=0.608, eta=11:59:46\n",
      "2018-09-06 18:57:26 Iter 29000 29000 [Val]: loss=353.26, epe=4.49\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-29000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-29000\n",
      "2018-09-06 18:58:39 Iter 29100 [Train]: loss=395.89, epe=4.94, lr=0.000187, samples/sec=13.2, sec/step=0.605, eta=11:54:42\n",
      "2018-09-06 18:59:44 Iter 29200 [Train]: loss=379.23, epe=4.75, lr=0.000189, samples/sec=13.2, sec/step=0.608, eta=11:57:34\n",
      "2018-09-06 19:00:48 Iter 29300 [Train]: loss=384.87, epe=4.81, lr=0.000191, samples/sec=13.2, sec/step=0.606, eta=11:53:43\n",
      "2018-09-06 19:01:52 Iter 29400 [Train]: loss=420.63, epe=5.32, lr=0.000193, samples/sec=13.1, sec/step=0.609, eta=11:56:46\n",
      "2018-09-06 19:02:56 Iter 29500 [Train]: loss=415.54, epe=5.23, lr=0.000195, samples/sec=13.2, sec/step=0.608, eta=11:54:17\n",
      "2018-09-06 19:04:01 Iter 29600 [Train]: loss=388.58, epe=4.90, lr=0.000197, samples/sec=13.2, sec/step=0.607, eta=11:52:06\n",
      "2018-09-06 19:05:05 Iter 29700 [Train]: loss=393.24, epe=4.89, lr=0.000199, samples/sec=13.2, sec/step=0.606, eta=11:50:21\n",
      "2018-09-06 19:06:09 Iter 29800 [Train]: loss=400.83, epe=5.03, lr=0.000201, samples/sec=13.2, sec/step=0.607, eta=11:50:18\n",
      "2018-09-06 19:07:13 Iter 29900 [Train]: loss=382.46, epe=4.80, lr=0.000203, samples/sec=13.2, sec/step=0.607, eta=11:48:59\n",
      "2018-09-06 19:08:17 Iter 30000 [Train]: loss=394.68, epe=4.94, lr=0.000205, samples/sec=13.2, sec/step=0.607, eta=11:48:28\n",
      "2018-09-06 19:08:38 Iter 30000 30000 [Val]: loss=364.06, epe=4.64\n",
      "Saving model...\n",
      "... model saved in None\n",
      "2018-09-06 19:09:48 Iter 30100 [Train]: loss=406.59, epe=5.13, lr=0.000203, samples/sec=13.2, sec/step=0.605, eta=11:44:45\n",
      "2018-09-06 19:10:52 Iter 30200 [Train]: loss=382.43, epe=4.79, lr=0.000201, samples/sec=13.2, sec/step=0.606, eta=11:45:20\n",
      "2018-09-06 19:11:56 Iter 30300 [Train]: loss=388.58, epe=4.86, lr=0.000199, samples/sec=13.2, sec/step=0.606, eta=11:44:24\n",
      "2018-09-06 19:13:01 Iter 30400 [Train]: loss=411.71, epe=5.17, lr=0.000197, samples/sec=13.2, sec/step=0.608, eta=11:45:06\n",
      "2018-09-06 19:14:05 Iter 30500 [Train]: loss=371.39, epe=4.64, lr=0.000195, samples/sec=13.2, sec/step=0.607, eta=11:43:31\n",
      "2018-09-06 19:15:09 Iter 30600 [Train]: loss=378.82, epe=4.72, lr=0.000193, samples/sec=13.2, sec/step=0.607, eta=11:42:19\n",
      "2018-09-06 19:16:13 Iter 30700 [Train]: loss=406.33, epe=5.09, lr=0.000191, samples/sec=13.1, sec/step=0.609, eta=11:43:20\n",
      "2018-09-06 19:17:18 Iter 30800 [Train]: loss=397.96, epe=4.99, lr=0.000189, samples/sec=13.2, sec/step=0.607, eta=11:40:24\n",
      "2018-09-06 19:18:22 Iter 30900 [Train]: loss=391.35, epe=4.90, lr=0.000187, samples/sec=13.2, sec/step=0.604, eta=11:35:37\n",
      "2018-09-06 19:19:26 Iter 31000 [Train]: loss=409.22, epe=5.15, lr=0.000186, samples/sec=13.2, sec/step=0.606, eta=11:36:27\n",
      "2018-09-06 19:19:47 Iter 31000 31000 [Val]: loss=359.82, epe=4.60\n",
      "Saving model...\n",
      "... model saved in None\n",
      "2018-09-06 19:20:55 Iter 31100 [Train]: loss=394.25, epe=4.97, lr=0.000184, samples/sec=13.2, sec/step=0.606, eta=11:36:20\n",
      "2018-09-06 19:21:59 Iter 31200 [Train]: loss=402.53, epe=5.02, lr=0.000182, samples/sec=13.1, sec/step=0.610, eta=11:39:27\n",
      "2018-09-06 19:23:03 Iter 31300 [Train]: loss=388.55, epe=4.85, lr=0.000180, samples/sec=13.2, sec/step=0.606, eta=11:34:17\n",
      "2018-09-06 19:24:07 Iter 31400 [Train]: loss=370.87, epe=4.61, lr=0.000178, samples/sec=13.2, sec/step=0.608, eta=11:34:48\n",
      "2018-09-06 19:25:11 Iter 31500 [Train]: loss=388.72, epe=4.83, lr=0.000176, samples/sec=13.2, sec/step=0.608, eta=11:34:00\n",
      "2018-09-06 19:26:16 Iter 31600 [Train]: loss=381.08, epe=4.76, lr=0.000174, samples/sec=13.2, sec/step=0.607, eta=11:31:36\n",
      "2018-09-06 19:27:20 Iter 31700 [Train]: loss=407.28, epe=5.11, lr=0.000172, samples/sec=13.2, sec/step=0.606, eta=11:29:55\n",
      "2018-09-06 19:28:24 Iter 31800 [Train]: loss=379.31, epe=4.73, lr=0.000170, samples/sec=13.2, sec/step=0.605, eta=11:27:20\n",
      "2018-09-06 19:29:28 Iter 31900 [Train]: loss=365.47, epe=4.58, lr=0.000168, samples/sec=13.2, sec/step=0.607, eta=11:28:58\n",
      "2018-09-06 19:30:32 Iter 32000 [Train]: loss=364.26, epe=4.56, lr=0.000166, samples/sec=13.2, sec/step=0.608, eta=11:28:53\n",
      "2018-09-06 19:30:53 Iter 32000 32000 [Val]: loss=344.17, epe=4.37\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-32000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-32000\n",
      "2018-09-06 19:32:06 Iter 32100 [Train]: loss=390.96, epe=4.90, lr=0.000164, samples/sec=13.2, sec/step=0.606, eta=11:25:42\n",
      "2018-09-06 19:33:10 Iter 32200 [Train]: loss=391.84, epe=4.92, lr=0.000162, samples/sec=13.1, sec/step=0.608, eta=11:27:33\n",
      "2018-09-06 19:34:15 Iter 32300 [Train]: loss=365.62, epe=4.54, lr=0.000160, samples/sec=13.1, sec/step=0.608, eta=11:26:32\n",
      "2018-09-06 19:35:19 Iter 32400 [Train]: loss=382.26, epe=4.76, lr=0.000158, samples/sec=13.1, sec/step=0.609, eta=11:25:39\n",
      "2018-09-06 19:36:23 Iter 32500 [Train]: loss=375.80, epe=4.66, lr=0.000156, samples/sec=13.1, sec/step=0.609, eta=11:24:50\n",
      "2018-09-06 19:37:28 Iter 32600 [Train]: loss=372.33, epe=4.62, lr=0.000154, samples/sec=13.1, sec/step=0.609, eta=11:24:20\n",
      "2018-09-06 19:38:32 Iter 32700 [Train]: loss=354.71, epe=4.39, lr=0.000152, samples/sec=13.2, sec/step=0.607, eta=11:21:03\n",
      "2018-09-06 19:39:36 Iter 32800 [Train]: loss=357.45, epe=4.44, lr=0.000150, samples/sec=13.2, sec/step=0.606, eta=11:18:44\n",
      "2018-09-06 19:40:41 Iter 32900 [Train]: loss=400.82, epe=5.00, lr=0.000148, samples/sec=13.1, sec/step=0.612, eta=11:23:56\n",
      "2018-09-06 19:41:45 Iter 33000 [Train]: loss=374.26, epe=4.65, lr=0.000147, samples/sec=13.1, sec/step=0.610, eta=11:21:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 19:42:06 Iter 33000 33000 [Val]: loss=339.30, epe=4.33\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-33000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-33000\n",
      "2018-09-06 19:43:20 Iter 33100 [Train]: loss=359.04, epe=4.47, lr=0.000145, samples/sec=13.1, sec/step=0.609, eta=11:19:35\n",
      "2018-09-06 19:44:25 Iter 33200 [Train]: loss=341.03, epe=4.22, lr=0.000143, samples/sec=13.1, sec/step=0.613, eta=11:21:55\n",
      "2018-09-06 19:45:29 Iter 33300 [Train]: loss=343.12, epe=4.26, lr=0.000141, samples/sec=13.2, sec/step=0.605, eta=11:12:03\n",
      "2018-09-06 19:46:33 Iter 33400 [Train]: loss=364.74, epe=4.53, lr=0.000139, samples/sec=13.2, sec/step=0.606, eta=11:12:37\n",
      "2018-09-06 19:47:37 Iter 33500 [Train]: loss=380.91, epe=4.75, lr=0.000137, samples/sec=13.2, sec/step=0.608, eta=11:13:43\n",
      "2018-09-06 19:48:41 Iter 33600 [Train]: loss=373.07, epe=4.63, lr=0.000135, samples/sec=13.2, sec/step=0.608, eta=11:12:45\n",
      "2018-09-06 19:49:45 Iter 33700 [Train]: loss=392.69, epe=4.89, lr=0.000133, samples/sec=13.1, sec/step=0.609, eta=11:12:36\n",
      "2018-09-06 19:50:50 Iter 33800 [Train]: loss=372.40, epe=4.64, lr=0.000131, samples/sec=13.1, sec/step=0.609, eta=11:11:36\n",
      "2018-09-06 19:51:54 Iter 33900 [Train]: loss=345.25, epe=4.26, lr=0.000129, samples/sec=13.2, sec/step=0.607, eta=11:08:10\n",
      "2018-09-06 19:52:58 Iter 34000 [Train]: loss=362.37, epe=4.47, lr=0.000127, samples/sec=13.2, sec/step=0.607, eta=11:08:02\n",
      "2018-09-06 19:53:19 Iter 34000 34000 [Val]: loss=332.61, epe=4.20\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-34000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-34000\n",
      "2018-09-06 19:54:32 Iter 34100 [Train]: loss=366.54, epe=4.55, lr=0.000125, samples/sec=13.2, sec/step=0.604, eta=11:03:39\n",
      "2018-09-06 19:55:37 Iter 34200 [Train]: loss=358.87, epe=4.47, lr=0.000123, samples/sec=13.1, sec/step=0.608, eta=11:07:15\n",
      "2018-09-06 19:56:41 Iter 34300 [Train]: loss=377.90, epe=4.68, lr=0.000121, samples/sec=13.2, sec/step=0.608, eta=11:05:33\n",
      "2018-09-06 19:57:45 Iter 34400 [Train]: loss=354.26, epe=4.38, lr=0.000119, samples/sec=13.2, sec/step=0.608, eta=11:04:55\n",
      "2018-09-06 19:58:49 Iter 34500 [Train]: loss=365.32, epe=4.53, lr=0.000117, samples/sec=13.2, sec/step=0.607, eta=11:02:35\n",
      "2018-09-06 19:59:54 Iter 34600 [Train]: loss=337.06, epe=4.15, lr=0.000115, samples/sec=13.1, sec/step=0.609, eta=11:03:26\n",
      "2018-09-06 20:00:58 Iter 34700 [Train]: loss=375.09, epe=4.65, lr=0.000113, samples/sec=13.2, sec/step=0.606, eta=10:59:27\n",
      "2018-09-06 20:02:02 Iter 34800 [Train]: loss=353.25, epe=4.36, lr=0.000111, samples/sec=13.2, sec/step=0.608, eta=11:00:38\n",
      "2018-09-06 20:03:06 Iter 34900 [Train]: loss=353.94, epe=4.37, lr=0.000109, samples/sec=13.2, sec/step=0.607, eta=10:59:05\n",
      "2018-09-06 20:04:11 Iter 35000 [Train]: loss=380.02, epe=4.71, lr=0.000108, samples/sec=13.2, sec/step=0.606, eta=10:57:02\n",
      "2018-09-06 20:04:31 Iter 35000 35000 [Val]: loss=323.90, epe=4.08\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-35000\n",
      "2018-09-06 20:05:44 Iter 35100 [Train]: loss=366.19, epe=4.53, lr=0.000106, samples/sec=13.2, sec/step=0.605, eta=10:54:49\n",
      "2018-09-06 20:06:48 Iter 35200 [Train]: loss=344.47, epe=4.26, lr=0.000104, samples/sec=13.2, sec/step=0.607, eta=10:55:32\n",
      "2018-09-06 20:07:53 Iter 35300 [Train]: loss=364.84, epe=4.54, lr=0.000102, samples/sec=13.2, sec/step=0.607, eta=10:54:02\n",
      "2018-09-06 20:08:58 Iter 35400 [Train]: loss=332.61, epe=4.11, lr=0.000100, samples/sec=13.0, sec/step=0.617, eta=11:03:46\n",
      "2018-09-06 20:10:03 Iter 35500 [Train]: loss=337.03, epe=4.18, lr=0.000098, samples/sec=12.9, sec/step=0.618, eta=11:04:34\n",
      "2018-09-06 20:11:09 Iter 35600 [Train]: loss=361.18, epe=4.48, lr=0.000096, samples/sec=12.9, sec/step=0.618, eta=11:03:13\n",
      "2018-09-06 20:12:14 Iter 35700 [Train]: loss=361.57, epe=4.47, lr=0.000094, samples/sec=12.9, sec/step=0.618, eta=11:02:18\n",
      "2018-09-06 20:13:20 Iter 35800 [Train]: loss=335.60, epe=4.12, lr=0.000092, samples/sec=12.9, sec/step=0.619, eta=11:01:51\n",
      "2018-09-06 20:14:26 Iter 35900 [Train]: loss=354.18, epe=4.38, lr=0.000090, samples/sec=12.9, sec/step=0.619, eta=11:01:03\n",
      "2018-09-06 20:15:31 Iter 36000 [Train]: loss=357.05, epe=4.42, lr=0.000088, samples/sec=12.9, sec/step=0.619, eta=10:59:57\n",
      "2018-09-06 20:15:53 Iter 36000 36000 [Val]: loss=315.13, epe=3.97\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-36000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-36000\n",
      "2018-09-06 20:17:09 Iter 36100 [Train]: loss=327.94, epe=4.03, lr=0.000086, samples/sec=13.0, sec/step=0.614, eta=10:54:26\n",
      "2018-09-06 20:18:15 Iter 36200 [Train]: loss=349.83, epe=4.32, lr=0.000084, samples/sec=12.8, sec/step=0.624, eta=11:03:17\n",
      "2018-09-06 20:19:21 Iter 36300 [Train]: loss=337.55, epe=4.13, lr=0.000082, samples/sec=12.9, sec/step=0.620, eta=10:58:40\n",
      "2018-09-06 20:20:27 Iter 36400 [Train]: loss=358.06, epe=4.40, lr=0.000080, samples/sec=12.9, sec/step=0.620, eta=10:57:21\n",
      "2018-09-06 20:21:33 Iter 36500 [Train]: loss=348.62, epe=4.30, lr=0.000078, samples/sec=12.8, sec/step=0.623, eta=10:59:03\n",
      "2018-09-06 20:22:39 Iter 36600 [Train]: loss=340.03, epe=4.19, lr=0.000076, samples/sec=12.9, sec/step=0.621, eta=10:56:15\n",
      "2018-09-06 20:23:44 Iter 36700 [Train]: loss=333.93, epe=4.11, lr=0.000074, samples/sec=12.9, sec/step=0.620, eta=10:53:42\n",
      "2018-09-06 20:24:50 Iter 36800 [Train]: loss=339.31, epe=4.20, lr=0.000072, samples/sec=12.9, sec/step=0.620, eta=10:53:26\n",
      "2018-09-06 20:25:56 Iter 36900 [Train]: loss=361.53, epe=4.46, lr=0.000070, samples/sec=12.9, sec/step=0.620, eta=10:52:03\n",
      "2018-09-06 20:27:02 Iter 37000 [Train]: loss=338.35, epe=4.15, lr=0.000069, samples/sec=12.9, sec/step=0.620, eta=10:51:04\n",
      "2018-09-06 20:27:24 Iter 37000 37000 [Val]: loss=310.43, epe=3.90\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-37000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-37000\n",
      "2018-09-06 20:28:40 Iter 37100 [Train]: loss=353.55, epe=4.35, lr=0.000067, samples/sec=13.0, sec/step=0.615, eta=10:45:04\n",
      "2018-09-06 20:29:45 Iter 37200 [Train]: loss=341.93, epe=4.18, lr=0.000065, samples/sec=12.9, sec/step=0.618, eta=10:47:05\n",
      "2018-09-06 20:30:51 Iter 37300 [Train]: loss=333.88, epe=4.10, lr=0.000063, samples/sec=12.9, sec/step=0.618, eta=10:46:10\n",
      "2018-09-06 20:31:57 Iter 37400 [Train]: loss=335.28, epe=4.12, lr=0.000061, samples/sec=12.9, sec/step=0.621, eta=10:47:58\n",
      "2018-09-06 20:33:02 Iter 37500 [Train]: loss=348.59, epe=4.31, lr=0.000059, samples/sec=12.9, sec/step=0.619, eta=10:44:44\n",
      "2018-09-06 20:34:08 Iter 37600 [Train]: loss=334.79, epe=4.10, lr=0.000057, samples/sec=12.9, sec/step=0.618, eta=10:42:56\n",
      "2018-09-06 20:35:14 Iter 37700 [Train]: loss=340.28, epe=4.18, lr=0.000055, samples/sec=12.9, sec/step=0.619, eta=10:42:34\n",
      "2018-09-06 20:36:19 Iter 37800 [Train]: loss=323.30, epe=3.99, lr=0.000053, samples/sec=12.9, sec/step=0.619, eta=10:42:08\n",
      "2018-09-06 20:37:25 Iter 37900 [Train]: loss=343.56, epe=4.24, lr=0.000051, samples/sec=12.9, sec/step=0.619, eta=10:40:20\n",
      "2018-09-06 20:38:31 Iter 38000 [Train]: loss=353.38, epe=4.37, lr=0.000049, samples/sec=12.9, sec/step=0.618, eta=10:38:22\n",
      "2018-09-06 20:38:53 Iter 38000 38000 [Val]: loss=307.09, epe=3.85\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-38000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-38000\n",
      "2018-09-06 20:40:09 Iter 38100 [Train]: loss=349.47, epe=4.29, lr=0.000047, samples/sec=13.0, sec/step=0.614, eta=10:33:36\n",
      "2018-09-06 20:41:14 Iter 38200 [Train]: loss=336.54, epe=4.14, lr=0.000045, samples/sec=12.9, sec/step=0.618, eta=10:37:00\n",
      "2018-09-06 20:42:20 Iter 38300 [Train]: loss=316.77, epe=3.88, lr=0.000043, samples/sec=12.9, sec/step=0.619, eta=10:36:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 20:43:26 Iter 38400 [Train]: loss=317.02, epe=3.88, lr=0.000041, samples/sec=12.9, sec/step=0.618, eta=10:34:44\n",
      "2018-09-06 20:44:31 Iter 38500 [Train]: loss=319.62, epe=3.90, lr=0.000039, samples/sec=12.9, sec/step=0.619, eta=10:34:34\n",
      "2018-09-06 20:45:37 Iter 38600 [Train]: loss=330.88, epe=4.06, lr=0.000037, samples/sec=13.0, sec/step=0.618, eta=10:31:57\n",
      "2018-09-06 20:46:43 Iter 38700 [Train]: loss=319.62, epe=3.91, lr=0.000035, samples/sec=12.9, sec/step=0.620, eta=10:33:13\n",
      "2018-09-06 20:47:48 Iter 38800 [Train]: loss=312.78, epe=3.83, lr=0.000033, samples/sec=12.9, sec/step=0.618, eta=10:30:42\n",
      "2018-09-06 20:48:54 Iter 38900 [Train]: loss=322.10, epe=3.95, lr=0.000031, samples/sec=12.9, sec/step=0.619, eta=10:30:31\n",
      "2018-09-06 20:49:59 Iter 39000 [Train]: loss=330.13, epe=4.01, lr=0.000030, samples/sec=12.9, sec/step=0.619, eta=10:29:28\n",
      "2018-09-06 20:50:21 Iter 39000 39000 [Val]: loss=300.62, epe=3.77\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-39000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-39000\n",
      "2018-09-06 20:51:37 Iter 39100 [Train]: loss=316.57, epe=3.86, lr=0.000028, samples/sec=13.0, sec/step=0.616, eta=10:25:31\n",
      "2018-09-06 20:52:43 Iter 39200 [Train]: loss=327.70, epe=4.00, lr=0.000026, samples/sec=12.9, sec/step=0.620, eta=10:28:07\n",
      "2018-09-06 20:53:48 Iter 39300 [Train]: loss=320.60, epe=3.93, lr=0.000024, samples/sec=12.9, sec/step=0.620, eta=10:27:10\n",
      "2018-09-06 20:54:54 Iter 39400 [Train]: loss=337.37, epe=4.15, lr=0.000022, samples/sec=12.9, sec/step=0.620, eta=10:26:12\n",
      "2018-09-06 20:56:00 Iter 39500 [Train]: loss=316.47, epe=3.86, lr=0.000020, samples/sec=12.9, sec/step=0.619, eta=10:24:19\n",
      "2018-09-06 20:57:06 Iter 39600 [Train]: loss=324.45, epe=3.97, lr=0.000018, samples/sec=12.9, sec/step=0.620, eta=10:24:01\n",
      "2018-09-06 20:58:11 Iter 39700 [Train]: loss=334.99, epe=4.08, lr=0.000016, samples/sec=12.9, sec/step=0.620, eta=10:22:38\n",
      "2018-09-06 20:59:17 Iter 39800 [Train]: loss=337.97, epe=4.13, lr=0.000014, samples/sec=12.9, sec/step=0.621, eta=10:22:46\n",
      "2018-09-06 21:00:23 Iter 39900 [Train]: loss=315.66, epe=3.85, lr=0.000012, samples/sec=12.9, sec/step=0.620, eta=10:20:46\n",
      "2018-09-06 21:01:29 Iter 40000 [Train]: loss=337.39, epe=4.14, lr=0.000010, samples/sec=12.9, sec/step=0.618, eta=10:17:58\n",
      "2018-09-06 21:01:50 Iter 40000 40000 [Val]: loss=298.23, epe=3.73\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-40000\n",
      "2018-09-06 21:03:06 Iter 40100 [Train]: loss=318.17, epe=3.90, lr=0.000011, samples/sec=13.0, sec/step=0.615, eta=10:14:26\n",
      "2018-09-06 21:04:12 Iter 40200 [Train]: loss=317.46, epe=3.85, lr=0.000012, samples/sec=12.9, sec/step=0.619, eta=10:16:33\n",
      "2018-09-06 21:05:18 Iter 40300 [Train]: loss=323.04, epe=3.95, lr=0.000013, samples/sec=12.9, sec/step=0.620, eta=10:16:58\n",
      "2018-09-06 21:06:23 Iter 40400 [Train]: loss=312.83, epe=3.82, lr=0.000014, samples/sec=12.9, sec/step=0.620, eta=10:15:41\n",
      "2018-09-06 21:07:29 Iter 40500 [Train]: loss=325.81, epe=3.97, lr=0.000015, samples/sec=12.9, sec/step=0.618, eta=10:12:39\n",
      "2018-09-06 21:08:35 Iter 40600 [Train]: loss=318.33, epe=3.90, lr=0.000016, samples/sec=12.9, sec/step=0.619, eta=10:12:25\n",
      "2018-09-06 21:09:40 Iter 40700 [Train]: loss=313.89, epe=3.85, lr=0.000017, samples/sec=12.9, sec/step=0.619, eta=10:11:56\n",
      "2018-09-06 21:10:46 Iter 40800 [Train]: loss=309.58, epe=3.78, lr=0.000018, samples/sec=13.0, sec/step=0.618, eta=10:09:18\n",
      "2018-09-06 21:11:51 Iter 40900 [Train]: loss=315.98, epe=3.84, lr=0.000019, samples/sec=12.9, sec/step=0.619, eta=10:10:04\n",
      "2018-09-06 21:12:57 Iter 41000 [Train]: loss=336.83, epe=4.10, lr=0.000020, samples/sec=12.9, sec/step=0.620, eta=10:09:16\n",
      "2018-09-06 21:13:19 Iter 41000 41000 [Val]: loss=297.38, epe=3.72\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-41000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-41000\n",
      "2018-09-06 21:14:35 Iter 41100 [Train]: loss=311.22, epe=3.81, lr=0.000021, samples/sec=13.0, sec/step=0.615, eta=10:03:36\n",
      "2018-09-06 21:15:41 Iter 41200 [Train]: loss=333.74, epe=4.10, lr=0.000022, samples/sec=12.9, sec/step=0.619, eta=10:06:31\n",
      "2018-09-06 21:16:46 Iter 41300 [Train]: loss=330.10, epe=4.04, lr=0.000023, samples/sec=12.9, sec/step=0.618, eta=10:04:50\n",
      "2018-09-06 21:17:52 Iter 41400 [Train]: loss=320.61, epe=3.92, lr=0.000024, samples/sec=12.9, sec/step=0.620, eta=10:05:31\n",
      "2018-09-06 21:18:58 Iter 41500 [Train]: loss=336.19, epe=4.12, lr=0.000025, samples/sec=12.9, sec/step=0.618, eta=10:02:39\n",
      "2018-09-06 21:20:03 Iter 41600 [Train]: loss=351.78, epe=4.33, lr=0.000026, samples/sec=12.9, sec/step=0.620, eta=10:03:42\n",
      "2018-09-06 21:21:09 Iter 41700 [Train]: loss=308.07, epe=3.75, lr=0.000027, samples/sec=12.9, sec/step=0.620, eta=10:02:04\n",
      "2018-09-06 21:22:15 Iter 41800 [Train]: loss=311.81, epe=3.80, lr=0.000028, samples/sec=12.9, sec/step=0.620, eta=10:01:00\n",
      "2018-09-06 21:23:21 Iter 41900 [Train]: loss=354.14, epe=4.35, lr=0.000029, samples/sec=12.9, sec/step=0.621, eta=10:00:54\n",
      "2018-09-06 21:24:27 Iter 42000 [Train]: loss=320.91, epe=3.92, lr=0.000029, samples/sec=12.9, sec/step=0.618, eta=9:57:46\n",
      "2018-09-06 21:24:48 Iter 42000 42000 [Val]: loss=304.22, epe=3.81\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-42000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-42000\n",
      "2018-09-06 21:26:07 Iter 42100 [Train]: loss=346.28, epe=4.27, lr=0.000030, samples/sec=13.0, sec/step=0.617, eta=9:55:46\n",
      "2018-09-06 21:27:12 Iter 42200 [Train]: loss=330.54, epe=4.06, lr=0.000031, samples/sec=12.9, sec/step=0.620, eta=9:57:08\n",
      "2018-09-06 21:28:18 Iter 42300 [Train]: loss=322.82, epe=3.96, lr=0.000032, samples/sec=12.9, sec/step=0.618, eta=9:54:28\n",
      "2018-09-06 21:29:24 Iter 42400 [Train]: loss=309.23, epe=3.76, lr=0.000033, samples/sec=12.9, sec/step=0.619, eta=9:53:47\n",
      "2018-09-06 21:30:30 Iter 42500 [Train]: loss=310.77, epe=3.79, lr=0.000034, samples/sec=12.9, sec/step=0.619, eta=9:52:58\n",
      "2018-09-06 21:31:36 Iter 42600 [Train]: loss=338.79, epe=4.16, lr=0.000035, samples/sec=12.9, sec/step=0.620, eta=9:52:49\n",
      "2018-09-06 21:32:40 Iter 42700 [Train]: loss=332.88, epe=4.07, lr=0.000036, samples/sec=13.2, sec/step=0.606, eta=9:38:50\n",
      "2018-09-06 21:33:44 Iter 42800 [Train]: loss=343.09, epe=4.23, lr=0.000037, samples/sec=13.2, sec/step=0.607, eta=9:38:38\n",
      "2018-09-06 21:34:48 Iter 42900 [Train]: loss=318.74, epe=3.91, lr=0.000038, samples/sec=13.2, sec/step=0.606, eta=9:36:29\n",
      "2018-09-06 21:35:52 Iter 43000 [Train]: loss=319.80, epe=3.90, lr=0.000039, samples/sec=13.2, sec/step=0.607, eta=9:36:28\n",
      "2018-09-06 21:36:13 Iter 43000 43000 [Val]: loss=299.32, epe=3.75\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-43000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-43000\n",
      "2018-09-06 21:37:26 Iter 43100 [Train]: loss=329.07, epe=4.03, lr=0.000040, samples/sec=13.2, sec/step=0.605, eta=9:33:18\n",
      "2018-09-06 21:38:31 Iter 43200 [Train]: loss=349.03, epe=4.31, lr=0.000041, samples/sec=13.1, sec/step=0.612, eta=9:39:08\n",
      "2018-09-06 21:39:36 Iter 43300 [Train]: loss=328.26, epe=4.03, lr=0.000042, samples/sec=13.0, sec/step=0.616, eta=9:41:54\n",
      "2018-09-06 21:40:41 Iter 43400 [Train]: loss=313.35, epe=3.84, lr=0.000043, samples/sec=13.0, sec/step=0.618, eta=9:42:44\n",
      "2018-09-06 21:41:46 Iter 43500 [Train]: loss=346.55, epe=4.23, lr=0.000044, samples/sec=13.0, sec/step=0.616, eta=9:40:31\n",
      "2018-09-06 21:42:52 Iter 43600 [Train]: loss=336.40, epe=4.13, lr=0.000045, samples/sec=12.9, sec/step=0.619, eta=9:42:13\n",
      "2018-09-06 21:43:57 Iter 43700 [Train]: loss=337.09, epe=4.16, lr=0.000046, samples/sec=13.0, sec/step=0.615, eta=9:37:11\n",
      "2018-09-06 21:45:02 Iter 43800 [Train]: loss=310.11, epe=3.78, lr=0.000047, samples/sec=12.9, sec/step=0.618, eta=9:38:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 21:46:07 Iter 43900 [Train]: loss=322.93, epe=3.93, lr=0.000048, samples/sec=13.0, sec/step=0.616, eta=9:35:57\n",
      "2018-09-06 21:47:12 Iter 44000 [Train]: loss=305.88, epe=3.72, lr=0.000049, samples/sec=13.0, sec/step=0.616, eta=9:34:41\n",
      "2018-09-06 21:47:33 Iter 44000 44000 [Val]: loss=301.08, epe=3.76\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-44000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-44000\n",
      "2018-09-06 21:48:49 Iter 44100 [Train]: loss=310.33, epe=3.79, lr=0.000050, samples/sec=13.1, sec/step=0.612, eta=9:30:36\n",
      "2018-09-06 21:49:54 Iter 44200 [Train]: loss=328.48, epe=4.02, lr=0.000051, samples/sec=13.0, sec/step=0.616, eta=9:32:38\n",
      "2018-09-06 21:50:59 Iter 44300 [Train]: loss=325.25, epe=3.97, lr=0.000052, samples/sec=13.0, sec/step=0.616, eta=9:31:55\n",
      "2018-09-06 21:52:04 Iter 44400 [Train]: loss=324.33, epe=3.97, lr=0.000053, samples/sec=12.9, sec/step=0.620, eta=9:34:28\n",
      "2018-09-06 21:53:09 Iter 44500 [Train]: loss=318.01, epe=3.89, lr=0.000054, samples/sec=13.2, sec/step=0.607, eta=9:21:30\n",
      "2018-09-06 21:54:13 Iter 44600 [Train]: loss=322.77, epe=3.97, lr=0.000055, samples/sec=13.1, sec/step=0.611, eta=9:24:07\n",
      "2018-09-06 21:55:18 Iter 44700 [Train]: loss=342.24, epe=4.19, lr=0.000056, samples/sec=13.1, sec/step=0.610, eta=9:22:30\n",
      "2018-09-06 21:56:23 Iter 44800 [Train]: loss=321.89, epe=3.95, lr=0.000057, samples/sec=13.1, sec/step=0.612, eta=9:22:41\n",
      "2018-09-06 21:57:28 Iter 44900 [Train]: loss=322.15, epe=3.98, lr=0.000058, samples/sec=13.1, sec/step=0.612, eta=9:22:14\n",
      "2018-09-06 21:58:33 Iter 45000 [Train]: loss=327.89, epe=4.04, lr=0.000059, samples/sec=13.1, sec/step=0.612, eta=9:20:38\n",
      "2018-09-06 21:58:54 Iter 45000 45000 [Val]: loss=302.05, epe=3.79\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-45000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-45000\n",
      "2018-09-06 22:00:09 Iter 45100 [Train]: loss=333.95, epe=4.11, lr=0.000060, samples/sec=13.2, sec/step=0.607, eta=9:15:02\n",
      "2018-09-06 22:01:14 Iter 45200 [Train]: loss=348.80, epe=4.28, lr=0.000061, samples/sec=13.1, sec/step=0.611, eta=9:18:13\n",
      "2018-09-06 22:02:19 Iter 45300 [Train]: loss=327.35, epe=4.03, lr=0.000062, samples/sec=13.1, sec/step=0.610, eta=9:15:54\n",
      "2018-09-06 22:03:24 Iter 45400 [Train]: loss=312.77, epe=3.83, lr=0.000063, samples/sec=13.0, sec/step=0.613, eta=9:18:02\n",
      "2018-09-06 22:04:29 Iter 45500 [Train]: loss=326.06, epe=3.99, lr=0.000064, samples/sec=13.1, sec/step=0.612, eta=9:15:48\n",
      "2018-09-06 22:05:34 Iter 45600 [Train]: loss=325.04, epe=3.95, lr=0.000065, samples/sec=13.1, sec/step=0.611, eta=9:14:06\n",
      "2018-09-06 22:06:38 Iter 45700 [Train]: loss=337.03, epe=4.15, lr=0.000066, samples/sec=13.2, sec/step=0.605, eta=9:07:32\n",
      "2018-09-06 22:07:42 Iter 45800 [Train]: loss=312.93, epe=3.81, lr=0.000067, samples/sec=13.2, sec/step=0.605, eta=9:06:09\n",
      "2018-09-06 22:08:46 Iter 45900 [Train]: loss=324.52, epe=3.97, lr=0.000068, samples/sec=13.2, sec/step=0.605, eta=9:05:11\n",
      "2018-09-06 22:09:50 Iter 46000 [Train]: loss=348.35, epe=4.28, lr=0.000068, samples/sec=13.2, sec/step=0.605, eta=9:04:06\n",
      "2018-09-06 22:10:11 Iter 46000 46000 [Val]: loss=300.29, epe=3.76\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-46000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-46000\n",
      "2018-09-06 22:11:23 Iter 46100 [Train]: loss=350.11, epe=4.30, lr=0.000069, samples/sec=13.3, sec/step=0.603, eta=9:01:56\n",
      "2018-09-06 22:12:27 Iter 46200 [Train]: loss=309.84, epe=3.79, lr=0.000070, samples/sec=13.2, sec/step=0.605, eta=9:02:30\n",
      "2018-09-06 22:13:31 Iter 46300 [Train]: loss=316.34, epe=3.88, lr=0.000071, samples/sec=13.2, sec/step=0.604, eta=9:00:33\n",
      "2018-09-06 22:14:35 Iter 46400 [Train]: loss=333.96, epe=4.10, lr=0.000072, samples/sec=13.2, sec/step=0.604, eta=8:59:33\n",
      "2018-09-06 22:15:39 Iter 46500 [Train]: loss=334.23, epe=4.09, lr=0.000073, samples/sec=13.2, sec/step=0.606, eta=8:59:56\n",
      "2018-09-06 22:16:43 Iter 46600 [Train]: loss=323.21, epe=3.94, lr=0.000074, samples/sec=13.2, sec/step=0.605, eta=8:58:09\n",
      "2018-09-06 22:17:47 Iter 46700 [Train]: loss=332.39, epe=4.07, lr=0.000075, samples/sec=13.2, sec/step=0.605, eta=8:57:52\n",
      "2018-09-06 22:18:51 Iter 46800 [Train]: loss=332.37, epe=4.06, lr=0.000076, samples/sec=13.2, sec/step=0.604, eta=8:55:31\n",
      "2018-09-06 22:19:55 Iter 46900 [Train]: loss=323.86, epe=3.97, lr=0.000077, samples/sec=13.2, sec/step=0.605, eta=8:55:14\n",
      "2018-09-06 22:20:59 Iter 47000 [Train]: loss=341.58, epe=4.22, lr=0.000078, samples/sec=13.2, sec/step=0.605, eta=8:54:06\n",
      "2018-09-06 22:21:20 Iter 47000 47000 [Val]: loss=307.49, epe=3.86\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-47000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-47000\n",
      "2018-09-06 22:22:32 Iter 47100 [Train]: loss=310.97, epe=3.82, lr=0.000079, samples/sec=13.3, sec/step=0.602, eta=8:50:33\n",
      "2018-09-06 22:23:36 Iter 47200 [Train]: loss=325.32, epe=3.96, lr=0.000080, samples/sec=13.2, sec/step=0.604, eta=8:51:51\n",
      "2018-09-06 22:24:40 Iter 47300 [Train]: loss=356.23, epe=4.39, lr=0.000081, samples/sec=13.3, sec/step=0.604, eta=8:50:07\n",
      "2018-09-06 22:25:44 Iter 47400 [Train]: loss=310.92, epe=3.80, lr=0.000082, samples/sec=13.2, sec/step=0.605, eta=8:50:44\n",
      "2018-09-06 22:26:48 Iter 47500 [Train]: loss=341.96, epe=4.19, lr=0.000083, samples/sec=13.3, sec/step=0.603, eta=8:47:20\n",
      "2018-09-06 22:27:52 Iter 47600 [Train]: loss=330.99, epe=4.04, lr=0.000084, samples/sec=13.2, sec/step=0.605, eta=8:48:02\n",
      "2018-09-06 22:28:56 Iter 47700 [Train]: loss=336.73, epe=4.14, lr=0.000085, samples/sec=13.2, sec/step=0.604, eta=8:46:43\n",
      "2018-09-06 22:30:00 Iter 47800 [Train]: loss=339.70, epe=4.19, lr=0.000086, samples/sec=13.2, sec/step=0.605, eta=8:46:40\n",
      "2018-09-06 22:31:04 Iter 47900 [Train]: loss=336.91, epe=4.16, lr=0.000087, samples/sec=13.2, sec/step=0.605, eta=8:45:17\n",
      "2018-09-06 22:32:08 Iter 48000 [Train]: loss=340.51, epe=4.20, lr=0.000088, samples/sec=13.2, sec/step=0.606, eta=8:45:06\n",
      "2018-09-06 22:32:29 Iter 48000 48000 [Val]: loss=313.01, epe=3.91\n",
      "Saving model...\n",
      "... model saved in None\n",
      "2018-09-06 22:33:37 Iter 48100 [Train]: loss=346.76, epe=4.27, lr=0.000089, samples/sec=13.3, sec/step=0.603, eta=8:41:59\n",
      "2018-09-06 22:34:41 Iter 48200 [Train]: loss=319.07, epe=3.89, lr=0.000090, samples/sec=13.3, sec/step=0.603, eta=8:41:00\n",
      "2018-09-06 22:35:45 Iter 48300 [Train]: loss=334.90, epe=4.11, lr=0.000091, samples/sec=13.2, sec/step=0.605, eta=8:41:19\n",
      "2018-09-06 22:36:49 Iter 48400 [Train]: loss=335.89, epe=4.15, lr=0.000092, samples/sec=13.3, sec/step=0.604, eta=8:39:02\n",
      "2018-09-06 22:37:53 Iter 48500 [Train]: loss=332.35, epe=4.09, lr=0.000093, samples/sec=13.2, sec/step=0.605, eta=8:39:10\n",
      "2018-09-06 22:38:57 Iter 48600 [Train]: loss=320.36, epe=3.94, lr=0.000094, samples/sec=13.2, sec/step=0.605, eta=8:38:31\n",
      "2018-09-06 22:40:01 Iter 48700 [Train]: loss=348.11, epe=4.30, lr=0.000095, samples/sec=13.2, sec/step=0.605, eta=8:37:25\n",
      "2018-09-06 22:41:05 Iter 48800 [Train]: loss=320.47, epe=3.94, lr=0.000096, samples/sec=13.3, sec/step=0.604, eta=8:35:12\n",
      "2018-09-06 22:42:09 Iter 48900 [Train]: loss=313.45, epe=3.83, lr=0.000097, samples/sec=13.2, sec/step=0.605, eta=8:35:29\n",
      "2018-09-06 22:43:13 Iter 49000 [Train]: loss=323.52, epe=3.96, lr=0.000098, samples/sec=13.2, sec/step=0.605, eta=8:33:58\n",
      "2018-09-06 22:43:33 Iter 49000 49000 [Val]: loss=299.39, epe=3.75\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-49000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-49000\n",
      "2018-09-06 22:44:46 Iter 49100 [Train]: loss=349.72, epe=4.31, lr=0.000099, samples/sec=13.3, sec/step=0.601, eta=8:30:08\n",
      "2018-09-06 22:45:50 Iter 49200 [Train]: loss=320.36, epe=3.93, lr=0.000100, samples/sec=13.2, sec/step=0.605, eta=8:32:36\n",
      "2018-09-06 22:46:54 Iter 49300 [Train]: loss=325.56, epe=4.00, lr=0.000101, samples/sec=13.3, sec/step=0.603, eta=8:29:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 22:47:58 Iter 49400 [Train]: loss=328.09, epe=4.04, lr=0.000102, samples/sec=13.3, sec/step=0.604, eta=8:29:06\n",
      "2018-09-06 22:49:02 Iter 49500 [Train]: loss=334.15, epe=4.09, lr=0.000103, samples/sec=13.2, sec/step=0.605, eta=8:29:35\n",
      "2018-09-06 22:50:06 Iter 49600 [Train]: loss=344.96, epe=4.26, lr=0.000104, samples/sec=13.2, sec/step=0.605, eta=8:28:04\n",
      "2018-09-06 22:51:10 Iter 49700 [Train]: loss=335.74, epe=4.13, lr=0.000105, samples/sec=13.2, sec/step=0.605, eta=8:27:34\n",
      "2018-09-06 22:52:14 Iter 49800 [Train]: loss=343.74, epe=4.26, lr=0.000106, samples/sec=13.2, sec/step=0.604, eta=8:25:35\n",
      "2018-09-06 22:53:18 Iter 49900 [Train]: loss=348.84, epe=4.32, lr=0.000107, samples/sec=13.3, sec/step=0.604, eta=8:24:09\n",
      "2018-09-06 22:54:22 Iter 50000 [Train]: loss=336.24, epe=4.12, lr=0.000108, samples/sec=13.3, sec/step=0.602, eta=8:21:42\n",
      "2018-09-06 22:54:43 Iter 50000 50000 [Val]: loss=306.56, epe=3.85\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-50000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-50000\n",
      "2018-09-06 22:55:56 Iter 50100 [Train]: loss=335.11, epe=4.14, lr=0.000107, samples/sec=13.3, sec/step=0.602, eta=8:20:49\n",
      "2018-09-06 22:56:59 Iter 50200 [Train]: loss=333.03, epe=4.10, lr=0.000106, samples/sec=13.3, sec/step=0.603, eta=8:20:12\n",
      "2018-09-06 22:58:03 Iter 50300 [Train]: loss=334.69, epe=4.12, lr=0.000105, samples/sec=13.2, sec/step=0.604, eta=8:20:18\n",
      "2018-09-06 22:59:07 Iter 50400 [Train]: loss=320.24, epe=3.94, lr=0.000104, samples/sec=13.3, sec/step=0.603, eta=8:18:26\n",
      "2018-09-06 23:00:11 Iter 50500 [Train]: loss=353.23, epe=4.35, lr=0.000103, samples/sec=13.3, sec/step=0.602, eta=8:16:50\n",
      "2018-09-06 23:01:15 Iter 50600 [Train]: loss=330.41, epe=4.06, lr=0.000102, samples/sec=13.3, sec/step=0.602, eta=8:15:58\n",
      "2018-09-06 23:02:19 Iter 50700 [Train]: loss=313.25, epe=3.83, lr=0.000101, samples/sec=13.2, sec/step=0.604, eta=8:16:27\n",
      "2018-09-06 23:03:23 Iter 50800 [Train]: loss=341.07, epe=4.21, lr=0.000100, samples/sec=13.2, sec/step=0.604, eta=8:15:34\n",
      "2018-09-06 23:04:27 Iter 50900 [Train]: loss=305.77, epe=3.74, lr=0.000099, samples/sec=13.2, sec/step=0.605, eta=8:15:03\n",
      "2018-09-06 23:05:31 Iter 51000 [Train]: loss=351.19, epe=4.33, lr=0.000098, samples/sec=13.3, sec/step=0.604, eta=8:13:03\n",
      "2018-09-06 23:05:51 Iter 51000 51000 [Val]: loss=300.60, epe=3.75\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-51000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-51000\n",
      "2018-09-06 23:07:04 Iter 51100 [Train]: loss=316.46, epe=3.87, lr=0.000097, samples/sec=13.3, sec/step=0.602, eta=8:10:24\n",
      "2018-09-06 23:08:08 Iter 51200 [Train]: loss=323.85, epe=3.97, lr=0.000096, samples/sec=13.2, sec/step=0.604, eta=8:11:25\n",
      "2018-09-06 23:09:12 Iter 51300 [Train]: loss=342.47, epe=4.21, lr=0.000095, samples/sec=13.2, sec/step=0.604, eta=8:10:20\n",
      "2018-09-06 23:10:15 Iter 51400 [Train]: loss=335.65, epe=4.10, lr=0.000094, samples/sec=13.3, sec/step=0.603, eta=8:08:46\n",
      "2018-09-06 23:11:19 Iter 51500 [Train]: loss=312.44, epe=3.80, lr=0.000093, samples/sec=13.3, sec/step=0.604, eta=8:07:52\n",
      "2018-09-06 23:12:23 Iter 51600 [Train]: loss=324.29, epe=3.98, lr=0.000092, samples/sec=13.2, sec/step=0.605, eta=8:07:42\n",
      "2018-09-06 23:13:27 Iter 51700 [Train]: loss=315.26, epe=3.85, lr=0.000091, samples/sec=13.3, sec/step=0.603, eta=8:05:41\n",
      "2018-09-06 23:14:31 Iter 51800 [Train]: loss=334.87, epe=4.13, lr=0.000090, samples/sec=13.3, sec/step=0.603, eta=8:04:41\n",
      "2018-09-06 23:15:35 Iter 51900 [Train]: loss=332.64, epe=4.08, lr=0.000089, samples/sec=13.3, sec/step=0.602, eta=8:02:47\n",
      "2018-09-06 23:16:39 Iter 52000 [Train]: loss=327.77, epe=4.02, lr=0.000088, samples/sec=13.3, sec/step=0.604, eta=8:02:52\n",
      "2018-09-06 23:17:00 Iter 52000 52000 [Val]: loss=304.82, epe=3.82\n",
      "Saving model...\n",
      "... model saved in None\n",
      "2018-09-06 23:18:07 Iter 52100 [Train]: loss=338.28, epe=4.16, lr=0.000087, samples/sec=13.3, sec/step=0.602, eta=8:00:46\n",
      "2018-09-06 23:19:11 Iter 52200 [Train]: loss=305.76, epe=3.72, lr=0.000086, samples/sec=13.2, sec/step=0.604, eta=8:01:06\n",
      "2018-09-06 23:20:15 Iter 52300 [Train]: loss=334.30, epe=4.10, lr=0.000085, samples/sec=13.3, sec/step=0.603, eta=7:59:44\n",
      "2018-09-06 23:21:19 Iter 52400 [Train]: loss=313.34, epe=3.83, lr=0.000084, samples/sec=13.3, sec/step=0.604, eta=7:58:55\n",
      "2018-09-06 23:22:23 Iter 52500 [Train]: loss=347.07, epe=4.27, lr=0.000083, samples/sec=13.2, sec/step=0.604, eta=7:58:14\n",
      "2018-09-06 23:23:27 Iter 52600 [Train]: loss=317.67, epe=3.87, lr=0.000082, samples/sec=13.2, sec/step=0.606, eta=7:58:31\n",
      "2018-09-06 23:24:31 Iter 52700 [Train]: loss=318.18, epe=3.90, lr=0.000081, samples/sec=13.3, sec/step=0.602, eta=7:54:42\n",
      "2018-09-06 23:25:34 Iter 52800 [Train]: loss=325.45, epe=3.98, lr=0.000080, samples/sec=13.3, sec/step=0.603, eta=7:54:07\n",
      "2018-09-06 23:26:38 Iter 52900 [Train]: loss=305.92, epe=3.71, lr=0.000079, samples/sec=13.3, sec/step=0.602, eta=7:52:29\n",
      "2018-09-06 23:27:42 Iter 53000 [Train]: loss=328.60, epe=4.03, lr=0.000078, samples/sec=13.2, sec/step=0.604, eta=7:53:07\n",
      "2018-09-06 23:28:03 Iter 53000 53000 [Val]: loss=292.56, epe=3.65\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-53000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-53000\n",
      "2018-09-06 23:29:15 Iter 53100 [Train]: loss=312.09, epe=3.81, lr=0.000077, samples/sec=13.3, sec/step=0.600, eta=7:49:14\n",
      "2018-09-06 23:30:19 Iter 53200 [Train]: loss=319.25, epe=3.90, lr=0.000076, samples/sec=13.3, sec/step=0.603, eta=7:50:14\n",
      "2018-09-06 23:31:23 Iter 53300 [Train]: loss=303.16, epe=3.67, lr=0.000075, samples/sec=13.2, sec/step=0.605, eta=7:50:33\n",
      "2018-09-06 23:32:27 Iter 53400 [Train]: loss=309.17, epe=3.76, lr=0.000074, samples/sec=13.3, sec/step=0.603, eta=7:48:10\n",
      "2018-09-06 23:33:31 Iter 53500 [Train]: loss=326.10, epe=3.97, lr=0.000073, samples/sec=13.3, sec/step=0.602, eta=7:46:32\n",
      "2018-09-06 23:34:35 Iter 53600 [Train]: loss=309.53, epe=3.78, lr=0.000072, samples/sec=13.3, sec/step=0.602, eta=7:45:35\n",
      "2018-09-06 23:35:38 Iter 53700 [Train]: loss=321.65, epe=3.92, lr=0.000071, samples/sec=13.3, sec/step=0.604, eta=7:45:53\n",
      "2018-09-06 23:36:42 Iter 53800 [Train]: loss=324.50, epe=3.95, lr=0.000070, samples/sec=13.3, sec/step=0.603, eta=7:44:41\n",
      "2018-09-06 23:37:46 Iter 53900 [Train]: loss=309.99, epe=3.78, lr=0.000069, samples/sec=13.2, sec/step=0.604, eta=7:44:18\n",
      "2018-09-06 23:38:50 Iter 54000 [Train]: loss=338.75, epe=4.16, lr=0.000068, samples/sec=13.3, sec/step=0.602, eta=7:41:44\n",
      "2018-09-06 23:39:11 Iter 54000 54000 [Val]: loss=288.92, epe=3.59\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-54000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-54000\n",
      "2018-09-06 23:40:23 Iter 54100 [Train]: loss=332.75, epe=4.06, lr=0.000068, samples/sec=13.3, sec/step=0.600, eta=7:39:13\n",
      "2018-09-06 23:41:27 Iter 54200 [Train]: loss=313.62, epe=3.82, lr=0.000067, samples/sec=13.3, sec/step=0.602, eta=7:39:52\n",
      "2018-09-06 23:42:31 Iter 54300 [Train]: loss=314.16, epe=3.84, lr=0.000066, samples/sec=13.3, sec/step=0.602, eta=7:38:20\n",
      "2018-09-06 23:43:35 Iter 54400 [Train]: loss=319.30, epe=3.89, lr=0.000065, samples/sec=13.3, sec/step=0.602, eta=7:37:27\n",
      "2018-09-06 23:44:39 Iter 54500 [Train]: loss=316.27, epe=3.86, lr=0.000064, samples/sec=13.3, sec/step=0.602, eta=7:36:51\n",
      "2018-09-06 23:45:43 Iter 54600 [Train]: loss=325.23, epe=4.00, lr=0.000063, samples/sec=13.3, sec/step=0.603, eta=7:36:10\n",
      "2018-09-06 23:46:46 Iter 54700 [Train]: loss=318.89, epe=3.87, lr=0.000062, samples/sec=13.3, sec/step=0.603, eta=7:34:59\n",
      "2018-09-06 23:47:50 Iter 54800 [Train]: loss=314.06, epe=3.81, lr=0.000061, samples/sec=13.3, sec/step=0.603, eta=7:34:37\n",
      "2018-09-06 23:48:54 Iter 54900 [Train]: loss=324.28, epe=3.98, lr=0.000060, samples/sec=13.3, sec/step=0.602, eta=7:32:38\n",
      "2018-09-06 23:49:58 Iter 55000 [Train]: loss=310.95, epe=3.78, lr=0.000059, samples/sec=13.3, sec/step=0.603, eta=7:32:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-06 23:50:19 Iter 55000 55000 [Val]: loss=293.75, epe=3.66\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-55000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-55000\n",
      "2018-09-06 23:51:34 Iter 55100 [Train]: loss=310.31, epe=3.78, lr=0.000058, samples/sec=13.4, sec/step=0.597, eta=7:27:02\n",
      "2018-09-06 23:52:37 Iter 55200 [Train]: loss=317.77, epe=3.88, lr=0.000057, samples/sec=13.3, sec/step=0.603, eta=7:30:09\n",
      "2018-09-06 23:53:41 Iter 55300 [Train]: loss=323.05, epe=3.94, lr=0.000056, samples/sec=13.3, sec/step=0.602, eta=7:28:33\n",
      "2018-09-06 23:54:45 Iter 55400 [Train]: loss=321.59, epe=3.92, lr=0.000055, samples/sec=13.3, sec/step=0.602, eta=7:27:37\n",
      "2018-09-06 23:55:49 Iter 55500 [Train]: loss=317.69, epe=3.86, lr=0.000054, samples/sec=13.3, sec/step=0.603, eta=7:26:54\n",
      "2018-09-06 23:56:53 Iter 55600 [Train]: loss=300.79, epe=3.63, lr=0.000053, samples/sec=13.3, sec/step=0.604, eta=7:26:36\n",
      "2018-09-06 23:57:57 Iter 55700 [Train]: loss=326.05, epe=4.01, lr=0.000052, samples/sec=13.3, sec/step=0.604, eta=7:25:38\n",
      "2018-09-06 23:59:00 Iter 55800 [Train]: loss=292.95, epe=3.55, lr=0.000051, samples/sec=13.3, sec/step=0.603, eta=7:24:00\n",
      "2018-09-07 00:00:04 Iter 55900 [Train]: loss=312.46, epe=3.79, lr=0.000050, samples/sec=13.3, sec/step=0.603, eta=7:23:23\n",
      "2018-09-07 00:01:08 Iter 56000 [Train]: loss=304.31, epe=3.70, lr=0.000049, samples/sec=13.3, sec/step=0.602, eta=7:21:28\n",
      "2018-09-07 00:01:29 Iter 56000 56000 [Val]: loss=286.82, epe=3.57\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-56000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-56000\n",
      "2018-09-07 00:02:41 Iter 56100 [Train]: loss=309.90, epe=3.75, lr=0.000048, samples/sec=13.3, sec/step=0.601, eta=7:19:48\n",
      "2018-09-07 00:03:45 Iter 56200 [Train]: loss=308.74, epe=3.74, lr=0.000047, samples/sec=13.3, sec/step=0.602, eta=7:19:12\n",
      "2018-09-07 00:04:49 Iter 56300 [Train]: loss=322.83, epe=3.93, lr=0.000046, samples/sec=13.3, sec/step=0.603, eta=7:19:27\n",
      "2018-09-07 00:05:53 Iter 56400 [Train]: loss=318.29, epe=3.87, lr=0.000045, samples/sec=13.3, sec/step=0.603, eta=7:18:09\n",
      "2018-09-07 00:06:57 Iter 56500 [Train]: loss=298.14, epe=3.60, lr=0.000044, samples/sec=13.3, sec/step=0.601, eta=7:15:32\n",
      "2018-09-07 00:08:01 Iter 56600 [Train]: loss=310.29, epe=3.78, lr=0.000043, samples/sec=13.3, sec/step=0.603, eta=7:16:10\n",
      "2018-09-07 00:09:04 Iter 56700 [Train]: loss=308.79, epe=3.77, lr=0.000042, samples/sec=13.2, sec/step=0.605, eta=7:16:25\n",
      "2018-09-07 00:10:08 Iter 56800 [Train]: loss=287.47, epe=3.50, lr=0.000041, samples/sec=13.2, sec/step=0.604, eta=7:15:05\n",
      "2018-09-07 00:11:12 Iter 56900 [Train]: loss=322.74, epe=3.90, lr=0.000040, samples/sec=13.2, sec/step=0.604, eta=7:14:12\n",
      "2018-09-07 00:12:16 Iter 57000 [Train]: loss=305.41, epe=3.69, lr=0.000039, samples/sec=13.2, sec/step=0.604, eta=7:12:53\n",
      "2018-09-07 00:12:37 Iter 57000 57000 [Val]: loss=285.29, epe=3.54\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-57000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-57000\n",
      "2018-09-07 00:13:50 Iter 57100 [Train]: loss=303.37, epe=3.68, lr=0.000038, samples/sec=13.3, sec/step=0.601, eta=7:09:56\n",
      "2018-09-07 00:14:54 Iter 57200 [Train]: loss=303.11, epe=3.69, lr=0.000037, samples/sec=13.2, sec/step=0.605, eta=7:11:18\n",
      "2018-09-07 00:15:58 Iter 57300 [Train]: loss=294.16, epe=3.55, lr=0.000036, samples/sec=13.2, sec/step=0.604, eta=7:10:03\n",
      "2018-09-07 00:17:02 Iter 57400 [Train]: loss=296.53, epe=3.57, lr=0.000035, samples/sec=13.3, sec/step=0.603, eta=7:07:56\n",
      "2018-09-07 00:18:06 Iter 57500 [Train]: loss=326.21, epe=3.97, lr=0.000034, samples/sec=13.2, sec/step=0.604, eta=7:07:46\n",
      "2018-09-07 00:19:10 Iter 57600 [Train]: loss=295.02, epe=3.56, lr=0.000033, samples/sec=13.3, sec/step=0.603, eta=7:06:25\n",
      "2018-09-07 00:20:14 Iter 57700 [Train]: loss=315.33, epe=3.82, lr=0.000032, samples/sec=13.2, sec/step=0.604, eta=7:05:44\n",
      "2018-09-07 00:21:18 Iter 57800 [Train]: loss=289.36, epe=3.49, lr=0.000031, samples/sec=13.3, sec/step=0.602, eta=7:03:45\n",
      "2018-09-07 00:22:22 Iter 57900 [Train]: loss=310.79, epe=3.78, lr=0.000030, samples/sec=13.2, sec/step=0.604, eta=7:04:07\n",
      "2018-09-07 00:23:26 Iter 58000 [Train]: loss=292.18, epe=3.53, lr=0.000030, samples/sec=13.3, sec/step=0.603, eta=7:02:01\n",
      "2018-09-07 00:23:46 Iter 58000 58000 [Val]: loss=279.22, epe=3.46\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-58000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-58000\n",
      "2018-09-07 00:24:59 Iter 58100 [Train]: loss=301.08, epe=3.65, lr=0.000029, samples/sec=13.3, sec/step=0.601, eta=6:59:46\n",
      "2018-09-07 00:26:03 Iter 58200 [Train]: loss=301.68, epe=3.63, lr=0.000028, samples/sec=13.3, sec/step=0.603, eta=7:00:05\n",
      "2018-09-07 00:27:07 Iter 58300 [Train]: loss=313.30, epe=3.79, lr=0.000027, samples/sec=13.3, sec/step=0.604, eta=6:59:31\n",
      "2018-09-07 00:28:11 Iter 58400 [Train]: loss=305.36, epe=3.71, lr=0.000026, samples/sec=13.3, sec/step=0.602, eta=6:57:43\n",
      "2018-09-07 00:29:15 Iter 58500 [Train]: loss=282.47, epe=3.41, lr=0.000025, samples/sec=13.3, sec/step=0.603, eta=6:57:19\n",
      "2018-09-07 00:30:19 Iter 58600 [Train]: loss=295.90, epe=3.59, lr=0.000024, samples/sec=13.3, sec/step=0.604, eta=6:56:36\n",
      "2018-09-07 00:31:22 Iter 58700 [Train]: loss=288.79, epe=3.48, lr=0.000023, samples/sec=13.2, sec/step=0.605, eta=6:56:14\n",
      "2018-09-07 00:32:26 Iter 58800 [Train]: loss=306.04, epe=3.73, lr=0.000022, samples/sec=13.3, sec/step=0.603, eta=6:53:52\n",
      "2018-09-07 00:33:30 Iter 58900 [Train]: loss=328.33, epe=4.01, lr=0.000021, samples/sec=13.3, sec/step=0.604, eta=6:53:29\n",
      "2018-09-07 00:34:34 Iter 59000 [Train]: loss=305.98, epe=3.72, lr=0.000020, samples/sec=13.3, sec/step=0.604, eta=6:52:33\n",
      "2018-09-07 00:34:55 Iter 59000 59000 [Val]: loss=279.11, epe=3.46\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-59000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-59000\n",
      "2018-09-07 00:36:08 Iter 59100 [Train]: loss=293.06, epe=3.54, lr=0.000019, samples/sec=13.3, sec/step=0.600, eta=6:48:50\n",
      "2018-09-07 00:37:12 Iter 59200 [Train]: loss=300.32, epe=3.62, lr=0.000018, samples/sec=13.3, sec/step=0.603, eta=6:50:09\n",
      "2018-09-07 00:38:16 Iter 59300 [Train]: loss=310.49, epe=3.75, lr=0.000017, samples/sec=13.3, sec/step=0.604, eta=6:49:24\n",
      "2018-09-07 00:39:19 Iter 59400 [Train]: loss=291.19, epe=3.52, lr=0.000016, samples/sec=13.2, sec/step=0.604, eta=6:48:46\n",
      "2018-09-07 00:40:23 Iter 59500 [Train]: loss=315.24, epe=3.83, lr=0.000015, samples/sec=13.2, sec/step=0.604, eta=6:47:39\n",
      "2018-09-07 00:41:27 Iter 59600 [Train]: loss=288.08, epe=3.49, lr=0.000014, samples/sec=13.2, sec/step=0.604, eta=6:46:38\n",
      "2018-09-07 00:42:31 Iter 59700 [Train]: loss=298.20, epe=3.59, lr=0.000013, samples/sec=13.2, sec/step=0.605, eta=6:46:14\n",
      "2018-09-07 00:43:35 Iter 59800 [Train]: loss=305.10, epe=3.67, lr=0.000012, samples/sec=13.2, sec/step=0.604, eta=6:44:38\n",
      "2018-09-07 00:44:39 Iter 59900 [Train]: loss=315.65, epe=3.84, lr=0.000011, samples/sec=13.2, sec/step=0.605, eta=6:44:13\n",
      "2018-09-07 00:45:43 Iter 60000 [Train]: loss=306.12, epe=3.69, lr=0.000010, samples/sec=13.2, sec/step=0.604, eta=6:42:39\n",
      "2018-09-07 00:46:04 Iter 60000 60000 [Val]: loss=277.54, epe=3.43\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-60000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-60000\n",
      "2018-09-07 00:47:16 Iter 60100 [Train]: loss=277.39, epe=3.33, lr=0.000010, samples/sec=13.4, sec/step=0.599, eta=6:38:30\n",
      "2018-09-07 00:48:20 Iter 60200 [Train]: loss=313.06, epe=3.80, lr=0.000011, samples/sec=13.2, sec/step=0.604, eta=6:40:51\n",
      "2018-09-07 00:49:24 Iter 60300 [Train]: loss=289.54, epe=3.46, lr=0.000011, samples/sec=13.3, sec/step=0.603, eta=6:38:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 00:50:28 Iter 60400 [Train]: loss=310.86, epe=3.75, lr=0.000012, samples/sec=13.3, sec/step=0.603, eta=6:37:57\n",
      "2018-09-07 00:51:32 Iter 60500 [Train]: loss=293.98, epe=3.53, lr=0.000012, samples/sec=13.3, sec/step=0.603, eta=6:37:18\n",
      "2018-09-07 00:52:36 Iter 60600 [Train]: loss=295.16, epe=3.56, lr=0.000013, samples/sec=13.3, sec/step=0.603, eta=6:35:54\n",
      "2018-09-07 00:53:40 Iter 60700 [Train]: loss=296.55, epe=3.58, lr=0.000013, samples/sec=13.3, sec/step=0.603, eta=6:35:14\n",
      "2018-09-07 00:54:44 Iter 60800 [Train]: loss=293.00, epe=3.52, lr=0.000014, samples/sec=13.3, sec/step=0.603, eta=6:34:11\n",
      "2018-09-07 00:55:48 Iter 60900 [Train]: loss=291.06, epe=3.51, lr=0.000014, samples/sec=13.2, sec/step=0.604, eta=6:33:49\n",
      "2018-09-07 00:56:52 Iter 61000 [Train]: loss=285.51, epe=3.44, lr=0.000015, samples/sec=13.3, sec/step=0.602, eta=6:31:16\n",
      "2018-09-07 00:57:12 Iter 61000 61000 [Val]: loss=276.98, epe=3.43\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-61000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-61000\n",
      "2018-09-07 00:58:25 Iter 61100 [Train]: loss=309.46, epe=3.76, lr=0.000015, samples/sec=13.3, sec/step=0.602, eta=6:30:07\n",
      "2018-09-07 00:59:29 Iter 61200 [Train]: loss=306.62, epe=3.71, lr=0.000016, samples/sec=13.3, sec/step=0.603, eta=6:30:08\n",
      "2018-09-07 01:00:33 Iter 61300 [Train]: loss=292.55, epe=3.54, lr=0.000016, samples/sec=13.3, sec/step=0.602, eta=6:28:27\n",
      "2018-09-07 01:01:37 Iter 61400 [Train]: loss=299.46, epe=3.61, lr=0.000017, samples/sec=13.2, sec/step=0.604, eta=6:28:50\n",
      "2018-09-07 01:02:41 Iter 61500 [Train]: loss=291.32, epe=3.50, lr=0.000017, samples/sec=13.3, sec/step=0.604, eta=6:27:15\n",
      "2018-09-07 01:03:45 Iter 61600 [Train]: loss=282.28, epe=3.39, lr=0.000018, samples/sec=13.3, sec/step=0.603, eta=6:25:44\n",
      "2018-09-07 01:04:48 Iter 61700 [Train]: loss=305.53, epe=3.70, lr=0.000018, samples/sec=13.2, sec/step=0.604, eta=6:25:34\n",
      "2018-09-07 01:05:52 Iter 61800 [Train]: loss=302.80, epe=3.67, lr=0.000019, samples/sec=13.2, sec/step=0.604, eta=6:24:50\n",
      "2018-09-07 01:06:56 Iter 61900 [Train]: loss=292.12, epe=3.54, lr=0.000019, samples/sec=13.2, sec/step=0.604, eta=6:23:26\n",
      "2018-09-07 01:08:00 Iter 62000 [Train]: loss=314.04, epe=3.83, lr=0.000020, samples/sec=13.3, sec/step=0.604, eta=6:22:19\n",
      "2018-09-07 01:08:21 Iter 62000 62000 [Val]: loss=280.97, epe=3.48\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-62000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-62000\n",
      "2018-09-07 01:09:34 Iter 62100 [Train]: loss=292.35, epe=3.52, lr=0.000020, samples/sec=13.4, sec/step=0.598, eta=6:17:50\n",
      "2018-09-07 01:10:38 Iter 62200 [Train]: loss=300.21, epe=3.65, lr=0.000021, samples/sec=13.3, sec/step=0.602, eta=6:19:32\n",
      "2018-09-07 01:11:42 Iter 62300 [Train]: loss=291.20, epe=3.53, lr=0.000021, samples/sec=13.3, sec/step=0.603, eta=6:19:04\n",
      "2018-09-07 01:12:45 Iter 62400 [Train]: loss=282.83, epe=3.41, lr=0.000022, samples/sec=13.3, sec/step=0.602, eta=6:17:11\n",
      "2018-09-07 01:13:49 Iter 62500 [Train]: loss=315.17, epe=3.84, lr=0.000022, samples/sec=13.3, sec/step=0.602, eta=6:16:32\n",
      "2018-09-07 01:14:53 Iter 62600 [Train]: loss=313.21, epe=3.80, lr=0.000023, samples/sec=13.3, sec/step=0.603, eta=6:15:54\n",
      "2018-09-07 01:15:57 Iter 62700 [Train]: loss=278.49, epe=3.33, lr=0.000023, samples/sec=13.3, sec/step=0.603, eta=6:14:38\n",
      "2018-09-07 01:17:01 Iter 62800 [Train]: loss=296.66, epe=3.54, lr=0.000024, samples/sec=13.2, sec/step=0.605, eta=6:15:08\n",
      "2018-09-07 01:18:05 Iter 62900 [Train]: loss=297.68, epe=3.60, lr=0.000024, samples/sec=13.3, sec/step=0.602, eta=6:12:00\n",
      "2018-09-07 01:19:08 Iter 63000 [Train]: loss=300.90, epe=3.65, lr=0.000025, samples/sec=13.3, sec/step=0.602, eta=6:11:22\n",
      "2018-09-07 01:19:29 Iter 63000 63000 [Val]: loss=276.61, epe=3.42\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-63000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-63000\n",
      "2018-09-07 01:20:42 Iter 63100 [Train]: loss=301.36, epe=3.66, lr=0.000025, samples/sec=13.3, sec/step=0.599, eta=6:08:40\n",
      "2018-09-07 01:21:46 Iter 63200 [Train]: loss=303.26, epe=3.67, lr=0.000026, samples/sec=13.3, sec/step=0.602, eta=6:09:24\n",
      "2018-09-07 01:22:49 Iter 63300 [Train]: loss=297.86, epe=3.63, lr=0.000026, samples/sec=13.3, sec/step=0.602, eta=6:08:14\n",
      "2018-09-07 01:23:53 Iter 63400 [Train]: loss=285.52, epe=3.44, lr=0.000027, samples/sec=13.3, sec/step=0.603, eta=6:08:08\n",
      "2018-09-07 01:24:57 Iter 63500 [Train]: loss=298.88, epe=3.60, lr=0.000027, samples/sec=13.3, sec/step=0.603, eta=6:06:49\n",
      "2018-09-07 01:26:01 Iter 63600 [Train]: loss=293.78, epe=3.54, lr=0.000028, samples/sec=13.3, sec/step=0.602, eta=6:04:58\n",
      "2018-09-07 01:27:05 Iter 63700 [Train]: loss=326.34, epe=3.96, lr=0.000028, samples/sec=13.3, sec/step=0.603, eta=6:04:40\n",
      "2018-09-07 01:28:09 Iter 63800 [Train]: loss=292.96, epe=3.51, lr=0.000029, samples/sec=13.3, sec/step=0.603, eta=6:03:32\n",
      "2018-09-07 01:29:13 Iter 63900 [Train]: loss=301.19, epe=3.66, lr=0.000029, samples/sec=13.3, sec/step=0.601, eta=6:01:53\n",
      "2018-09-07 01:30:16 Iter 64000 [Train]: loss=316.91, epe=3.85, lr=0.000029, samples/sec=13.3, sec/step=0.602, eta=6:01:27\n",
      "2018-09-07 01:30:37 Iter 64000 64000 [Val]: loss=277.69, epe=3.45\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-64000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-64000\n",
      "2018-09-07 01:31:50 Iter 64100 [Train]: loss=311.99, epe=3.78, lr=0.000030, samples/sec=13.4, sec/step=0.599, eta=5:58:30\n",
      "2018-09-07 01:32:53 Iter 64200 [Train]: loss=297.34, epe=3.61, lr=0.000030, samples/sec=13.3, sec/step=0.603, eta=5:59:45\n",
      "2018-09-07 01:33:57 Iter 64300 [Train]: loss=308.93, epe=3.76, lr=0.000031, samples/sec=13.3, sec/step=0.602, eta=5:58:15\n",
      "2018-09-07 01:35:01 Iter 64400 [Train]: loss=289.64, epe=3.47, lr=0.000031, samples/sec=13.3, sec/step=0.604, eta=5:58:05\n",
      "2018-09-07 01:36:05 Iter 64500 [Train]: loss=291.40, epe=3.52, lr=0.000032, samples/sec=13.3, sec/step=0.601, eta=5:55:45\n",
      "2018-09-07 01:37:09 Iter 64600 [Train]: loss=297.40, epe=3.60, lr=0.000032, samples/sec=13.3, sec/step=0.602, eta=5:55:05\n",
      "2018-09-07 01:38:13 Iter 64700 [Train]: loss=275.78, epe=3.34, lr=0.000033, samples/sec=13.3, sec/step=0.603, eta=5:54:43\n",
      "2018-09-07 01:39:17 Iter 64800 [Train]: loss=308.12, epe=3.75, lr=0.000033, samples/sec=13.3, sec/step=0.603, eta=5:53:29\n",
      "2018-09-07 01:40:21 Iter 64900 [Train]: loss=298.57, epe=3.62, lr=0.000034, samples/sec=13.3, sec/step=0.604, eta=5:53:07\n",
      "2018-09-07 01:41:25 Iter 65000 [Train]: loss=309.88, epe=3.75, lr=0.000034, samples/sec=13.3, sec/step=0.602, eta=5:51:16\n",
      "2018-09-07 01:41:46 Iter 65000 65000 [Val]: loss=277.78, epe=3.44\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-65000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-65000\n",
      "2018-09-07 01:42:58 Iter 65100 [Train]: loss=314.10, epe=3.80, lr=0.000035, samples/sec=13.3, sec/step=0.601, eta=5:49:24\n",
      "2018-09-07 01:44:02 Iter 65200 [Train]: loss=313.43, epe=3.80, lr=0.000035, samples/sec=13.3, sec/step=0.603, eta=5:49:27\n",
      "2018-09-07 01:45:06 Iter 65300 [Train]: loss=296.21, epe=3.58, lr=0.000036, samples/sec=13.3, sec/step=0.603, eta=5:48:33\n",
      "2018-09-07 01:46:09 Iter 65400 [Train]: loss=300.56, epe=3.63, lr=0.000036, samples/sec=13.3, sec/step=0.603, eta=5:47:41\n",
      "2018-09-07 01:47:13 Iter 65500 [Train]: loss=304.90, epe=3.69, lr=0.000037, samples/sec=13.3, sec/step=0.602, eta=5:46:23\n",
      "2018-09-07 01:48:17 Iter 65600 [Train]: loss=298.28, epe=3.61, lr=0.000037, samples/sec=13.3, sec/step=0.601, eta=5:44:33\n",
      "2018-09-07 01:49:21 Iter 65700 [Train]: loss=308.81, epe=3.75, lr=0.000038, samples/sec=13.3, sec/step=0.601, eta=5:43:39\n",
      "2018-09-07 01:50:25 Iter 65800 [Train]: loss=314.13, epe=3.81, lr=0.000038, samples/sec=13.3, sec/step=0.603, eta=5:43:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 01:51:29 Iter 65900 [Train]: loss=296.73, epe=3.58, lr=0.000039, samples/sec=13.3, sec/step=0.602, eta=5:42:22\n",
      "2018-09-07 01:52:33 Iter 66000 [Train]: loss=303.70, epe=3.68, lr=0.000039, samples/sec=13.3, sec/step=0.602, eta=5:40:59\n",
      "2018-09-07 01:52:54 Iter 66000 66000 [Val]: loss=278.84, epe=3.45\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-66000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-66000\n",
      "2018-09-07 01:54:06 Iter 66100 [Train]: loss=290.67, epe=3.50, lr=0.000040, samples/sec=13.3, sec/step=0.601, eta=5:39:34\n",
      "2018-09-07 01:55:10 Iter 66200 [Train]: loss=302.42, epe=3.65, lr=0.000040, samples/sec=13.2, sec/step=0.604, eta=5:40:10\n",
      "2018-09-07 01:56:14 Iter 66300 [Train]: loss=298.14, epe=3.63, lr=0.000041, samples/sec=13.3, sec/step=0.602, eta=5:37:59\n",
      "2018-09-07 01:57:18 Iter 66400 [Train]: loss=299.39, epe=3.62, lr=0.000041, samples/sec=13.3, sec/step=0.602, eta=5:37:07\n",
      "2018-09-07 01:58:21 Iter 66500 [Train]: loss=298.65, epe=3.62, lr=0.000042, samples/sec=13.3, sec/step=0.602, eta=5:35:57\n",
      "2018-09-07 01:59:25 Iter 66600 [Train]: loss=295.06, epe=3.57, lr=0.000042, samples/sec=13.3, sec/step=0.602, eta=5:35:04\n",
      "2018-09-07 02:00:29 Iter 66700 [Train]: loss=287.01, epe=3.48, lr=0.000043, samples/sec=13.3, sec/step=0.603, eta=5:34:36\n",
      "2018-09-07 02:01:33 Iter 66800 [Train]: loss=273.11, epe=3.28, lr=0.000043, samples/sec=13.3, sec/step=0.602, eta=5:33:16\n",
      "2018-09-07 02:02:37 Iter 66900 [Train]: loss=293.21, epe=3.54, lr=0.000044, samples/sec=13.3, sec/step=0.603, eta=5:32:26\n",
      "2018-09-07 02:03:41 Iter 67000 [Train]: loss=312.77, epe=3.80, lr=0.000044, samples/sec=13.3, sec/step=0.602, eta=5:30:54\n",
      "2018-09-07 02:04:02 Iter 67000 67000 [Val]: loss=277.57, epe=3.43\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-67000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-67000\n",
      "2018-09-07 02:05:14 Iter 67100 [Train]: loss=297.34, epe=3.60, lr=0.000045, samples/sec=13.3, sec/step=0.600, eta=5:29:15\n",
      "2018-09-07 02:06:18 Iter 67200 [Train]: loss=298.38, epe=3.61, lr=0.000045, samples/sec=13.3, sec/step=0.602, eta=5:29:10\n",
      "2018-09-07 02:07:22 Iter 67300 [Train]: loss=311.05, epe=3.75, lr=0.000046, samples/sec=13.3, sec/step=0.602, eta=5:28:15\n",
      "2018-09-07 02:08:26 Iter 67400 [Train]: loss=295.95, epe=3.57, lr=0.000046, samples/sec=13.3, sec/step=0.604, eta=5:27:55\n",
      "2018-09-07 02:09:30 Iter 67500 [Train]: loss=297.72, epe=3.60, lr=0.000047, samples/sec=13.3, sec/step=0.603, eta=5:26:44\n",
      "2018-09-07 02:10:34 Iter 67600 [Train]: loss=297.96, epe=3.61, lr=0.000047, samples/sec=13.3, sec/step=0.603, eta=5:25:30\n",
      "2018-09-07 02:11:38 Iter 67700 [Train]: loss=306.37, epe=3.70, lr=0.000048, samples/sec=13.2, sec/step=0.604, eta=5:25:05\n",
      "2018-09-07 02:12:41 Iter 67800 [Train]: loss=304.98, epe=3.71, lr=0.000048, samples/sec=13.2, sec/step=0.605, eta=5:24:39\n",
      "2018-09-07 02:13:45 Iter 67900 [Train]: loss=308.63, epe=3.75, lr=0.000049, samples/sec=13.3, sec/step=0.603, eta=5:22:27\n",
      "2018-09-07 02:14:49 Iter 68000 [Train]: loss=313.90, epe=3.81, lr=0.000049, samples/sec=13.2, sec/step=0.604, eta=5:22:06\n",
      "2018-09-07 02:15:10 Iter 68000 68000 [Val]: loss=277.28, epe=3.44\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-68000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-68000\n",
      "2018-09-07 02:16:23 Iter 68100 [Train]: loss=303.63, epe=3.68, lr=0.000049, samples/sec=13.4, sec/step=0.599, eta=5:18:28\n",
      "2018-09-07 02:17:27 Iter 68200 [Train]: loss=296.64, epe=3.57, lr=0.000050, samples/sec=13.3, sec/step=0.603, eta=5:19:34\n",
      "2018-09-07 02:18:31 Iter 68300 [Train]: loss=309.12, epe=3.74, lr=0.000050, samples/sec=13.2, sec/step=0.604, eta=5:19:09\n",
      "2018-09-07 02:19:35 Iter 68400 [Train]: loss=294.16, epe=3.55, lr=0.000051, samples/sec=13.3, sec/step=0.603, eta=5:17:44\n",
      "2018-09-07 02:20:39 Iter 68500 [Train]: loss=308.42, epe=3.74, lr=0.000051, samples/sec=13.3, sec/step=0.603, eta=5:16:30\n",
      "2018-09-07 02:21:43 Iter 68600 [Train]: loss=316.22, epe=3.83, lr=0.000052, samples/sec=13.3, sec/step=0.603, eta=5:15:47\n",
      "2018-09-07 02:22:46 Iter 68700 [Train]: loss=321.75, epe=3.93, lr=0.000052, samples/sec=13.3, sec/step=0.602, eta=5:14:10\n",
      "2018-09-07 02:23:50 Iter 68800 [Train]: loss=295.30, epe=3.56, lr=0.000053, samples/sec=13.3, sec/step=0.603, eta=5:13:44\n",
      "2018-09-07 02:24:54 Iter 68900 [Train]: loss=310.02, epe=3.77, lr=0.000053, samples/sec=13.3, sec/step=0.603, eta=5:12:24\n",
      "2018-09-07 02:25:58 Iter 69000 [Train]: loss=290.89, epe=3.51, lr=0.000054, samples/sec=13.3, sec/step=0.603, eta=5:11:39\n",
      "2018-09-07 02:26:19 Iter 69000 69000 [Val]: loss=278.54, epe=3.45\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-69000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-69000\n",
      "2018-09-07 02:27:32 Iter 69100 [Train]: loss=296.95, epe=3.61, lr=0.000054, samples/sec=13.3, sec/step=0.600, eta=5:08:57\n",
      "2018-09-07 02:28:36 Iter 69200 [Train]: loss=301.90, epe=3.66, lr=0.000055, samples/sec=13.3, sec/step=0.603, eta=5:09:25\n",
      "2018-09-07 02:29:40 Iter 69300 [Train]: loss=295.20, epe=3.59, lr=0.000055, samples/sec=13.3, sec/step=0.602, eta=5:07:51\n",
      "2018-09-07 02:30:44 Iter 69400 [Train]: loss=289.29, epe=3.49, lr=0.000056, samples/sec=13.3, sec/step=0.603, eta=5:07:33\n",
      "2018-09-07 02:31:48 Iter 69500 [Train]: loss=303.19, epe=3.69, lr=0.000056, samples/sec=13.3, sec/step=0.603, eta=5:06:33\n",
      "2018-09-07 02:32:52 Iter 69600 [Train]: loss=304.22, epe=3.70, lr=0.000057, samples/sec=13.3, sec/step=0.604, eta=5:05:52\n",
      "2018-09-07 02:33:56 Iter 69700 [Train]: loss=311.98, epe=3.76, lr=0.000057, samples/sec=13.3, sec/step=0.603, eta=5:04:23\n",
      "2018-09-07 02:34:59 Iter 69800 [Train]: loss=284.71, epe=3.44, lr=0.000058, samples/sec=13.3, sec/step=0.602, eta=5:03:09\n",
      "2018-09-07 02:36:03 Iter 69900 [Train]: loss=319.23, epe=3.88, lr=0.000058, samples/sec=13.3, sec/step=0.603, eta=5:02:16\n",
      "2018-09-07 02:37:07 Iter 70000 [Train]: loss=307.63, epe=3.73, lr=0.000059, samples/sec=13.3, sec/step=0.603, eta=5:01:43\n",
      "2018-09-07 02:37:28 Iter 70000 70000 [Val]: loss=276.83, epe=3.43\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-70000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-70000\n",
      "2018-09-07 02:38:44 Iter 70100 [Train]: loss=299.26, epe=3.63, lr=0.000058, samples/sec=13.4, sec/step=0.599, eta=4:58:32\n",
      "2018-09-07 02:39:48 Iter 70200 [Train]: loss=306.40, epe=3.70, lr=0.000058, samples/sec=13.3, sec/step=0.603, eta=4:59:39\n",
      "2018-09-07 02:40:51 Iter 70300 [Train]: loss=306.74, epe=3.73, lr=0.000057, samples/sec=13.2, sec/step=0.604, eta=4:58:54\n",
      "2018-09-07 02:41:55 Iter 70400 [Train]: loss=284.97, epe=3.43, lr=0.000057, samples/sec=13.2, sec/step=0.604, eta=4:58:13\n",
      "2018-09-07 02:42:59 Iter 70500 [Train]: loss=288.19, epe=3.49, lr=0.000056, samples/sec=13.2, sec/step=0.605, eta=4:57:17\n",
      "2018-09-07 02:44:03 Iter 70600 [Train]: loss=325.40, epe=3.96, lr=0.000056, samples/sec=13.3, sec/step=0.603, eta=4:55:29\n",
      "2018-09-07 02:45:07 Iter 70700 [Train]: loss=291.02, epe=3.51, lr=0.000055, samples/sec=13.2, sec/step=0.604, eta=4:55:05\n",
      "2018-09-07 02:46:11 Iter 70800 [Train]: loss=297.45, epe=3.58, lr=0.000055, samples/sec=13.2, sec/step=0.604, eta=4:53:56\n",
      "2018-09-07 02:47:15 Iter 70900 [Train]: loss=325.41, epe=3.96, lr=0.000054, samples/sec=13.3, sec/step=0.603, eta=4:52:27\n",
      "2018-09-07 02:48:19 Iter 71000 [Train]: loss=306.63, epe=3.72, lr=0.000054, samples/sec=13.3, sec/step=0.602, eta=4:50:49\n",
      "2018-09-07 02:48:40 Iter 71000 71000 [Val]: loss=280.68, epe=3.48\n",
      "Saving model...\n",
      "... model saved in None\n",
      "2018-09-07 02:49:48 Iter 71100 [Train]: loss=289.26, epe=3.51, lr=0.000053, samples/sec=13.2, sec/step=0.604, eta=4:51:10\n",
      "2018-09-07 02:50:52 Iter 71200 [Train]: loss=294.06, epe=3.57, lr=0.000053, samples/sec=13.2, sec/step=0.604, eta=4:50:09\n",
      "2018-09-07 02:51:56 Iter 71300 [Train]: loss=302.95, epe=3.65, lr=0.000052, samples/sec=13.3, sec/step=0.603, eta=4:48:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 02:52:59 Iter 71400 [Train]: loss=321.92, epe=3.92, lr=0.000052, samples/sec=13.3, sec/step=0.603, eta=4:47:29\n",
      "2018-09-07 02:54:03 Iter 71500 [Train]: loss=311.86, epe=3.78, lr=0.000051, samples/sec=13.3, sec/step=0.603, eta=4:46:26\n",
      "2018-09-07 02:55:07 Iter 71600 [Train]: loss=313.24, epe=3.83, lr=0.000051, samples/sec=13.3, sec/step=0.602, eta=4:45:10\n",
      "2018-09-07 02:56:11 Iter 71700 [Train]: loss=288.49, epe=3.48, lr=0.000050, samples/sec=13.3, sec/step=0.602, eta=4:43:58\n",
      "2018-09-07 02:57:15 Iter 71800 [Train]: loss=292.00, epe=3.54, lr=0.000050, samples/sec=13.3, sec/step=0.603, eta=4:43:11\n",
      "2018-09-07 02:58:19 Iter 71900 [Train]: loss=312.43, epe=3.77, lr=0.000049, samples/sec=13.3, sec/step=0.602, eta=4:42:03\n",
      "2018-09-07 02:59:23 Iter 72000 [Train]: loss=299.09, epe=3.62, lr=0.000049, samples/sec=13.3, sec/step=0.603, eta=4:41:17\n",
      "2018-09-07 02:59:44 Iter 72000 72000 [Val]: loss=276.25, epe=3.42\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-72000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-72000\n",
      "2018-09-07 03:00:56 Iter 72100 [Train]: loss=299.60, epe=3.62, lr=0.000049, samples/sec=13.3, sec/step=0.599, eta=4:38:42\n",
      "2018-09-07 03:02:00 Iter 72200 [Train]: loss=284.39, epe=3.43, lr=0.000048, samples/sec=13.3, sec/step=0.601, eta=4:38:38\n",
      "2018-09-07 03:03:04 Iter 72300 [Train]: loss=290.08, epe=3.51, lr=0.000048, samples/sec=13.3, sec/step=0.601, eta=4:37:32\n",
      "2018-09-07 03:04:08 Iter 72400 [Train]: loss=287.46, epe=3.46, lr=0.000047, samples/sec=13.3, sec/step=0.603, eta=4:37:16\n",
      "2018-09-07 03:05:12 Iter 72500 [Train]: loss=301.64, epe=3.66, lr=0.000047, samples/sec=13.3, sec/step=0.602, eta=4:35:59\n",
      "2018-09-07 03:06:16 Iter 72600 [Train]: loss=289.43, epe=3.49, lr=0.000046, samples/sec=13.3, sec/step=0.603, eta=4:35:24\n",
      "2018-09-07 03:07:20 Iter 72700 [Train]: loss=309.90, epe=3.75, lr=0.000046, samples/sec=13.3, sec/step=0.603, eta=4:34:31\n",
      "2018-09-07 03:08:24 Iter 72800 [Train]: loss=299.03, epe=3.60, lr=0.000045, samples/sec=13.2, sec/step=0.604, eta=4:33:49\n",
      "2018-09-07 03:09:28 Iter 72900 [Train]: loss=285.86, epe=3.44, lr=0.000045, samples/sec=13.3, sec/step=0.603, eta=4:32:33\n",
      "2018-09-07 03:10:32 Iter 73000 [Train]: loss=299.40, epe=3.62, lr=0.000044, samples/sec=13.3, sec/step=0.602, eta=4:31:00\n",
      "2018-09-07 03:10:53 Iter 73000 73000 [Val]: loss=275.45, epe=3.42\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-73000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-73000\n",
      "2018-09-07 03:12:05 Iter 73100 [Train]: loss=313.73, epe=3.80, lr=0.000044, samples/sec=13.4, sec/step=0.599, eta=4:28:39\n",
      "2018-09-07 03:13:09 Iter 73200 [Train]: loss=300.13, epe=3.62, lr=0.000043, samples/sec=13.3, sec/step=0.601, eta=4:28:40\n",
      "2018-09-07 03:14:13 Iter 73300 [Train]: loss=284.39, epe=3.42, lr=0.000043, samples/sec=13.3, sec/step=0.603, eta=4:28:31\n",
      "2018-09-07 03:15:17 Iter 73400 [Train]: loss=282.03, epe=3.40, lr=0.000042, samples/sec=13.3, sec/step=0.602, eta=4:26:54\n",
      "2018-09-07 03:16:21 Iter 73500 [Train]: loss=306.21, epe=3.71, lr=0.000042, samples/sec=13.2, sec/step=0.604, eta=4:26:44\n",
      "2018-09-07 03:17:25 Iter 73600 [Train]: loss=288.48, epe=3.47, lr=0.000041, samples/sec=13.3, sec/step=0.604, eta=4:25:35\n",
      "2018-09-07 03:18:29 Iter 73700 [Train]: loss=298.97, epe=3.60, lr=0.000041, samples/sec=13.3, sec/step=0.603, eta=4:24:12\n",
      "2018-09-07 03:19:33 Iter 73800 [Train]: loss=303.00, epe=3.65, lr=0.000040, samples/sec=13.3, sec/step=0.603, eta=4:23:07\n",
      "2018-09-07 03:20:37 Iter 73900 [Train]: loss=289.95, epe=3.49, lr=0.000040, samples/sec=13.3, sec/step=0.602, eta=4:21:59\n",
      "2018-09-07 03:21:40 Iter 74000 [Train]: loss=308.49, epe=3.74, lr=0.000039, samples/sec=13.3, sec/step=0.603, eta=4:21:10\n",
      "2018-09-07 03:22:01 Iter 74000 74000 [Val]: loss=273.39, epe=3.37\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-74000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-74000\n",
      "2018-09-07 03:23:14 Iter 74100 [Train]: loss=292.13, epe=3.51, lr=0.000039, samples/sec=13.3, sec/step=0.600, eta=4:19:04\n",
      "2018-09-07 03:24:18 Iter 74200 [Train]: loss=314.49, epe=3.81, lr=0.000038, samples/sec=13.3, sec/step=0.603, eta=4:19:18\n",
      "2018-09-07 03:25:22 Iter 74300 [Train]: loss=301.41, epe=3.65, lr=0.000038, samples/sec=13.3, sec/step=0.603, eta=4:18:14\n",
      "2018-09-07 03:26:25 Iter 74400 [Train]: loss=284.42, epe=3.42, lr=0.000037, samples/sec=13.3, sec/step=0.601, eta=4:16:27\n",
      "2018-09-07 03:27:29 Iter 74500 [Train]: loss=291.10, epe=3.50, lr=0.000037, samples/sec=13.3, sec/step=0.602, eta=4:15:41\n",
      "2018-09-07 03:28:33 Iter 74600 [Train]: loss=289.59, epe=3.50, lr=0.000036, samples/sec=13.3, sec/step=0.601, eta=4:14:18\n",
      "2018-09-07 03:29:37 Iter 74700 [Train]: loss=300.03, epe=3.61, lr=0.000036, samples/sec=13.3, sec/step=0.602, eta=4:13:42\n",
      "2018-09-07 03:30:41 Iter 74800 [Train]: loss=300.99, epe=3.65, lr=0.000035, samples/sec=13.3, sec/step=0.603, eta=4:13:05\n",
      "2018-09-07 03:31:45 Iter 74900 [Train]: loss=295.60, epe=3.57, lr=0.000035, samples/sec=13.3, sec/step=0.603, eta=4:12:13\n",
      "2018-09-07 03:32:49 Iter 75000 [Train]: loss=306.77, epe=3.71, lr=0.000034, samples/sec=13.3, sec/step=0.602, eta=4:10:54\n",
      "2018-09-07 03:33:10 Iter 75000 75000 [Val]: loss=268.89, epe=3.31\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-75000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-75000\n",
      "2018-09-07 03:34:23 Iter 75100 [Train]: loss=273.31, epe=3.27, lr=0.000034, samples/sec=13.3, sec/step=0.601, eta=4:09:19\n",
      "2018-09-07 03:35:26 Iter 75200 [Train]: loss=297.23, epe=3.56, lr=0.000033, samples/sec=13.2, sec/step=0.604, eta=4:09:35\n",
      "2018-09-07 03:36:30 Iter 75300 [Train]: loss=298.30, epe=3.61, lr=0.000033, samples/sec=13.3, sec/step=0.603, eta=4:08:05\n",
      "2018-09-07 03:37:34 Iter 75400 [Train]: loss=296.21, epe=3.56, lr=0.000032, samples/sec=13.3, sec/step=0.603, eta=4:07:06\n",
      "2018-09-07 03:38:38 Iter 75500 [Train]: loss=285.40, epe=3.42, lr=0.000032, samples/sec=13.3, sec/step=0.603, eta=4:06:15\n",
      "2018-09-07 03:39:42 Iter 75600 [Train]: loss=287.70, epe=3.47, lr=0.000031, samples/sec=13.2, sec/step=0.604, eta=4:05:38\n",
      "2018-09-07 03:40:46 Iter 75700 [Train]: loss=296.38, epe=3.59, lr=0.000031, samples/sec=13.2, sec/step=0.604, eta=4:04:47\n",
      "2018-09-07 03:41:50 Iter 75800 [Train]: loss=277.28, epe=3.31, lr=0.000030, samples/sec=13.3, sec/step=0.602, eta=4:02:54\n",
      "2018-09-07 03:42:54 Iter 75900 [Train]: loss=287.20, epe=3.45, lr=0.000030, samples/sec=13.2, sec/step=0.604, eta=4:02:33\n",
      "2018-09-07 03:43:58 Iter 76000 [Train]: loss=283.36, epe=3.42, lr=0.000030, samples/sec=13.3, sec/step=0.603, eta=4:01:10\n",
      "2018-09-07 03:44:19 Iter 76000 76000 [Val]: loss=268.70, epe=3.31\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-76000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-76000\n",
      "2018-09-07 03:45:32 Iter 76100 [Train]: loss=294.60, epe=3.55, lr=0.000029, samples/sec=13.3, sec/step=0.601, eta=3:59:31\n",
      "2018-09-07 03:46:36 Iter 76200 [Train]: loss=276.02, epe=3.30, lr=0.000029, samples/sec=13.3, sec/step=0.603, eta=3:59:17\n",
      "2018-09-07 03:47:40 Iter 76300 [Train]: loss=302.64, epe=3.66, lr=0.000028, samples/sec=13.3, sec/step=0.603, eta=3:58:16\n",
      "2018-09-07 03:48:44 Iter 76400 [Train]: loss=281.38, epe=3.40, lr=0.000028, samples/sec=13.3, sec/step=0.603, eta=3:57:13\n",
      "2018-09-07 03:49:48 Iter 76500 [Train]: loss=288.02, epe=3.46, lr=0.000027, samples/sec=13.2, sec/step=0.604, eta=3:56:34\n",
      "2018-09-07 03:50:52 Iter 76600 [Train]: loss=289.45, epe=3.48, lr=0.000027, samples/sec=13.2, sec/step=0.604, eta=3:55:30\n",
      "2018-09-07 03:51:56 Iter 76700 [Train]: loss=286.36, epe=3.44, lr=0.000026, samples/sec=13.2, sec/step=0.604, eta=3:54:38\n",
      "2018-09-07 03:53:00 Iter 76800 [Train]: loss=294.26, epe=3.54, lr=0.000026, samples/sec=13.3, sec/step=0.602, eta=3:52:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 03:54:04 Iter 76900 [Train]: loss=284.61, epe=3.41, lr=0.000025, samples/sec=13.2, sec/step=0.605, eta=3:52:55\n",
      "2018-09-07 03:55:08 Iter 77000 [Train]: loss=286.55, epe=3.45, lr=0.000025, samples/sec=13.3, sec/step=0.603, eta=3:51:08\n",
      "2018-09-07 03:55:29 Iter 77000 77000 [Val]: loss=266.31, epe=3.27\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-77000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-77000\n",
      "2018-09-07 03:56:41 Iter 77100 [Train]: loss=282.77, epe=3.38, lr=0.000024, samples/sec=13.3, sec/step=0.600, eta=3:49:00\n",
      "2018-09-07 03:57:45 Iter 77200 [Train]: loss=284.34, epe=3.43, lr=0.000024, samples/sec=13.3, sec/step=0.604, eta=3:49:20\n",
      "2018-09-07 03:58:49 Iter 77300 [Train]: loss=284.94, epe=3.41, lr=0.000023, samples/sec=13.3, sec/step=0.603, eta=3:48:17\n",
      "2018-09-07 03:59:53 Iter 77400 [Train]: loss=306.81, epe=3.70, lr=0.000023, samples/sec=13.3, sec/step=0.603, eta=3:47:19\n",
      "2018-09-07 04:00:57 Iter 77500 [Train]: loss=311.33, epe=3.79, lr=0.000022, samples/sec=13.3, sec/step=0.601, eta=3:45:17\n",
      "2018-09-07 04:02:01 Iter 77600 [Train]: loss=309.80, epe=3.75, lr=0.000022, samples/sec=13.3, sec/step=0.602, eta=3:44:50\n",
      "2018-09-07 04:03:05 Iter 77700 [Train]: loss=296.21, epe=3.55, lr=0.000021, samples/sec=13.3, sec/step=0.603, eta=3:44:10\n",
      "2018-09-07 04:04:09 Iter 77800 [Train]: loss=283.47, epe=3.40, lr=0.000021, samples/sec=13.2, sec/step=0.604, eta=3:43:31\n",
      "2018-09-07 04:05:13 Iter 77900 [Train]: loss=283.25, epe=3.38, lr=0.000020, samples/sec=13.2, sec/step=0.604, eta=3:42:30\n",
      "2018-09-07 04:06:17 Iter 78000 [Train]: loss=275.17, epe=3.30, lr=0.000020, samples/sec=13.3, sec/step=0.603, eta=3:41:10\n",
      "2018-09-07 04:06:38 Iter 78000 78000 [Val]: loss=266.66, epe=3.29\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-78000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-78000\n",
      "2018-09-07 04:07:51 Iter 78100 [Train]: loss=287.57, epe=3.46, lr=0.000019, samples/sec=13.3, sec/step=0.601, eta=3:39:15\n",
      "2018-09-07 04:08:54 Iter 78200 [Train]: loss=301.54, epe=3.64, lr=0.000019, samples/sec=13.3, sec/step=0.603, eta=3:38:59\n",
      "2018-09-07 04:09:58 Iter 78300 [Train]: loss=309.04, epe=3.73, lr=0.000018, samples/sec=13.3, sec/step=0.603, eta=3:38:09\n",
      "2018-09-07 04:11:03 Iter 78400 [Train]: loss=276.77, epe=3.29, lr=0.000018, samples/sec=13.3, sec/step=0.604, eta=3:37:20\n",
      "2018-09-07 04:12:07 Iter 78500 [Train]: loss=285.43, epe=3.44, lr=0.000017, samples/sec=13.3, sec/step=0.602, eta=3:35:53\n",
      "2018-09-07 04:13:10 Iter 78600 [Train]: loss=278.32, epe=3.33, lr=0.000017, samples/sec=13.3, sec/step=0.602, eta=3:34:51\n",
      "2018-09-07 04:14:14 Iter 78700 [Train]: loss=300.00, epe=3.61, lr=0.000016, samples/sec=13.3, sec/step=0.602, eta=3:33:46\n",
      "2018-09-07 04:15:18 Iter 78800 [Train]: loss=282.24, epe=3.39, lr=0.000016, samples/sec=13.3, sec/step=0.604, eta=3:33:19\n",
      "2018-09-07 04:16:22 Iter 78900 [Train]: loss=306.54, epe=3.69, lr=0.000015, samples/sec=13.3, sec/step=0.602, eta=3:31:51\n",
      "2018-09-07 04:17:26 Iter 79000 [Train]: loss=295.47, epe=3.55, lr=0.000015, samples/sec=13.2, sec/step=0.605, eta=3:31:51\n",
      "2018-09-07 04:17:47 Iter 79000 79000 [Val]: loss=265.25, epe=3.26\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-79000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-79000\n",
      "2018-09-07 04:19:00 Iter 79100 [Train]: loss=275.45, epe=3.30, lr=0.000014, samples/sec=13.3, sec/step=0.601, eta=3:29:17\n",
      "2018-09-07 04:20:04 Iter 79200 [Train]: loss=282.51, epe=3.36, lr=0.000014, samples/sec=13.3, sec/step=0.601, eta=3:28:22\n",
      "2018-09-07 04:21:08 Iter 79300 [Train]: loss=284.90, epe=3.41, lr=0.000013, samples/sec=13.3, sec/step=0.603, eta=3:28:01\n",
      "2018-09-07 04:22:12 Iter 79400 [Train]: loss=295.92, epe=3.55, lr=0.000013, samples/sec=13.3, sec/step=0.604, eta=3:27:17\n",
      "2018-09-07 04:23:16 Iter 79500 [Train]: loss=287.51, epe=3.45, lr=0.000012, samples/sec=13.3, sec/step=0.603, eta=3:26:04\n",
      "2018-09-07 04:24:20 Iter 79600 [Train]: loss=282.63, epe=3.38, lr=0.000012, samples/sec=13.3, sec/step=0.602, eta=3:24:48\n",
      "2018-09-07 04:25:24 Iter 79700 [Train]: loss=291.62, epe=3.50, lr=0.000011, samples/sec=13.3, sec/step=0.601, eta=3:23:20\n",
      "2018-09-07 04:26:28 Iter 79800 [Train]: loss=281.89, epe=3.38, lr=0.000011, samples/sec=13.2, sec/step=0.605, eta=3:23:34\n",
      "2018-09-07 04:27:32 Iter 79900 [Train]: loss=289.52, epe=3.49, lr=0.000010, samples/sec=13.3, sec/step=0.604, eta=3:22:10\n",
      "2018-09-07 04:28:36 Iter 80000 [Train]: loss=282.44, epe=3.39, lr=0.000010, samples/sec=13.3, sec/step=0.604, eta=3:21:15\n",
      "2018-09-07 04:28:57 Iter 80000 80000 [Val]: loss=267.13, epe=3.29\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-80000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-80000\n",
      "2018-09-07 04:30:10 Iter 80100 [Train]: loss=279.26, epe=3.35, lr=0.000010, samples/sec=13.3, sec/step=0.600, eta=3:19:10\n",
      "2018-09-07 04:31:14 Iter 80200 [Train]: loss=277.25, epe=3.31, lr=0.000010, samples/sec=13.3, sec/step=0.603, eta=3:19:06\n",
      "2018-09-07 04:32:18 Iter 80300 [Train]: loss=276.04, epe=3.27, lr=0.000011, samples/sec=13.3, sec/step=0.602, eta=3:17:39\n",
      "2018-09-07 04:33:22 Iter 80400 [Train]: loss=277.72, epe=3.32, lr=0.000011, samples/sec=13.3, sec/step=0.603, eta=3:17:00\n",
      "2018-09-07 04:34:26 Iter 80500 [Train]: loss=277.63, epe=3.31, lr=0.000011, samples/sec=13.3, sec/step=0.602, eta=3:15:37\n",
      "2018-09-07 04:35:29 Iter 80600 [Train]: loss=281.30, epe=3.37, lr=0.000011, samples/sec=13.3, sec/step=0.603, eta=3:15:02\n",
      "2018-09-07 04:36:33 Iter 80700 [Train]: loss=294.58, epe=3.54, lr=0.000012, samples/sec=13.3, sec/step=0.603, eta=3:14:03\n",
      "2018-09-07 04:37:37 Iter 80800 [Train]: loss=282.67, epe=3.39, lr=0.000012, samples/sec=13.3, sec/step=0.603, eta=3:13:02\n",
      "2018-09-07 04:38:42 Iter 80900 [Train]: loss=286.98, epe=3.45, lr=0.000012, samples/sec=13.1, sec/step=0.612, eta=3:14:55\n",
      "2018-09-07 04:39:47 Iter 81000 [Train]: loss=278.70, epe=3.34, lr=0.000012, samples/sec=13.1, sec/step=0.609, eta=3:12:46\n",
      "2018-09-07 04:40:08 Iter 81000 81000 [Val]: loss=266.20, epe=3.28\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-81000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-81000\n",
      "2018-09-07 04:41:21 Iter 81100 [Train]: loss=289.16, epe=3.49, lr=0.000013, samples/sec=13.3, sec/step=0.602, eta=3:09:46\n",
      "2018-09-07 04:42:25 Iter 81200 [Train]: loss=288.42, epe=3.45, lr=0.000013, samples/sec=13.2, sec/step=0.605, eta=3:09:27\n",
      "2018-09-07 04:43:29 Iter 81300 [Train]: loss=282.22, epe=3.38, lr=0.000013, samples/sec=13.2, sec/step=0.605, eta=3:08:43\n",
      "2018-09-07 04:44:33 Iter 81400 [Train]: loss=275.59, epe=3.30, lr=0.000013, samples/sec=13.2, sec/step=0.606, eta=3:07:50\n",
      "2018-09-07 04:45:38 Iter 81500 [Train]: loss=285.95, epe=3.41, lr=0.000014, samples/sec=13.2, sec/step=0.606, eta=3:06:46\n",
      "2018-09-07 04:46:42 Iter 81600 [Train]: loss=296.92, epe=3.56, lr=0.000014, samples/sec=13.2, sec/step=0.607, eta=3:06:16\n",
      "2018-09-07 04:47:46 Iter 81700 [Train]: loss=279.72, epe=3.35, lr=0.000014, samples/sec=13.2, sec/step=0.606, eta=3:04:51\n",
      "2018-09-07 04:48:50 Iter 81800 [Train]: loss=301.32, epe=3.62, lr=0.000014, samples/sec=13.2, sec/step=0.606, eta=3:03:42\n",
      "2018-09-07 04:49:54 Iter 81900 [Train]: loss=278.05, epe=3.31, lr=0.000015, samples/sec=13.2, sec/step=0.605, eta=3:02:26\n",
      "2018-09-07 04:50:59 Iter 82000 [Train]: loss=315.22, epe=3.79, lr=0.000015, samples/sec=13.2, sec/step=0.605, eta=3:01:31\n",
      "2018-09-07 04:51:20 Iter 82000 82000 [Val]: loss=265.12, epe=3.26\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-82000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-82000\n",
      "2018-09-07 04:52:33 Iter 82100 [Train]: loss=290.15, epe=3.47, lr=0.000015, samples/sec=13.3, sec/step=0.603, eta=2:59:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 04:53:37 Iter 82200 [Train]: loss=280.93, epe=3.36, lr=0.000015, samples/sec=13.3, sec/step=0.603, eta=2:58:58\n",
      "2018-09-07 04:54:41 Iter 82300 [Train]: loss=275.24, epe=3.29, lr=0.000016, samples/sec=13.2, sec/step=0.604, eta=2:58:19\n",
      "2018-09-07 04:55:45 Iter 82400 [Train]: loss=282.34, epe=3.37, lr=0.000016, samples/sec=13.2, sec/step=0.606, eta=2:57:45\n",
      "2018-09-07 04:56:50 Iter 82500 [Train]: loss=293.95, epe=3.53, lr=0.000016, samples/sec=13.2, sec/step=0.606, eta=2:56:39\n",
      "2018-09-07 04:57:54 Iter 82600 [Train]: loss=273.24, epe=3.27, lr=0.000016, samples/sec=13.2, sec/step=0.607, eta=2:56:03\n",
      "2018-09-07 04:58:58 Iter 82700 [Train]: loss=277.08, epe=3.31, lr=0.000017, samples/sec=13.2, sec/step=0.606, eta=2:54:46\n",
      "2018-09-07 05:00:02 Iter 82800 [Train]: loss=275.15, epe=3.30, lr=0.000017, samples/sec=13.2, sec/step=0.605, eta=2:53:24\n",
      "2018-09-07 05:01:07 Iter 82900 [Train]: loss=288.87, epe=3.49, lr=0.000017, samples/sec=13.2, sec/step=0.606, eta=2:52:48\n",
      "2018-09-07 05:02:11 Iter 83000 [Train]: loss=295.73, epe=3.54, lr=0.000017, samples/sec=13.2, sec/step=0.605, eta=2:51:33\n",
      "2018-09-07 05:02:32 Iter 83000 83000 [Val]: loss=265.86, epe=3.28\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-83000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-83000\n",
      "2018-09-07 05:03:45 Iter 83100 [Train]: loss=297.33, epe=3.59, lr=0.000018, samples/sec=13.2, sec/step=0.604, eta=2:50:05\n",
      "2018-09-07 05:04:49 Iter 83200 [Train]: loss=274.94, epe=3.28, lr=0.000018, samples/sec=13.2, sec/step=0.606, eta=2:49:36\n",
      "2018-09-07 05:05:54 Iter 83300 [Train]: loss=279.88, epe=3.34, lr=0.000018, samples/sec=13.2, sec/step=0.606, eta=2:48:40\n",
      "2018-09-07 05:06:58 Iter 83400 [Train]: loss=278.64, epe=3.34, lr=0.000018, samples/sec=13.1, sec/step=0.611, eta=2:49:04\n",
      "2018-09-07 05:08:03 Iter 83500 [Train]: loss=277.95, epe=3.33, lr=0.000019, samples/sec=13.2, sec/step=0.608, eta=2:47:16\n",
      "2018-09-07 05:09:07 Iter 83600 [Train]: loss=278.25, epe=3.33, lr=0.000019, samples/sec=13.2, sec/step=0.605, eta=2:45:22\n",
      "2018-09-07 05:10:11 Iter 83700 [Train]: loss=291.80, epe=3.49, lr=0.000019, samples/sec=13.2, sec/step=0.605, eta=2:44:13\n",
      "2018-09-07 05:11:15 Iter 83800 [Train]: loss=281.98, epe=3.38, lr=0.000019, samples/sec=13.2, sec/step=0.605, eta=2:43:19\n",
      "2018-09-07 05:12:20 Iter 83900 [Train]: loss=293.73, epe=3.53, lr=0.000020, samples/sec=13.2, sec/step=0.604, eta=2:42:05\n",
      "2018-09-07 05:13:24 Iter 84000 [Train]: loss=285.97, epe=3.43, lr=0.000020, samples/sec=13.2, sec/step=0.605, eta=2:41:21\n",
      "2018-09-07 05:13:45 Iter 84000 84000 [Val]: loss=266.76, epe=3.28\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-84000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-84000\n",
      "2018-09-07 05:14:58 Iter 84100 [Train]: loss=261.29, epe=3.11, lr=0.000020, samples/sec=13.3, sec/step=0.604, eta=2:39:57\n",
      "2018-09-07 05:16:02 Iter 84200 [Train]: loss=276.45, epe=3.30, lr=0.000020, samples/sec=13.2, sec/step=0.605, eta=2:39:26\n",
      "2018-09-07 05:17:06 Iter 84300 [Train]: loss=301.64, epe=3.65, lr=0.000020, samples/sec=13.2, sec/step=0.605, eta=2:38:22\n",
      "2018-09-07 05:18:11 Iter 84400 [Train]: loss=270.45, epe=3.25, lr=0.000021, samples/sec=13.2, sec/step=0.606, eta=2:37:31\n",
      "2018-09-07 05:19:15 Iter 84500 [Train]: loss=285.87, epe=3.42, lr=0.000021, samples/sec=13.2, sec/step=0.607, eta=2:36:41\n",
      "2018-09-07 05:20:19 Iter 84600 [Train]: loss=271.70, epe=3.24, lr=0.000021, samples/sec=13.3, sec/step=0.603, eta=2:34:52\n",
      "2018-09-07 05:21:23 Iter 84700 [Train]: loss=288.26, epe=3.46, lr=0.000021, samples/sec=13.2, sec/step=0.604, eta=2:34:06\n",
      "2018-09-07 05:22:27 Iter 84800 [Train]: loss=287.73, epe=3.47, lr=0.000022, samples/sec=13.2, sec/step=0.605, eta=2:33:14\n",
      "2018-09-07 05:23:32 Iter 84900 [Train]: loss=278.03, epe=3.34, lr=0.000022, samples/sec=13.2, sec/step=0.606, eta=2:32:35\n",
      "2018-09-07 05:24:36 Iter 85000 [Train]: loss=288.58, epe=3.46, lr=0.000022, samples/sec=13.2, sec/step=0.606, eta=2:31:27\n",
      "2018-09-07 05:24:57 Iter 85000 85000 [Val]: loss=267.24, epe=3.29\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-85000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-85000\n",
      "2018-09-07 05:26:10 Iter 85100 [Train]: loss=306.47, epe=3.70, lr=0.000022, samples/sec=13.3, sec/step=0.602, eta=2:29:33\n",
      "2018-09-07 05:27:14 Iter 85200 [Train]: loss=287.21, epe=3.44, lr=0.000023, samples/sec=13.2, sec/step=0.605, eta=2:29:12\n",
      "2018-09-07 05:28:18 Iter 85300 [Train]: loss=285.06, epe=3.41, lr=0.000023, samples/sec=13.2, sec/step=0.604, eta=2:27:56\n",
      "2018-09-07 05:29:23 Iter 85400 [Train]: loss=284.30, epe=3.41, lr=0.000023, samples/sec=13.2, sec/step=0.606, eta=2:27:27\n",
      "2018-09-07 05:30:27 Iter 85500 [Train]: loss=296.82, epe=3.57, lr=0.000023, samples/sec=13.2, sec/step=0.606, eta=2:26:30\n",
      "2018-09-07 05:31:31 Iter 85600 [Train]: loss=271.33, epe=3.21, lr=0.000024, samples/sec=13.2, sec/step=0.607, eta=2:25:35\n",
      "2018-09-07 05:32:35 Iter 85700 [Train]: loss=285.37, epe=3.43, lr=0.000024, samples/sec=13.2, sec/step=0.606, eta=2:24:22\n",
      "2018-09-07 05:33:40 Iter 85800 [Train]: loss=288.12, epe=3.49, lr=0.000024, samples/sec=13.2, sec/step=0.605, eta=2:23:15\n",
      "2018-09-07 05:34:44 Iter 85900 [Train]: loss=300.93, epe=3.62, lr=0.000024, samples/sec=13.2, sec/step=0.607, eta=2:22:34\n",
      "2018-09-07 05:35:48 Iter 86000 [Train]: loss=290.88, epe=3.49, lr=0.000025, samples/sec=13.2, sec/step=0.605, eta=2:21:03\n",
      "2018-09-07 05:36:09 Iter 86000 86000 [Val]: loss=268.46, epe=3.31\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-86000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-86000\n",
      "2018-09-07 05:37:22 Iter 86100 [Train]: loss=292.83, epe=3.53, lr=0.000025, samples/sec=13.3, sec/step=0.602, eta=2:19:33\n",
      "2018-09-07 05:38:26 Iter 86200 [Train]: loss=275.70, epe=3.30, lr=0.000025, samples/sec=13.2, sec/step=0.604, eta=2:18:58\n",
      "2018-09-07 05:39:30 Iter 86300 [Train]: loss=297.03, epe=3.57, lr=0.000025, samples/sec=13.2, sec/step=0.605, eta=2:18:14\n",
      "2018-09-07 05:40:35 Iter 86400 [Train]: loss=293.14, epe=3.52, lr=0.000026, samples/sec=13.2, sec/step=0.604, eta=2:16:56\n",
      "2018-09-07 05:41:39 Iter 86500 [Train]: loss=281.21, epe=3.38, lr=0.000026, samples/sec=13.2, sec/step=0.604, eta=2:15:56\n",
      "2018-09-07 05:42:43 Iter 86600 [Train]: loss=287.21, epe=3.46, lr=0.000026, samples/sec=13.2, sec/step=0.606, eta=2:15:17\n",
      "2018-09-07 05:43:47 Iter 86700 [Train]: loss=287.57, epe=3.45, lr=0.000026, samples/sec=13.2, sec/step=0.607, eta=2:14:34\n",
      "2018-09-07 05:44:52 Iter 86800 [Train]: loss=278.81, epe=3.34, lr=0.000027, samples/sec=13.2, sec/step=0.606, eta=2:13:23\n",
      "2018-09-07 05:45:56 Iter 86900 [Train]: loss=287.56, epe=3.42, lr=0.000027, samples/sec=13.2, sec/step=0.607, eta=2:12:36\n",
      "2018-09-07 05:47:00 Iter 87000 [Train]: loss=300.76, epe=3.63, lr=0.000027, samples/sec=13.1, sec/step=0.609, eta=2:11:56\n",
      "2018-09-07 05:47:21 Iter 87000 87000 [Val]: loss=267.87, epe=3.29\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-87000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-87000\n",
      "2018-09-07 05:48:37 Iter 87100 [Train]: loss=282.39, epe=3.39, lr=0.000027, samples/sec=13.3, sec/step=0.601, eta=2:09:18\n",
      "2018-09-07 05:49:42 Iter 87200 [Train]: loss=277.80, epe=3.32, lr=0.000028, samples/sec=13.2, sec/step=0.606, eta=2:09:14\n",
      "2018-09-07 05:50:46 Iter 87300 [Train]: loss=307.29, epe=3.71, lr=0.000028, samples/sec=13.2, sec/step=0.606, eta=2:08:14\n",
      "2018-09-07 05:51:50 Iter 87400 [Train]: loss=295.35, epe=3.57, lr=0.000028, samples/sec=13.2, sec/step=0.606, eta=2:07:11\n",
      "2018-09-07 05:52:54 Iter 87500 [Train]: loss=298.50, epe=3.59, lr=0.000028, samples/sec=13.2, sec/step=0.606, eta=2:06:15\n",
      "2018-09-07 05:53:59 Iter 87600 [Train]: loss=291.72, epe=3.49, lr=0.000029, samples/sec=13.2, sec/step=0.606, eta=2:05:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 05:55:03 Iter 87700 [Train]: loss=296.77, epe=3.58, lr=0.000029, samples/sec=13.2, sec/step=0.606, eta=2:04:08\n",
      "2018-09-07 05:56:07 Iter 87800 [Train]: loss=291.91, epe=3.53, lr=0.000029, samples/sec=13.2, sec/step=0.607, eta=2:03:25\n",
      "2018-09-07 05:57:11 Iter 87900 [Train]: loss=298.38, epe=3.56, lr=0.000029, samples/sec=13.2, sec/step=0.605, eta=2:02:05\n",
      "2018-09-07 05:58:15 Iter 88000 [Train]: loss=277.15, epe=3.31, lr=0.000030, samples/sec=13.2, sec/step=0.605, eta=2:00:56\n",
      "2018-09-07 05:58:37 Iter 88000 88000 [Val]: loss=266.11, epe=3.28\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-88000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-88000\n",
      "2018-09-07 05:59:50 Iter 88100 [Train]: loss=272.66, epe=3.25, lr=0.000030, samples/sec=13.3, sec/step=0.602, eta=1:59:23\n",
      "2018-09-07 06:00:54 Iter 88200 [Train]: loss=281.29, epe=3.39, lr=0.000030, samples/sec=13.2, sec/step=0.604, eta=1:58:45\n",
      "2018-09-07 06:01:58 Iter 88300 [Train]: loss=277.03, epe=3.31, lr=0.000030, samples/sec=13.2, sec/step=0.607, eta=1:58:22\n",
      "2018-09-07 06:03:02 Iter 88400 [Train]: loss=306.54, epe=3.70, lr=0.000030, samples/sec=13.2, sec/step=0.606, eta=1:57:12\n",
      "2018-09-07 06:04:07 Iter 88500 [Train]: loss=284.00, epe=3.41, lr=0.000031, samples/sec=13.2, sec/step=0.605, eta=1:55:59\n",
      "2018-09-07 06:05:11 Iter 88600 [Train]: loss=283.17, epe=3.37, lr=0.000031, samples/sec=13.2, sec/step=0.604, eta=1:54:49\n",
      "2018-09-07 06:06:15 Iter 88700 [Train]: loss=286.63, epe=3.44, lr=0.000031, samples/sec=13.2, sec/step=0.607, eta=1:54:24\n",
      "2018-09-07 06:07:19 Iter 88800 [Train]: loss=258.89, epe=3.08, lr=0.000031, samples/sec=13.2, sec/step=0.605, eta=1:53:00\n",
      "2018-09-07 06:08:23 Iter 88900 [Train]: loss=281.83, epe=3.36, lr=0.000032, samples/sec=13.2, sec/step=0.604, eta=1:51:45\n",
      "2018-09-07 06:09:28 Iter 89000 [Train]: loss=288.91, epe=3.47, lr=0.000032, samples/sec=13.2, sec/step=0.604, eta=1:50:45\n",
      "2018-09-07 06:09:49 Iter 89000 89000 [Val]: loss=266.11, epe=3.28\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-89000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-89000\n",
      "2018-09-07 06:11:02 Iter 89100 [Train]: loss=291.53, epe=3.51, lr=0.000032, samples/sec=13.3, sec/step=0.602, eta=1:49:23\n",
      "2018-09-07 06:12:06 Iter 89200 [Train]: loss=296.33, epe=3.57, lr=0.000032, samples/sec=13.2, sec/step=0.606, eta=1:49:07\n",
      "2018-09-07 06:13:10 Iter 89300 [Train]: loss=292.96, epe=3.51, lr=0.000033, samples/sec=13.2, sec/step=0.607, eta=1:48:13\n",
      "2018-09-07 06:14:14 Iter 89400 [Train]: loss=291.01, epe=3.49, lr=0.000033, samples/sec=13.2, sec/step=0.606, eta=1:47:07\n",
      "2018-09-07 06:15:19 Iter 89500 [Train]: loss=296.46, epe=3.59, lr=0.000033, samples/sec=13.2, sec/step=0.607, eta=1:46:09\n",
      "2018-09-07 06:16:23 Iter 89600 [Train]: loss=282.24, epe=3.38, lr=0.000033, samples/sec=13.2, sec/step=0.605, eta=1:44:55\n",
      "2018-09-07 06:17:27 Iter 89700 [Train]: loss=285.94, epe=3.43, lr=0.000034, samples/sec=13.2, sec/step=0.604, eta=1:43:42\n",
      "2018-09-07 06:18:32 Iter 89800 [Train]: loss=284.83, epe=3.44, lr=0.000034, samples/sec=13.2, sec/step=0.605, eta=1:42:56\n",
      "2018-09-07 06:19:36 Iter 89900 [Train]: loss=283.06, epe=3.40, lr=0.000034, samples/sec=13.1, sec/step=0.609, eta=1:42:31\n",
      "2018-09-07 06:20:41 Iter 90000 [Train]: loss=286.32, epe=3.46, lr=0.000034, samples/sec=13.2, sec/step=0.607, eta=1:41:06\n",
      "2018-09-07 06:21:02 Iter 90000 90000 [Val]: loss=267.68, epe=3.30\n",
      "Saving model...\n",
      "... model saved in None\n",
      "2018-09-07 06:22:10 Iter 90100 [Train]: loss=293.61, epe=3.54, lr=0.000034, samples/sec=13.2, sec/step=0.605, eta=1:39:45\n",
      "2018-09-07 06:23:14 Iter 90200 [Train]: loss=281.95, epe=3.37, lr=0.000034, samples/sec=13.1, sec/step=0.608, eta=1:39:23\n",
      "2018-09-07 06:24:19 Iter 90300 [Train]: loss=290.18, epe=3.49, lr=0.000034, samples/sec=13.2, sec/step=0.606, eta=1:38:02\n",
      "2018-09-07 06:25:23 Iter 90400 [Train]: loss=282.41, epe=3.38, lr=0.000033, samples/sec=13.2, sec/step=0.605, eta=1:36:47\n",
      "2018-09-07 06:26:27 Iter 90500 [Train]: loss=282.88, epe=3.39, lr=0.000033, samples/sec=13.2, sec/step=0.606, eta=1:35:58\n",
      "2018-09-07 06:27:31 Iter 90600 [Train]: loss=285.93, epe=3.43, lr=0.000033, samples/sec=13.2, sec/step=0.606, eta=1:35:00\n",
      "2018-09-07 06:28:35 Iter 90700 [Train]: loss=287.23, epe=3.46, lr=0.000033, samples/sec=13.2, sec/step=0.607, eta=1:34:06\n",
      "2018-09-07 06:29:40 Iter 90800 [Train]: loss=288.27, epe=3.45, lr=0.000032, samples/sec=13.2, sec/step=0.606, eta=1:32:52\n",
      "2018-09-07 06:30:44 Iter 90900 [Train]: loss=299.58, epe=3.60, lr=0.000032, samples/sec=13.2, sec/step=0.607, eta=1:32:06\n",
      "2018-09-07 06:31:48 Iter 91000 [Train]: loss=274.53, epe=3.30, lr=0.000032, samples/sec=13.2, sec/step=0.606, eta=1:30:52\n",
      "2018-09-07 06:32:09 Iter 91000 91000 [Val]: loss=264.78, epe=3.26\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-91000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-91000\n",
      "2018-09-07 06:33:22 Iter 91100 [Train]: loss=277.09, epe=3.31, lr=0.000032, samples/sec=13.3, sec/step=0.602, eta=1:29:18\n",
      "2018-09-07 06:34:27 Iter 91200 [Train]: loss=279.54, epe=3.36, lr=0.000031, samples/sec=13.2, sec/step=0.607, eta=1:28:58\n",
      "2018-09-07 06:35:31 Iter 91300 [Train]: loss=282.85, epe=3.39, lr=0.000031, samples/sec=13.2, sec/step=0.606, eta=1:27:49\n",
      "2018-09-07 06:36:35 Iter 91400 [Train]: loss=284.21, epe=3.39, lr=0.000031, samples/sec=13.2, sec/step=0.605, eta=1:26:46\n",
      "2018-09-07 06:37:39 Iter 91500 [Train]: loss=275.77, epe=3.31, lr=0.000031, samples/sec=13.2, sec/step=0.605, eta=1:25:40\n",
      "2018-09-07 06:38:44 Iter 91600 [Train]: loss=291.21, epe=3.51, lr=0.000030, samples/sec=13.2, sec/step=0.606, eta=1:24:50\n",
      "2018-09-07 06:39:48 Iter 91700 [Train]: loss=287.61, epe=3.45, lr=0.000030, samples/sec=13.2, sec/step=0.607, eta=1:23:55\n",
      "2018-09-07 06:40:52 Iter 91800 [Train]: loss=294.32, epe=3.54, lr=0.000030, samples/sec=13.2, sec/step=0.606, eta=1:22:47\n",
      "2018-09-07 06:41:57 Iter 91900 [Train]: loss=288.64, epe=3.48, lr=0.000030, samples/sec=13.2, sec/step=0.606, eta=1:21:51\n",
      "2018-09-07 06:43:01 Iter 92000 [Train]: loss=292.26, epe=3.50, lr=0.000030, samples/sec=13.2, sec/step=0.607, eta=1:20:55\n",
      "2018-09-07 06:43:22 Iter 92000 92000 [Val]: loss=271.16, epe=3.35\n",
      "Saving model...\n",
      "... model saved in None\n",
      "2018-09-07 06:44:30 Iter 92100 [Train]: loss=280.73, epe=3.37, lr=0.000029, samples/sec=13.2, sec/step=0.605, eta=1:19:40\n",
      "2018-09-07 06:45:34 Iter 92200 [Train]: loss=287.53, epe=3.43, lr=0.000029, samples/sec=13.3, sec/step=0.604, eta=1:18:28\n",
      "2018-09-07 06:46:39 Iter 92300 [Train]: loss=287.20, epe=3.45, lr=0.000029, samples/sec=13.2, sec/step=0.605, eta=1:17:38\n",
      "2018-09-07 06:47:43 Iter 92400 [Train]: loss=276.85, epe=3.31, lr=0.000029, samples/sec=13.2, sec/step=0.606, eta=1:16:48\n",
      "2018-09-07 06:48:47 Iter 92500 [Train]: loss=289.27, epe=3.47, lr=0.000028, samples/sec=13.2, sec/step=0.607, eta=1:15:50\n",
      "2018-09-07 06:49:51 Iter 92600 [Train]: loss=292.69, epe=3.51, lr=0.000028, samples/sec=13.2, sec/step=0.605, eta=1:14:38\n",
      "2018-09-07 06:50:56 Iter 92700 [Train]: loss=284.42, epe=3.42, lr=0.000028, samples/sec=13.2, sec/step=0.604, eta=1:13:30\n",
      "2018-09-07 06:52:00 Iter 92800 [Train]: loss=278.91, epe=3.34, lr=0.000028, samples/sec=13.2, sec/step=0.605, eta=1:12:39\n",
      "2018-09-07 06:53:04 Iter 92900 [Train]: loss=294.15, epe=3.53, lr=0.000027, samples/sec=13.3, sec/step=0.603, eta=1:11:21\n",
      "2018-09-07 06:54:08 Iter 93000 [Train]: loss=285.47, epe=3.42, lr=0.000027, samples/sec=13.2, sec/step=0.606, eta=1:10:42\n",
      "2018-09-07 06:54:30 Iter 93000 93000 [Val]: loss=263.52, epe=3.24\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-93000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-93000\n",
      "2018-09-07 06:55:42 Iter 93100 [Train]: loss=265.67, epe=3.16, lr=0.000027, samples/sec=13.2, sec/step=0.604, eta=1:09:26\n",
      "2018-09-07 06:56:47 Iter 93200 [Train]: loss=292.81, epe=3.51, lr=0.000027, samples/sec=13.2, sec/step=0.605, eta=1:08:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 06:57:51 Iter 93300 [Train]: loss=271.65, epe=3.24, lr=0.000026, samples/sec=13.3, sec/step=0.603, eta=1:07:23\n",
      "2018-09-07 06:58:55 Iter 93400 [Train]: loss=285.05, epe=3.41, lr=0.000026, samples/sec=13.2, sec/step=0.604, eta=1:06:29\n",
      "2018-09-07 06:59:59 Iter 93500 [Train]: loss=292.68, epe=3.50, lr=0.000026, samples/sec=13.2, sec/step=0.606, eta=1:05:39\n",
      "2018-09-07 07:01:04 Iter 93600 [Train]: loss=287.91, epe=3.47, lr=0.000026, samples/sec=13.2, sec/step=0.605, eta=1:04:32\n",
      "2018-09-07 07:02:08 Iter 93700 [Train]: loss=277.35, epe=3.30, lr=0.000025, samples/sec=13.2, sec/step=0.605, eta=1:03:31\n",
      "2018-09-07 07:03:12 Iter 93800 [Train]: loss=278.76, epe=3.34, lr=0.000025, samples/sec=13.2, sec/step=0.605, eta=1:02:34\n",
      "2018-09-07 07:04:16 Iter 93900 [Train]: loss=279.22, epe=3.35, lr=0.000025, samples/sec=13.2, sec/step=0.604, eta=1:01:27\n",
      "2018-09-07 07:05:21 Iter 94000 [Train]: loss=300.72, epe=3.61, lr=0.000025, samples/sec=13.2, sec/step=0.605, eta=1:00:27\n",
      "2018-09-07 07:05:42 Iter 94000 94000 [Val]: loss=263.32, epe=3.24\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-94000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-94000\n",
      "2018-09-07 07:06:54 Iter 94100 [Train]: loss=277.98, epe=3.31, lr=0.000024, samples/sec=13.3, sec/step=0.604, eta=0:59:21\n",
      "2018-09-07 07:07:59 Iter 94200 [Train]: loss=271.38, epe=3.25, lr=0.000024, samples/sec=13.2, sec/step=0.606, eta=0:58:37\n",
      "2018-09-07 07:09:03 Iter 94300 [Train]: loss=267.74, epe=3.18, lr=0.000024, samples/sec=13.2, sec/step=0.606, eta=0:57:36\n",
      "2018-09-07 07:10:07 Iter 94400 [Train]: loss=296.39, epe=3.55, lr=0.000024, samples/sec=13.2, sec/step=0.607, eta=0:56:37\n",
      "2018-09-07 07:11:11 Iter 94500 [Train]: loss=276.89, epe=3.30, lr=0.000023, samples/sec=13.3, sec/step=0.603, eta=0:55:14\n",
      "2018-09-07 07:12:15 Iter 94600 [Train]: loss=288.10, epe=3.42, lr=0.000023, samples/sec=13.3, sec/step=0.602, eta=0:54:12\n",
      "2018-09-07 07:13:19 Iter 94700 [Train]: loss=283.47, epe=3.41, lr=0.000023, samples/sec=13.3, sec/step=0.603, eta=0:53:14\n",
      "2018-09-07 07:14:23 Iter 94800 [Train]: loss=284.98, epe=3.43, lr=0.000023, samples/sec=13.3, sec/step=0.603, eta=0:52:13\n",
      "2018-09-07 07:15:27 Iter 94900 [Train]: loss=286.14, epe=3.39, lr=0.000022, samples/sec=13.3, sec/step=0.603, eta=0:51:17\n",
      "2018-09-07 07:16:31 Iter 95000 [Train]: loss=281.05, epe=3.38, lr=0.000022, samples/sec=13.3, sec/step=0.602, eta=0:50:09\n",
      "2018-09-07 07:16:52 Iter 95000 95000 [Val]: loss=262.55, epe=3.22\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-95000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-95000\n",
      "2018-09-07 07:18:05 Iter 95100 [Train]: loss=278.91, epe=3.33, lr=0.000022, samples/sec=13.3, sec/step=0.600, eta=0:48:59\n",
      "2018-09-07 07:19:09 Iter 95200 [Train]: loss=283.87, epe=3.38, lr=0.000022, samples/sec=13.3, sec/step=0.603, eta=0:48:14\n",
      "2018-09-07 07:20:13 Iter 95300 [Train]: loss=273.16, epe=3.27, lr=0.000021, samples/sec=13.3, sec/step=0.604, eta=0:47:18\n",
      "2018-09-07 07:21:17 Iter 95400 [Train]: loss=290.01, epe=3.48, lr=0.000021, samples/sec=13.3, sec/step=0.602, eta=0:46:07\n",
      "2018-09-07 07:22:21 Iter 95500 [Train]: loss=275.05, epe=3.28, lr=0.000021, samples/sec=13.3, sec/step=0.603, eta=0:45:12\n",
      "2018-09-07 07:23:25 Iter 95600 [Train]: loss=279.12, epe=3.33, lr=0.000021, samples/sec=13.3, sec/step=0.602, eta=0:44:10\n",
      "2018-09-07 07:24:29 Iter 95700 [Train]: loss=271.32, epe=3.23, lr=0.000020, samples/sec=13.3, sec/step=0.604, eta=0:43:16\n",
      "2018-09-07 07:25:33 Iter 95800 [Train]: loss=268.56, epe=3.20, lr=0.000020, samples/sec=13.3, sec/step=0.602, eta=0:42:09\n",
      "2018-09-07 07:26:37 Iter 95900 [Train]: loss=278.39, epe=3.34, lr=0.000020, samples/sec=13.2, sec/step=0.605, eta=0:41:21\n",
      "2018-09-07 07:27:41 Iter 96000 [Train]: loss=279.45, epe=3.31, lr=0.000020, samples/sec=13.2, sec/step=0.604, eta=0:40:17\n",
      "2018-09-07 07:28:02 Iter 96000 96000 [Val]: loss=260.35, epe=3.19\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-96000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-96000\n",
      "2018-09-07 07:29:15 Iter 96100 [Train]: loss=276.52, epe=3.30, lr=0.000020, samples/sec=13.3, sec/step=0.601, eta=0:39:04\n",
      "2018-09-07 07:30:19 Iter 96200 [Train]: loss=282.28, epe=3.35, lr=0.000019, samples/sec=13.3, sec/step=0.602, eta=0:38:09\n",
      "2018-09-07 07:31:23 Iter 96300 [Train]: loss=283.64, epe=3.37, lr=0.000019, samples/sec=13.3, sec/step=0.602, eta=0:37:09\n",
      "2018-09-07 07:32:27 Iter 96400 [Train]: loss=293.44, epe=3.52, lr=0.000019, samples/sec=13.3, sec/step=0.604, eta=0:36:13\n",
      "2018-09-07 07:33:31 Iter 96500 [Train]: loss=279.47, epe=3.34, lr=0.000019, samples/sec=13.3, sec/step=0.602, eta=0:35:09\n",
      "2018-09-07 07:34:35 Iter 96600 [Train]: loss=282.43, epe=3.39, lr=0.000018, samples/sec=13.3, sec/step=0.602, eta=0:34:07\n",
      "2018-09-07 07:35:39 Iter 96700 [Train]: loss=295.10, epe=3.53, lr=0.000018, samples/sec=13.3, sec/step=0.602, eta=0:33:05\n",
      "2018-09-07 07:36:43 Iter 96800 [Train]: loss=249.62, epe=2.96, lr=0.000018, samples/sec=13.2, sec/step=0.605, eta=0:32:17\n",
      "2018-09-07 07:37:47 Iter 96900 [Train]: loss=288.93, epe=3.48, lr=0.000018, samples/sec=13.3, sec/step=0.604, eta=0:31:11\n",
      "2018-09-07 07:38:51 Iter 97000 [Train]: loss=282.22, epe=3.39, lr=0.000017, samples/sec=13.2, sec/step=0.604, eta=0:30:12\n",
      "2018-09-07 07:39:12 Iter 97000 97000 [Val]: loss=261.99, epe=3.21\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-97000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-97000\n",
      "2018-09-07 07:40:25 Iter 97100 [Train]: loss=281.80, epe=3.37, lr=0.000017, samples/sec=13.4, sec/step=0.599, eta=0:28:57\n",
      "2018-09-07 07:41:29 Iter 97200 [Train]: loss=297.05, epe=3.58, lr=0.000017, samples/sec=13.3, sec/step=0.603, eta=0:28:07\n",
      "2018-09-07 07:42:33 Iter 97300 [Train]: loss=266.84, epe=3.18, lr=0.000017, samples/sec=13.3, sec/step=0.603, eta=0:27:08\n",
      "2018-09-07 07:43:37 Iter 97400 [Train]: loss=277.63, epe=3.31, lr=0.000016, samples/sec=13.3, sec/step=0.603, eta=0:26:07\n",
      "2018-09-07 07:44:41 Iter 97500 [Train]: loss=294.55, epe=3.51, lr=0.000016, samples/sec=13.2, sec/step=0.604, eta=0:25:10\n",
      "2018-09-07 07:45:45 Iter 97600 [Train]: loss=276.37, epe=3.28, lr=0.000016, samples/sec=13.3, sec/step=0.601, eta=0:24:03\n",
      "2018-09-07 07:46:49 Iter 97700 [Train]: loss=290.43, epe=3.47, lr=0.000016, samples/sec=13.2, sec/step=0.604, eta=0:23:09\n",
      "2018-09-07 07:47:53 Iter 97800 [Train]: loss=279.61, epe=3.33, lr=0.000015, samples/sec=13.3, sec/step=0.603, eta=0:22:07\n",
      "2018-09-07 07:48:57 Iter 97900 [Train]: loss=271.16, epe=3.24, lr=0.000015, samples/sec=13.3, sec/step=0.602, eta=0:21:05\n",
      "2018-09-07 07:50:01 Iter 98000 [Train]: loss=282.67, epe=3.38, lr=0.000015, samples/sec=13.3, sec/step=0.603, eta=0:20:07\n",
      "2018-09-07 07:50:22 Iter 98000 98000 [Val]: loss=259.04, epe=3.17\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-98000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-98000\n",
      "2018-09-07 07:51:34 Iter 98100 [Train]: loss=282.77, epe=3.37, lr=0.000015, samples/sec=13.3, sec/step=0.601, eta=0:19:02\n",
      "2018-09-07 07:52:39 Iter 98200 [Train]: loss=272.14, epe=3.25, lr=0.000014, samples/sec=13.3, sec/step=0.602, eta=0:18:03\n",
      "2018-09-07 07:53:43 Iter 98300 [Train]: loss=285.40, epe=3.42, lr=0.000014, samples/sec=13.3, sec/step=0.600, eta=0:17:01\n",
      "2018-09-07 07:54:47 Iter 98400 [Train]: loss=271.40, epe=3.23, lr=0.000014, samples/sec=13.3, sec/step=0.601, eta=0:16:02\n",
      "2018-09-07 07:55:51 Iter 98500 [Train]: loss=283.43, epe=3.41, lr=0.000014, samples/sec=13.3, sec/step=0.602, eta=0:15:03\n",
      "2018-09-07 07:56:55 Iter 98600 [Train]: loss=282.47, epe=3.39, lr=0.000013, samples/sec=13.3, sec/step=0.603, eta=0:14:05\n",
      "2018-09-07 07:57:59 Iter 98700 [Train]: loss=281.00, epe=3.36, lr=0.000013, samples/sec=13.3, sec/step=0.601, eta=0:13:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-07 07:59:03 Iter 98800 [Train]: loss=273.18, epe=3.26, lr=0.000013, samples/sec=13.3, sec/step=0.603, eta=0:12:04\n",
      "2018-09-07 08:00:07 Iter 98900 [Train]: loss=282.97, epe=3.38, lr=0.000013, samples/sec=13.3, sec/step=0.602, eta=0:11:02\n",
      "2018-09-07 08:01:11 Iter 99000 [Train]: loss=293.29, epe=3.50, lr=0.000012, samples/sec=13.3, sec/step=0.604, eta=0:10:04\n",
      "2018-09-07 08:01:32 Iter 99000 99000 [Val]: loss=260.52, epe=3.19\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-99000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-99000\n",
      "2018-09-07 08:02:45 Iter 99100 [Train]: loss=268.93, epe=3.20, lr=0.000012, samples/sec=13.3, sec/step=0.601, eta=0:09:01\n",
      "2018-09-07 08:03:49 Iter 99200 [Train]: loss=278.70, epe=3.32, lr=0.000012, samples/sec=13.2, sec/step=0.604, eta=0:08:04\n",
      "2018-09-07 08:04:53 Iter 99300 [Train]: loss=259.01, epe=3.08, lr=0.000012, samples/sec=13.3, sec/step=0.603, eta=0:07:02\n",
      "2018-09-07 08:05:57 Iter 99400 [Train]: loss=264.70, epe=3.16, lr=0.000011, samples/sec=13.3, sec/step=0.603, eta=0:06:02\n",
      "2018-09-07 08:07:01 Iter 99500 [Train]: loss=286.86, epe=3.43, lr=0.000011, samples/sec=13.3, sec/step=0.603, eta=0:05:01\n",
      "2018-09-07 08:08:05 Iter 99600 [Train]: loss=270.44, epe=3.22, lr=0.000011, samples/sec=13.3, sec/step=0.601, eta=0:04:01\n",
      "2018-09-07 08:09:09 Iter 99700 [Train]: loss=268.99, epe=3.23, lr=0.000011, samples/sec=13.3, sec/step=0.603, eta=0:03:01\n",
      "2018-09-07 08:10:13 Iter 99800 [Train]: loss=270.86, epe=3.23, lr=0.000010, samples/sec=13.3, sec/step=0.603, eta=0:02:01\n",
      "2018-09-07 08:11:17 Iter 99900 [Train]: loss=275.21, epe=3.28, lr=0.000010, samples/sec=13.3, sec/step=0.604, eta=0:01:00\n",
      "2018-09-07 08:12:22 Iter 100000 [Train]: loss=283.23, epe=3.40, lr=0.000010, samples/sec=13.3, sec/step=0.604, eta=0:00:00\n",
      "2018-09-07 08:12:43 Iter 100000 100000 [Val]: loss=257.06, epe=3.15\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-100000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-sm-6-1-cyclic-chairs/pwcnet.ckpt-100000\n",
      "... done training.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the training curves for the run above:\n",
    "\n",
    "![](img/pwcnet-sm-6-1-cyclic-chairs/loss.png)\n",
    "![](img/pwcnet-sm-6-1-cyclic-chairs/epe.png)\n",
    "![](img/pwcnet-sm-6-1-cyclic-chairs/lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictions issued by the model for a few validation samples:\n",
    "\n",
    "![](img/pwcnet-sm-6-1-cyclic-chairs/val1.png)\n",
    "![](img/pwcnet-sm-6-1-cyclic-chairs/val2.png)\n",
    "![](img/pwcnet-sm-6-1-cyclic-chairs/val3.png)\n",
    "![](img/pwcnet-sm-6-1-cyclic-chairs/val4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune on `FlyingThings3D`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds_opts = deepcopy(_DEFAULT_DS_TUNE_OPTIONS)\n",
    "ds_opts['in_memory'] = False                 # Too many samples to keep in memory at once, so don't preload them\n",
    "ds_opts['aug_type'] = 'heavy'                # Apply all supported augmentations\n",
    "ds_opts['batch_size'] = 4 * len(gpu_devices) # Use a multiple of 4; here, 8 for dual-GPU mode (Titan X & 1080 Ti)\n",
    "ds_opts['crop_preproc'] = (384, 768)         # Crop to a smaller input size\n",
    "ds_opts['type'] = 'into_future'\n",
    "ds = FlyingThings3DDataset(mode='train_with_val', ds_root=_FLYINGTHINGS3D_ROOT, options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the finetuning, starting from the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_FINETUNE_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_path'] = './pwcnet-cyclic-chairs/pwcnet.ckpt-25000'\n",
    "nn_opts['ckpt_dir'] = './pwcnet-cyclic-chairs-things/'\n",
    "nn_opts['batch_size'] = ds_opts['batch_size']\n",
    "nn_opts['x_shape'] = [2, ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 3]\n",
    "nn_opts['y_shape'] = [ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 2]\n",
    "nn_opts['use_tf_data'] = True # Use tf.data reader\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# Use the PWC-Net-small model\n",
    "nn_opts['use_dense_cx'] = False\n",
    "nn_opts['use_res_cx'] = False\n",
    "\n",
    "# Couldn't get the training to converge with robust loss... switch back to multiscale loss\n",
    "nn_opts['loss_fn'] = 'loss_multiscale'\n",
    "nn_opts['q'] = 1.\n",
    "nn_opts['epsilon'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate schedule. This schedule is for a single GPU using a batch size of 8.\n",
    "# Below,we adjust the schedule to the size of the batch and the number of GPUs.\n",
    "nn_opts['lr_policy'] = 'cyclic'\n",
    "nn_opts['cyclic_lr_max'] = 2e-05\n",
    "nn_opts['cyclic_lr_base'] = 1e-06\n",
    "nn_opts['cyclic_lr_stepsize'] = 10000\n",
    "nn_opts['max_steps'] = 100000\n",
    "\n",
    "# Below,we adjust the schedule to the size of the batch and our number of GPUs (2).\n",
    "nn_opts['cyclic_lr_stepsize'] /= len(gpu_devices)\n",
    "nn_opts['max_steps'] /= len(gpu_devices)\n",
    "nn_opts['cyclic_lr_stepsize'] = int(nn_opts['cyclic_lr_stepsize'] / (float(ds_opts['batch_size']) / 4))\n",
    "nn_opts['max_steps'] = int(nn_opts['max_steps'] / (float(ds_opts['batch_size']) / 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and display the model configuration\n",
    "nn = ModelPWCNet(mode='train_with_val', options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune the model\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the training curves for the run above:\n",
    "    \n",
    "![](pwcnet-sm-6-1-cyclic-chairs-things/img/loss.png)\n",
    "![](pwcnet-sm-6-1-cyclic-chairs-things/img/epe.png)\n",
    "![](pwcnet-sm-6-1-cyclic-chairs-things/img/lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictions issued by the model for a few validation samples:\n",
    "    \n",
    "![](pwcnet-sm-6-1-cyclic-chairs-things/img/val1.png)\n",
    "![](pwcnet-sm-6-1-cyclic-chairs-things/img/val2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
