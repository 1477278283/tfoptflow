{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PWC-Net-large model training (with multisteps learning rate schedule)\n",
    "=========================================================\n",
    "\n",
    "In this notebook, we:\n",
    "- Use a PWC-Net-large model (with dense and residual connections), 6 level pyramid, uspample level 2 by 4 as the final flow prediction\n",
    "- Train the model on a mix of the `FlyingChairs` and `FlyingThings3DHalfRes` dataset using a S<sub>long</sub> schedule described in [[2018a]](#2018a)\n",
    "- The S<sub>long</sub> schedule is borrowed from [[2016a]](#2016a) and looks as follows:\n",
    "\n",
    "![](img/lr_multisteps.png)\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own machine setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [2018a]<a name=\"2018a\"></a> Sun et al. 2018. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume. [[arXiv]](https://arxiv.org/abs/1709.02371) [[web]](http://research.nvidia.com/publication/2018-02_PWC-Net%3A-CNNs-for) [[PyTorch (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/PyTorch) [[Caffe (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/Caffe)\n",
    "- [2016a]<a name=\"2016a\"></a> Ilg et al. 2016. FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks. [[arXiv]](https://arxiv.org/abs/1612.01925) [[PyTorch (Official)]](https://github.com/NVIDIA/flownet2-pytorch) [[TensorFlow]](https://github.com/sampepose/flownet2-tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_train.ipynb\n",
    "\n",
    "PWC-Net model training.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\n",
    "Tensorboard:\n",
    "    [win] tensorboard --logdir=E:\\\\repos\\\\tf-optflow\\\\tfoptflow\\\\pwcnet-lg-6-2-multisteps-chairsthingsmix\n",
    "    [ubu] tensorboard --logdir=/media/EDrive/repos/tf-optflow/tfoptflow/pwcnet-lg-6-2-multisteps-chairsthingsmix\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "from dataset_base import _DEFAULT_DS_TRAIN_OPTIONS\n",
    "from dataset_flyingchairs import FlyingChairsDataset\n",
    "from dataset_flyingthings3d import FlyingThings3DHalfResDataset\n",
    "from dataset_mixer import MixedDataset\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_TRAIN_OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    _DATASET_ROOT = 'E:/datasets/'\n",
    "else:\n",
    "    _DATASET_ROOT = '/media/EDrive/datasets/'\n",
    "_FLYINGCHAIRS_ROOT = _DATASET_ROOT + 'FlyingChairs_release'\n",
    "_FLYINGTHINGS3DHALFRES_ROOT = _DATASET_ROOT + 'FlyingThings3D_HalfRes'\n",
    "    \n",
    "# TODO: You MUST adjust the settings below based on the number of GPU(s) used for training\n",
    "# Set controller device and devices\n",
    "# A one-gpu setup would be something like controller='/device:GPU:0' and gpu_devices=['/device:GPU:0']\n",
    "# Here, we use a dual-GPU setup, as shown below\n",
    "gpu_devices = ['/device:GPU:0', '/device:GPU:1']\n",
    "controller = '/device:CPU:0'\n",
    "\n",
    "# TODO: You MUST adjust this setting below based on the amount of memory on your GPU(s)\n",
    "# Batch size\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train on `FlyingChairs+FlyingThings3DHalfRes` mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set the batch size based on the capabilities of your GPU(s) \n",
    "#  Load train dataset\n",
    "ds_opts = deepcopy(_DEFAULT_DS_TRAIN_OPTIONS)\n",
    "ds_opts['in_memory'] = False                          # Too many samples to keep in memory at once, so don't preload them\n",
    "ds_opts['aug_type'] = 'heavy'                         # Apply all supported augmentations\n",
    "ds_opts['batch_size'] = batch_size * len(gpu_devices) # Use a multiple of 8; here, 16 for dual-GPU mode (Titan X & 1080 Ti)\n",
    "ds_opts['crop_preproc'] = (256, 448)                  # Crop to a smaller input size\n",
    "ds1 = FlyingChairsDataset(mode='train_with_val', ds_root=_FLYINGCHAIRS_ROOT, options=ds_opts)\n",
    "ds_opts['type'] = 'into_future'\n",
    "ds2 = FlyingThings3DHalfResDataset(mode='train_with_val', ds_root=_FLYINGTHINGS3DHALFRES_ROOT, options=ds_opts)\n",
    "ds = MixedDataset(mode='train_with_val', datasets=[ds1, ds2], options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration:\n",
      "  verbose              False\n",
      "  in_memory            False\n",
      "  crop_preproc         (256, 448)\n",
      "  scale_preproc        None\n",
      "  input_channels       3\n",
      "  tb_test_imgs         False\n",
      "  random_seed          1969\n",
      "  val_split            0.03\n",
      "  aug_type             heavy\n",
      "  aug_labels           True\n",
      "  fliplr               0.5\n",
      "  flipud               0.5\n",
      "  translate            (0.5, 0.05)\n",
      "  scale                (0.5, 0.05)\n",
      "  batch_size           16\n",
      "  type                 into_future\n",
      "  mode                 train_with_val\n",
      "  train size           41282\n",
      "  val size             1230\n"
     ]
    }
   ],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_TRAIN_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_dir'] = './pwcnet-lg-6-2-multisteps-chairsthingsmix/'\n",
    "nn_opts['batch_size'] = ds_opts['batch_size']\n",
    "nn_opts['x_shape'] = [2, ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 3]\n",
    "nn_opts['y_shape'] = [ds_opts['crop_preproc'][0], ds_opts['crop_preproc'][1], 2]\n",
    "nn_opts['use_tf_data'] = True # Use tf.data reader\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# Use the PWC-Net-large model in quarter-resolution mode\n",
    "nn_opts['use_dense_cx'] = True\n",
    "nn_opts['use_res_cx'] = True\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate schedule. This schedule is for a single GPU using a batch size of 8.\n",
    "# Below,we adjust the schedule to the size of the batch and the number of GPUs.\n",
    "nn_opts['lr_policy'] = 'multisteps'\n",
    "nn_opts['lr_boundaries'] = [400000, 600000, 800000, 1000000, 1200000]\n",
    "nn_opts['lr_values'] = [0.0001, 5e-05, 2.5e-05, 1.25e-05, 6.25e-06, 3.125e-06]\n",
    "nn_opts['max_steps'] = 1200000\n",
    "\n",
    "# Below, we adjust the schedule to the size of the batch and our number of GPUs (2).\n",
    "nn_opts['max_steps'] = int(nn_opts['max_steps'] * 8 / ds_opts['batch_size'])\n",
    "nn_opts['lr_boundaries'] = [int(boundary * 8 / ds_opts['batch_size']) for boundary in nn_opts['lr_boundaries']]\n",
    "\n",
    "# Debugging changes\n",
    "nn_opts['max_to_keep'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model towers...\n",
      "  Building tower_0...\n",
      "WARNING:tensorflow:From /media/EDrive/toolkits.ubu/anaconda3-5.2.0/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "  ...tower_0 built.\n",
      "  Building tower_1...\n",
      "  ...tower_1 built.\n",
      "... model towers built.\n",
      "Initializing model from previous checkpoint ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-310000 to resume training...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-310000\n",
      "... model initialized\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_dir               ./pwcnet-lg-6-2-multisteps-chairsthingsmix/\n",
      "  max_to_keep            50\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, 256, 448, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [256, 448, 2]\n",
      "  train_mode             train\n",
      "  display_step           100\n",
      "  snapshot_step          1000\n",
      "  val_step               1000\n",
      "  val_batch_size         -1\n",
      "  tb_val_imgs            pyramid\n",
      "  tb_test_imgs           None\n",
      "  gpu_devices            ['/device:GPU:0', '/device:GPU:1']\n",
      "  controller             /device:CPU:0\n",
      "  use_tf_data            True\n",
      "  use_mixed_precision    False\n",
      "  loss_scaler            8.0\n",
      "  batch_size             16\n",
      "  lr_policy              multisteps\n",
      "  max_steps              600000\n",
      "  lr_boundaries          [200000, 300000, 400000, 500000, 600000]\n",
      "  lr_values              [0.0001, 5e-05, 2.5e-05, 1.25e-05, 6.25e-06, 3.125e-06]\n",
      "  loss_fn                loss_multiscale\n",
      "  alphas                 [0.32, 0.08, 0.02, 0.01, 0.005, 0.0025]\n",
      "  gamma                  0.0004\n",
      "  q                      1.0\n",
      "  epsilon                0.0\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          2\n",
      "  search_range           4\n",
      "  use_dense_cx           True\n",
      "  use_res_cx             True\n",
      "  mode                   train_with_val\n",
      "  trainable params       14079050\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and display the model configuration\n",
    "nn = ModelPWCNet(mode='train_with_val', options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume training from step 310001...\n",
      "2018-09-16 12:14:00 Iter 310100 [Train]: loss=38.81, epe=2.47, lr=0.000025, samples/sec=21.0, sec/step=1.525, eta=5 days, 2:50:07\n",
      "2018-09-16 12:15:47 Iter 310200 [Train]: loss=36.46, epe=2.28, lr=0.000025, samples/sec=32.1, sec/step=0.997, eta=3 days, 8:16:14\n",
      "2018-09-16 12:17:38 Iter 310300 [Train]: loss=38.82, epe=2.45, lr=0.000025, samples/sec=31.2, sec/step=1.025, eta=3 days, 10:26:54\n",
      "2018-09-16 12:19:28 Iter 310400 [Train]: loss=38.15, epe=2.41, lr=0.000025, samples/sec=31.4, sec/step=1.018, eta=3 days, 9:52:43\n",
      "2018-09-16 12:21:17 Iter 310500 [Train]: loss=36.81, epe=2.32, lr=0.000025, samples/sec=31.5, sec/step=1.015, eta=3 days, 9:39:05\n",
      "2018-09-16 12:23:06 Iter 310600 [Train]: loss=38.82, epe=2.47, lr=0.000025, samples/sec=31.5, sec/step=1.017, eta=3 days, 9:47:15\n",
      "2018-09-16 12:24:56 Iter 310700 [Train]: loss=39.47, epe=2.51, lr=0.000025, samples/sec=31.5, sec/step=1.015, eta=3 days, 9:34:53\n",
      "2018-09-16 12:26:46 Iter 310800 [Train]: loss=38.71, epe=2.46, lr=0.000025, samples/sec=31.4, sec/step=1.019, eta=3 days, 9:51:27\n",
      "2018-09-16 12:28:35 Iter 310900 [Train]: loss=37.83, epe=2.39, lr=0.000025, samples/sec=31.4, sec/step=1.019, eta=3 days, 9:49:39\n",
      "2018-09-16 12:30:25 Iter 311000 [Train]: loss=36.84, epe=2.32, lr=0.000025, samples/sec=31.5, sec/step=1.016, eta=3 days, 9:31:59\n",
      "2018-09-16 12:30:51 Iter 311000 [Val]: loss=42.97, epe=2.79\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-311000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-311000\n",
      "2018-09-16 12:32:57 Iter 311100 [Train]: loss=37.59, epe=2.37, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 10:19:18\n",
      "2018-09-16 12:34:43 Iter 311200 [Train]: loss=36.84, epe=2.31, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 10:26:35\n",
      "2018-09-16 12:36:29 Iter 311300 [Train]: loss=36.63, epe=2.31, lr=0.000025, samples/sec=31.4, sec/step=1.020, eta=3 days, 9:48:51\n",
      "2018-09-16 12:38:13 Iter 311400 [Train]: loss=37.18, epe=2.34, lr=0.000025, samples/sec=31.9, sec/step=1.002, eta=3 days, 8:18:04\n",
      "2018-09-16 12:39:57 Iter 311500 [Train]: loss=38.07, epe=2.41, lr=0.000025, samples/sec=31.7, sec/step=1.011, eta=3 days, 8:59:04\n",
      "2018-09-16 12:41:43 Iter 311600 [Train]: loss=37.71, epe=2.38, lr=0.000025, samples/sec=31.3, sec/step=1.021, eta=3 days, 9:49:00\n",
      "2018-09-16 12:43:29 Iter 311700 [Train]: loss=38.74, epe=2.45, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 9:52:14\n",
      "2018-09-16 12:45:15 Iter 311800 [Train]: loss=36.44, epe=2.28, lr=0.000025, samples/sec=31.3, sec/step=1.023, eta=3 days, 9:54:55\n",
      "2018-09-16 12:47:01 Iter 311900 [Train]: loss=38.81, epe=2.47, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 10:13:55\n",
      "2018-09-16 12:48:48 Iter 312000 [Train]: loss=37.83, epe=2.38, lr=0.000025, samples/sec=31.1, sec/step=1.027, eta=3 days, 10:11:57\n",
      "2018-09-16 12:49:05 Iter 312000 [Val]: loss=42.87, epe=2.77\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-312000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-312000\n",
      "2018-09-16 12:51:07 Iter 312100 [Train]: loss=37.64, epe=2.39, lr=0.000025, samples/sec=32.2, sec/step=0.994, eta=3 days, 7:30:32\n",
      "2018-09-16 12:52:53 Iter 312200 [Train]: loss=37.59, epe=2.36, lr=0.000025, samples/sec=32.1, sec/step=0.998, eta=3 days, 7:48:00\n",
      "2018-09-16 12:54:39 Iter 312300 [Train]: loss=38.09, epe=2.41, lr=0.000025, samples/sec=32.1, sec/step=0.998, eta=3 days, 7:47:30\n",
      "2018-09-16 12:56:26 Iter 312400 [Train]: loss=38.08, epe=2.41, lr=0.000025, samples/sec=32.0, sec/step=1.000, eta=3 days, 7:54:15\n",
      "2018-09-16 12:58:12 Iter 312500 [Train]: loss=38.33, epe=2.42, lr=0.000025, samples/sec=32.0, sec/step=0.999, eta=3 days, 7:45:44\n",
      "2018-09-16 12:59:57 Iter 312600 [Train]: loss=37.32, epe=2.35, lr=0.000025, samples/sec=32.3, sec/step=0.992, eta=3 days, 7:09:25\n",
      "2018-09-16 13:01:41 Iter 312700 [Train]: loss=39.61, epe=2.51, lr=0.000025, samples/sec=32.9, sec/step=0.974, eta=3 days, 5:42:18\n",
      "2018-09-16 13:03:25 Iter 312800 [Train]: loss=38.61, epe=2.45, lr=0.000025, samples/sec=32.7, sec/step=0.978, eta=3 days, 6:02:09\n",
      "2018-09-16 13:05:11 Iter 312900 [Train]: loss=37.51, epe=2.37, lr=0.000025, samples/sec=32.2, sec/step=0.993, eta=3 days, 7:10:35\n",
      "2018-09-16 13:06:57 Iter 313000 [Train]: loss=37.88, epe=2.40, lr=0.000025, samples/sec=32.1, sec/step=0.997, eta=3 days, 7:28:57\n",
      "2018-09-16 13:07:15 Iter 313000 [Val]: loss=42.21, epe=2.71\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-313000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-313000\n",
      "2018-09-16 13:09:21 Iter 313100 [Train]: loss=37.51, epe=2.37, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 10:05:20\n",
      "2018-09-16 13:11:10 Iter 313200 [Train]: loss=38.44, epe=2.43, lr=0.000025, samples/sec=31.0, sec/step=1.033, eta=3 days, 10:18:01\n",
      "2018-09-16 13:12:59 Iter 313300 [Train]: loss=36.83, epe=2.32, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 10:02:01\n",
      "2018-09-16 13:14:49 Iter 313400 [Train]: loss=37.48, epe=2.37, lr=0.000025, samples/sec=31.1, sec/step=1.029, eta=3 days, 9:55:46\n",
      "2018-09-16 13:16:38 Iter 313500 [Train]: loss=39.49, epe=2.51, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 9:43:09\n",
      "2018-09-16 13:18:27 Iter 313600 [Train]: loss=36.79, epe=2.31, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 9:54:38\n",
      "2018-09-16 13:20:17 Iter 313700 [Train]: loss=37.02, epe=2.33, lr=0.000025, samples/sec=31.0, sec/step=1.033, eta=3 days, 10:07:11\n",
      "2018-09-16 13:22:06 Iter 313800 [Train]: loss=37.38, epe=2.36, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 9:45:32\n",
      "2018-09-16 13:23:54 Iter 313900 [Train]: loss=36.61, epe=2.31, lr=0.000025, samples/sec=31.5, sec/step=1.015, eta=3 days, 8:39:47\n",
      "2018-09-16 13:25:40 Iter 314000 [Train]: loss=37.53, epe=2.37, lr=0.000025, samples/sec=31.9, sec/step=1.002, eta=3 days, 7:37:33\n",
      "2018-09-16 13:25:59 Iter 314000 [Val]: loss=42.97, epe=2.79\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-314000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-314000\n",
      "2018-09-16 13:28:04 Iter 314100 [Train]: loss=36.52, epe=2.29, lr=0.000025, samples/sec=31.6, sec/step=1.013, eta=3 days, 8:27:10\n",
      "2018-09-16 13:29:52 Iter 314200 [Train]: loss=36.64, epe=2.30, lr=0.000025, samples/sec=31.3, sec/step=1.023, eta=3 days, 9:14:44\n",
      "2018-09-16 13:31:41 Iter 314300 [Train]: loss=37.98, epe=2.42, lr=0.000025, samples/sec=31.3, sec/step=1.024, eta=3 days, 9:13:54\n",
      "2018-09-16 13:33:30 Iter 314400 [Train]: loss=39.26, epe=2.48, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 9:27:43\n",
      "2018-09-16 13:35:19 Iter 314500 [Train]: loss=38.43, epe=2.43, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 9:24:54\n",
      "2018-09-16 13:37:08 Iter 314600 [Train]: loss=37.72, epe=2.38, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 9:21:08\n",
      "2018-09-16 13:38:57 Iter 314700 [Train]: loss=37.71, epe=2.38, lr=0.000025, samples/sec=31.0, sec/step=1.031, eta=3 days, 9:41:46\n",
      "2018-09-16 13:40:46 Iter 314800 [Train]: loss=38.14, epe=2.42, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 9:15:17\n",
      "2018-09-16 13:42:35 Iter 314900 [Train]: loss=38.06, epe=2.41, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 9:14:09\n",
      "2018-09-16 13:44:24 Iter 315000 [Train]: loss=36.93, epe=2.33, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 9:21:45\n",
      "2018-09-16 13:44:43 Iter 315000 [Val]: loss=42.31, epe=2.73\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-315000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-315000\n",
      "2018-09-16 13:46:48 Iter 315100 [Train]: loss=37.48, epe=2.37, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 9:22:17\n",
      "2018-09-16 13:48:36 Iter 315200 [Train]: loss=36.98, epe=2.35, lr=0.000025, samples/sec=31.6, sec/step=1.013, eta=3 days, 8:06:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-16 13:50:22 Iter 315300 [Train]: loss=37.59, epe=2.37, lr=0.000025, samples/sec=32.0, sec/step=1.000, eta=3 days, 7:06:10\n",
      "2018-09-16 13:52:10 Iter 315400 [Train]: loss=37.78, epe=2.39, lr=0.000025, samples/sec=31.5, sec/step=1.017, eta=3 days, 8:23:36\n",
      "2018-09-16 13:53:59 Iter 315500 [Train]: loss=37.13, epe=2.35, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 8:47:22\n",
      "2018-09-16 13:55:48 Iter 315600 [Train]: loss=39.32, epe=2.51, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 9:03:26\n",
      "2018-09-16 13:57:37 Iter 315700 [Train]: loss=37.49, epe=2.38, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 9:11:00\n",
      "2018-09-16 13:59:26 Iter 315800 [Train]: loss=38.41, epe=2.44, lr=0.000025, samples/sec=31.2, sec/step=1.024, eta=3 days, 8:51:20\n",
      "2018-09-16 14:01:15 Iter 315900 [Train]: loss=37.57, epe=2.37, lr=0.000025, samples/sec=31.1, sec/step=1.029, eta=3 days, 9:11:02\n",
      "2018-09-16 14:03:04 Iter 316000 [Train]: loss=36.52, epe=2.29, lr=0.000025, samples/sec=31.2, sec/step=1.025, eta=3 days, 8:52:12\n",
      "2018-09-16 14:03:23 Iter 316000 [Val]: loss=42.93, epe=2.78\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-316000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-316000\n",
      "2018-09-16 14:05:28 Iter 316100 [Train]: loss=36.04, epe=2.26, lr=0.000025, samples/sec=31.3, sec/step=1.024, eta=3 days, 8:42:55\n",
      "2018-09-16 14:07:17 Iter 316200 [Train]: loss=37.94, epe=2.39, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 9:00:05\n",
      "2018-09-16 14:09:05 Iter 316300 [Train]: loss=38.01, epe=2.41, lr=0.000025, samples/sec=31.3, sec/step=1.023, eta=3 days, 8:37:09\n",
      "2018-09-16 14:10:54 Iter 316400 [Train]: loss=38.29, epe=2.42, lr=0.000025, samples/sec=31.2, sec/step=1.024, eta=3 days, 8:40:37\n",
      "2018-09-16 14:12:41 Iter 316500 [Train]: loss=37.58, epe=2.37, lr=0.000025, samples/sec=31.8, sec/step=1.006, eta=3 days, 7:15:37\n",
      "2018-09-16 14:14:28 Iter 316600 [Train]: loss=37.13, epe=2.34, lr=0.000025, samples/sec=31.9, sec/step=1.005, eta=3 days, 7:04:55\n",
      "2018-09-16 14:16:15 Iter 316700 [Train]: loss=37.90, epe=2.40, lr=0.000025, samples/sec=31.7, sec/step=1.010, eta=3 days, 7:27:26\n",
      "2018-09-16 14:18:04 Iter 316800 [Train]: loss=37.40, epe=2.37, lr=0.000025, samples/sec=31.4, sec/step=1.019, eta=3 days, 8:11:18\n",
      "2018-09-16 14:19:52 Iter 316900 [Train]: loss=38.50, epe=2.45, lr=0.000025, samples/sec=31.3, sec/step=1.021, eta=3 days, 8:17:48\n",
      "2018-09-16 14:21:41 Iter 317000 [Train]: loss=36.53, epe=2.31, lr=0.000025, samples/sec=31.1, sec/step=1.029, eta=3 days, 8:55:24\n",
      "2018-09-16 14:22:00 Iter 317000 [Val]: loss=42.51, epe=2.76\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-317000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-317000\n",
      "2018-09-16 14:24:07 Iter 317100 [Train]: loss=38.64, epe=2.45, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 8:36:28\n",
      "2018-09-16 14:25:56 Iter 317200 [Train]: loss=39.31, epe=2.51, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 8:52:36\n",
      "2018-09-16 14:27:45 Iter 317300 [Train]: loss=38.09, epe=2.41, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 8:53:07\n",
      "2018-09-16 14:29:35 Iter 317400 [Train]: loss=37.57, epe=2.37, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 8:43:38\n",
      "2018-09-16 14:31:24 Iter 317500 [Train]: loss=36.68, epe=2.30, lr=0.000025, samples/sec=31.1, sec/step=1.027, eta=3 days, 8:37:41\n",
      "2018-09-16 14:33:13 Iter 317600 [Train]: loss=35.86, epe=2.25, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 8:48:44\n",
      "2018-09-16 14:35:02 Iter 317700 [Train]: loss=38.34, epe=2.43, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 8:31:02\n",
      "2018-09-16 14:36:49 Iter 317800 [Train]: loss=35.68, epe=2.23, lr=0.000025, samples/sec=31.9, sec/step=1.004, eta=3 days, 6:42:07\n",
      "2018-09-16 14:38:36 Iter 317900 [Train]: loss=38.02, epe=2.41, lr=0.000025, samples/sec=31.9, sec/step=1.004, eta=3 days, 6:39:39\n",
      "2018-09-16 14:40:24 Iter 318000 [Train]: loss=37.26, epe=2.35, lr=0.000025, samples/sec=31.4, sec/step=1.020, eta=3 days, 7:54:42\n",
      "2018-09-16 14:40:43 Iter 318000 [Val]: loss=43.67, epe=2.85\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-318000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-318000\n",
      "2018-09-16 14:42:43 Iter 318100 [Train]: loss=38.11, epe=2.40, lr=0.000025, samples/sec=32.3, sec/step=0.989, eta=3 days, 5:28:52\n",
      "2018-09-16 14:44:26 Iter 318200 [Train]: loss=37.89, epe=2.39, lr=0.000025, samples/sec=32.2, sec/step=0.995, eta=3 days, 5:53:31\n",
      "2018-09-16 14:46:10 Iter 318300 [Train]: loss=37.52, epe=2.37, lr=0.000025, samples/sec=32.1, sec/step=0.998, eta=3 days, 6:03:52\n",
      "2018-09-16 14:47:54 Iter 318400 [Train]: loss=36.97, epe=2.32, lr=0.000025, samples/sec=32.2, sec/step=0.993, eta=3 days, 5:41:21\n",
      "2018-09-16 14:49:37 Iter 318500 [Train]: loss=37.57, epe=2.38, lr=0.000025, samples/sec=32.2, sec/step=0.993, eta=3 days, 5:40:05\n",
      "2018-09-16 14:51:21 Iter 318600 [Train]: loss=39.57, epe=2.51, lr=0.000025, samples/sec=32.1, sec/step=0.996, eta=3 days, 5:49:48\n",
      "2018-09-16 14:53:04 Iter 318700 [Train]: loss=35.74, epe=2.24, lr=0.000025, samples/sec=32.1, sec/step=0.996, eta=3 days, 5:47:19\n",
      "2018-09-16 14:54:48 Iter 318800 [Train]: loss=39.18, epe=2.51, lr=0.000025, samples/sec=32.0, sec/step=0.998, eta=3 days, 5:59:37\n",
      "2018-09-16 14:56:31 Iter 318900 [Train]: loss=37.83, epe=2.39, lr=0.000025, samples/sec=32.3, sec/step=0.991, eta=3 days, 5:23:27\n",
      "2018-09-16 14:58:15 Iter 319000 [Train]: loss=37.16, epe=2.34, lr=0.000025, samples/sec=32.2, sec/step=0.994, eta=3 days, 5:36:43\n",
      "2018-09-16 14:58:31 Iter 319000 [Val]: loss=40.73, epe=2.60\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-319000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-319000\n",
      "2018-09-16 15:00:29 Iter 319100 [Train]: loss=37.23, epe=2.34, lr=0.000025, samples/sec=33.4, sec/step=0.959, eta=3 days, 2:51:12\n",
      "2018-09-16 15:02:11 Iter 319200 [Train]: loss=36.91, epe=2.33, lr=0.000025, samples/sec=32.9, sec/step=0.972, eta=3 days, 3:51:02\n",
      "2018-09-16 15:03:53 Iter 319300 [Train]: loss=37.95, epe=2.40, lr=0.000025, samples/sec=32.8, sec/step=0.976, eta=3 days, 4:04:29\n",
      "2018-09-16 15:05:36 Iter 319400 [Train]: loss=37.16, epe=2.35, lr=0.000025, samples/sec=32.5, sec/step=0.985, eta=3 days, 4:46:28\n",
      "2018-09-16 15:07:19 Iter 319500 [Train]: loss=37.10, epe=2.34, lr=0.000025, samples/sec=32.3, sec/step=0.989, eta=3 days, 5:05:48\n",
      "2018-09-16 15:09:03 Iter 319600 [Train]: loss=38.01, epe=2.40, lr=0.000025, samples/sec=32.3, sec/step=0.991, eta=3 days, 5:11:32\n",
      "2018-09-16 15:10:47 Iter 319700 [Train]: loss=37.97, epe=2.39, lr=0.000025, samples/sec=32.3, sec/step=0.992, eta=3 days, 5:13:03\n",
      "2018-09-16 15:12:30 Iter 319800 [Train]: loss=36.25, epe=2.27, lr=0.000025, samples/sec=32.4, sec/step=0.988, eta=3 days, 4:53:56\n",
      "2018-09-16 15:14:14 Iter 319900 [Train]: loss=38.54, epe=2.44, lr=0.000025, samples/sec=32.4, sec/step=0.988, eta=3 days, 4:51:47\n",
      "2018-09-16 15:15:57 Iter 320000 [Train]: loss=37.72, epe=2.39, lr=0.000025, samples/sec=32.4, sec/step=0.988, eta=3 days, 4:49:15\n",
      "2018-09-16 15:16:13 Iter 320000 [Val]: loss=41.81, epe=2.70\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-320000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-320000\n",
      "2018-09-16 15:18:18 Iter 320100 [Train]: loss=38.16, epe=2.43, lr=0.000025, samples/sec=31.4, sec/step=1.021, eta=3 days, 7:20:54\n",
      "2018-09-16 15:20:07 Iter 320200 [Train]: loss=38.50, epe=2.44, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 7:45:04\n",
      "2018-09-16 15:21:56 Iter 320300 [Train]: loss=37.59, epe=2.37, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 7:45:36\n",
      "2018-09-16 15:23:43 Iter 320400 [Train]: loss=36.24, epe=2.28, lr=0.000025, samples/sec=32.0, sec/step=1.000, eta=3 days, 5:40:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-16 15:25:30 Iter 320500 [Train]: loss=36.32, epe=2.28, lr=0.000025, samples/sec=31.8, sec/step=1.007, eta=3 days, 6:09:08\n",
      "2018-09-16 15:27:18 Iter 320600 [Train]: loss=37.05, epe=2.33, lr=0.000025, samples/sec=31.4, sec/step=1.018, eta=3 days, 7:02:44\n",
      "2018-09-16 15:29:07 Iter 320700 [Train]: loss=38.51, epe=2.42, lr=0.000025, samples/sec=31.2, sec/step=1.024, eta=3 days, 7:27:50\n",
      "2018-09-16 15:30:56 Iter 320800 [Train]: loss=38.03, epe=2.41, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 7:44:06\n",
      "2018-09-16 15:32:45 Iter 320900 [Train]: loss=36.10, epe=2.26, lr=0.000025, samples/sec=31.0, sec/step=1.031, eta=3 days, 7:57:22\n",
      "2018-09-16 15:34:35 Iter 321000 [Train]: loss=37.46, epe=2.37, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 7:33:32\n",
      "2018-09-16 15:34:53 Iter 321000 [Val]: loss=43.23, epe=2.80\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-321000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-321000\n",
      "2018-09-16 15:36:58 Iter 321100 [Train]: loss=37.17, epe=2.34, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 7:10:12\n",
      "2018-09-16 15:38:47 Iter 321200 [Train]: loss=38.00, epe=2.41, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 7:28:01\n",
      "2018-09-16 15:40:37 Iter 321300 [Train]: loss=36.57, epe=2.31, lr=0.000025, samples/sec=31.0, sec/step=1.032, eta=3 days, 7:52:52\n",
      "2018-09-16 15:42:26 Iter 321400 [Train]: loss=39.20, epe=2.48, lr=0.000025, samples/sec=31.2, sec/step=1.025, eta=3 days, 7:19:21\n",
      "2018-09-16 15:44:14 Iter 321500 [Train]: loss=38.03, epe=2.41, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 7:22:47\n",
      "2018-09-16 15:46:03 Iter 321600 [Train]: loss=37.58, epe=2.37, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 7:18:43\n",
      "2018-09-16 15:47:49 Iter 321700 [Train]: loss=37.20, epe=2.34, lr=0.000025, samples/sec=32.1, sec/step=0.998, eta=3 days, 5:10:04\n",
      "2018-09-16 15:49:36 Iter 321800 [Train]: loss=37.98, epe=2.40, lr=0.000025, samples/sec=31.8, sec/step=1.006, eta=3 days, 5:45:52\n",
      "2018-09-16 15:51:25 Iter 321900 [Train]: loss=36.32, epe=2.28, lr=0.000025, samples/sec=31.4, sec/step=1.018, eta=3 days, 6:38:26\n",
      "2018-09-16 15:53:14 Iter 322000 [Train]: loss=38.61, epe=2.44, lr=0.000025, samples/sec=31.1, sec/step=1.027, eta=3 days, 7:20:30\n",
      "2018-09-16 15:53:32 Iter 322000 [Val]: loss=42.53, epe=2.76\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-322000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-322000\n",
      "2018-09-16 15:55:39 Iter 322100 [Train]: loss=37.67, epe=2.38, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 6:51:36\n",
      "2018-09-16 15:57:28 Iter 322200 [Train]: loss=39.15, epe=2.48, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 7:21:49\n",
      "2018-09-16 15:59:18 Iter 322300 [Train]: loss=36.96, epe=2.32, lr=0.000025, samples/sec=31.0, sec/step=1.032, eta=3 days, 7:37:23\n",
      "2018-09-16 16:01:07 Iter 322400 [Train]: loss=37.33, epe=2.35, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 7:25:50\n",
      "2018-09-16 16:02:56 Iter 322500 [Train]: loss=36.41, epe=2.28, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 7:09:18\n",
      "2018-09-16 16:04:45 Iter 322600 [Train]: loss=38.08, epe=2.41, lr=0.000025, samples/sec=31.2, sec/step=1.025, eta=3 days, 7:00:53\n",
      "2018-09-16 16:06:34 Iter 322700 [Train]: loss=37.12, epe=2.34, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 7:04:49\n",
      "2018-09-16 16:08:23 Iter 322800 [Train]: loss=37.60, epe=2.39, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 7:01:38\n",
      "2018-09-16 16:10:11 Iter 322900 [Train]: loss=37.12, epe=2.35, lr=0.000025, samples/sec=31.4, sec/step=1.020, eta=3 days, 6:31:17\n",
      "2018-09-16 16:11:58 Iter 323000 [Train]: loss=39.42, epe=2.51, lr=0.000025, samples/sec=32.0, sec/step=1.000, eta=3 days, 4:54:36\n",
      "2018-09-16 16:12:17 Iter 323000 [Val]: loss=42.27, epe=2.72\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-323000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-323000\n",
      "2018-09-16 16:14:20 Iter 323100 [Train]: loss=38.19, epe=2.41, lr=0.000025, samples/sec=31.8, sec/step=1.005, eta=3 days, 5:19:40\n",
      "2018-09-16 16:16:09 Iter 323200 [Train]: loss=36.95, epe=2.33, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 6:36:06\n",
      "2018-09-16 16:17:58 Iter 323300 [Train]: loss=37.51, epe=2.36, lr=0.000025, samples/sec=31.3, sec/step=1.024, eta=3 days, 6:40:29\n",
      "2018-09-16 16:19:47 Iter 323400 [Train]: loss=36.58, epe=2.30, lr=0.000025, samples/sec=31.1, sec/step=1.029, eta=3 days, 7:02:50\n",
      "2018-09-16 16:21:36 Iter 323500 [Train]: loss=36.11, epe=2.26, lr=0.000025, samples/sec=31.1, sec/step=1.029, eta=3 days, 7:00:37\n",
      "2018-09-16 16:23:25 Iter 323600 [Train]: loss=37.59, epe=2.38, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 7:04:12\n",
      "2018-09-16 16:25:14 Iter 323700 [Train]: loss=37.81, epe=2.38, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 6:46:34\n",
      "2018-09-16 16:27:03 Iter 323800 [Train]: loss=38.43, epe=2.44, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 6:47:02\n",
      "2018-09-16 16:28:52 Iter 323900 [Train]: loss=36.71, epe=2.31, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 6:45:11\n",
      "2018-09-16 16:30:41 Iter 324000 [Train]: loss=36.86, epe=2.32, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 6:38:03\n",
      "2018-09-16 16:31:00 Iter 324000 [Val]: loss=41.24, epe=2.66\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-324000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-324000\n",
      "2018-09-16 16:33:05 Iter 324100 [Train]: loss=37.89, epe=2.40, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 6:21:08\n",
      "2018-09-16 16:34:53 Iter 324200 [Train]: loss=36.09, epe=2.25, lr=0.000025, samples/sec=31.3, sec/step=1.021, eta=3 days, 6:12:51\n",
      "2018-09-16 16:36:40 Iter 324300 [Train]: loss=37.87, epe=2.40, lr=0.000025, samples/sec=32.1, sec/step=0.997, eta=3 days, 4:22:57\n",
      "2018-09-16 16:38:27 Iter 324400 [Train]: loss=37.96, epe=2.41, lr=0.000025, samples/sec=31.7, sec/step=1.009, eta=3 days, 5:14:01\n",
      "2018-09-16 16:40:15 Iter 324500 [Train]: loss=36.43, epe=2.28, lr=0.000025, samples/sec=31.4, sec/step=1.021, eta=3 days, 6:06:52\n",
      "2018-09-16 16:42:04 Iter 324600 [Train]: loss=37.20, epe=2.35, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 6:09:13\n",
      "2018-09-16 16:43:53 Iter 324700 [Train]: loss=38.41, epe=2.43, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 6:28:01\n",
      "2018-09-16 16:45:43 Iter 324800 [Train]: loss=36.97, epe=2.33, lr=0.000025, samples/sec=30.8, sec/step=1.039, eta=3 days, 7:23:45\n",
      "2018-09-16 16:47:32 Iter 324900 [Train]: loss=37.49, epe=2.37, lr=0.000025, samples/sec=30.9, sec/step=1.035, eta=3 days, 7:05:27\n",
      "2018-09-16 16:49:21 Iter 325000 [Train]: loss=38.17, epe=2.41, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 6:30:56\n",
      "2018-09-16 16:49:40 Iter 325000 [Val]: loss=42.70, epe=2.76\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-325000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-325000\n",
      "2018-09-16 16:51:45 Iter 325100 [Train]: loss=36.54, epe=2.30, lr=0.000025, samples/sec=31.5, sec/step=1.017, eta=3 days, 5:40:58\n",
      "2018-09-16 16:53:34 Iter 325200 [Train]: loss=37.24, epe=2.35, lr=0.000025, samples/sec=31.2, sec/step=1.025, eta=3 days, 6:14:56\n",
      "2018-09-16 16:55:23 Iter 325300 [Train]: loss=38.39, epe=2.43, lr=0.000025, samples/sec=31.0, sec/step=1.031, eta=3 days, 6:40:53\n",
      "2018-09-16 16:57:12 Iter 325400 [Train]: loss=37.75, epe=2.39, lr=0.000025, samples/sec=31.3, sec/step=1.023, eta=3 days, 6:02:13\n",
      "2018-09-16 16:59:00 Iter 325500 [Train]: loss=36.77, epe=2.31, lr=0.000025, samples/sec=31.4, sec/step=1.018, eta=3 days, 5:35:09\n",
      "2018-09-16 17:00:47 Iter 325600 [Train]: loss=37.58, epe=2.37, lr=0.000025, samples/sec=31.9, sec/step=1.003, eta=3 days, 4:25:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-16 17:02:34 Iter 325700 [Train]: loss=38.26, epe=2.43, lr=0.000025, samples/sec=31.6, sec/step=1.012, eta=3 days, 5:07:29\n",
      "2018-09-16 17:04:23 Iter 325800 [Train]: loss=36.34, epe=2.29, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 5:49:21\n",
      "2018-09-16 17:06:12 Iter 325900 [Train]: loss=36.64, epe=2.31, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 6:05:35\n",
      "2018-09-16 17:08:01 Iter 326000 [Train]: loss=37.63, epe=2.38, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 6:14:26\n",
      "2018-09-16 17:08:20 Iter 326000 [Val]: loss=41.50, epe=2.69\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-326000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-326000\n",
      "2018-09-16 17:10:27 Iter 326100 [Train]: loss=36.29, epe=2.28, lr=0.000025, samples/sec=31.3, sec/step=1.022, eta=3 days, 5:47:38\n",
      "2018-09-16 17:12:16 Iter 326200 [Train]: loss=37.15, epe=2.34, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 6:07:03\n",
      "2018-09-16 17:14:05 Iter 326300 [Train]: loss=37.90, epe=2.40, lr=0.000025, samples/sec=31.2, sec/step=1.024, eta=3 days, 5:51:49\n",
      "2018-09-16 17:15:54 Iter 326400 [Train]: loss=36.73, epe=2.31, lr=0.000025, samples/sec=31.0, sec/step=1.031, eta=3 days, 6:20:25\n",
      "2018-09-16 17:17:43 Iter 326500 [Train]: loss=37.55, epe=2.38, lr=0.000025, samples/sec=31.1, sec/step=1.030, eta=3 days, 6:14:19\n",
      "2018-09-16 17:19:32 Iter 326600 [Train]: loss=38.29, epe=2.43, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 6:04:50\n",
      "2018-09-16 17:21:21 Iter 326700 [Train]: loss=38.87, epe=2.46, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 5:55:13\n",
      "2018-09-16 17:23:09 Iter 326800 [Train]: loss=36.72, epe=2.32, lr=0.000025, samples/sec=31.5, sec/step=1.015, eta=3 days, 5:01:06\n",
      "2018-09-16 17:24:56 Iter 326900 [Train]: loss=36.84, epe=2.33, lr=0.000025, samples/sec=31.8, sec/step=1.005, eta=3 days, 4:15:05\n",
      "2018-09-16 17:26:44 Iter 327000 [Train]: loss=37.93, epe=2.40, lr=0.000025, samples/sec=31.6, sec/step=1.012, eta=3 days, 4:44:43\n",
      "2018-09-16 17:27:02 Iter 327000 [Val]: loss=43.99, epe=2.87\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-327000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-327000\n",
      "2018-09-16 17:29:08 Iter 327100 [Train]: loss=37.14, epe=2.35, lr=0.000025, samples/sec=31.4, sec/step=1.018, eta=3 days, 5:11:10\n",
      "2018-09-16 17:30:57 Iter 327200 [Train]: loss=37.77, epe=2.38, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 5:56:11\n",
      "2018-09-16 17:32:46 Iter 327300 [Train]: loss=37.03, epe=2.33, lr=0.000025, samples/sec=31.0, sec/step=1.033, eta=3 days, 6:12:55\n",
      "2018-09-16 17:34:35 Iter 327400 [Train]: loss=37.00, epe=2.34, lr=0.000025, samples/sec=31.2, sec/step=1.027, eta=3 days, 5:47:01\n",
      "2018-09-16 17:36:24 Iter 327500 [Train]: loss=37.17, epe=2.36, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 5:37:46\n",
      "2018-09-16 17:38:14 Iter 327600 [Train]: loss=37.83, epe=2.39, lr=0.000025, samples/sec=31.0, sec/step=1.033, eta=3 days, 6:08:12\n",
      "2018-09-16 17:40:03 Iter 327700 [Train]: loss=37.28, epe=2.35, lr=0.000025, samples/sec=31.1, sec/step=1.028, eta=3 days, 5:43:27\n",
      "2018-09-16 17:41:52 Iter 327800 [Train]: loss=37.38, epe=2.36, lr=0.000025, samples/sec=31.1, sec/step=1.029, eta=3 days, 5:47:04\n",
      "2018-09-16 17:43:41 Iter 327900 [Train]: loss=37.78, epe=2.38, lr=0.000025, samples/sec=31.2, sec/step=1.026, eta=3 days, 5:35:09\n",
      "2018-09-16 17:45:30 Iter 328000 [Train]: loss=36.89, epe=2.33, lr=0.000025, samples/sec=31.2, sec/step=1.024, eta=3 days, 5:24:11\n",
      "2018-09-16 17:45:48 Iter 328000 [Val]: loss=40.46, epe=2.59\n",
      "Saving model...\n",
      "INFO:tensorflow:./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-328000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "... model saved in ./pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-328000\n",
      "2018-09-16 17:47:52 Iter 328100 [Train]: loss=37.82, epe=2.40, lr=0.000025, samples/sec=31.7, sec/step=1.010, eta=3 days, 4:15:52\n",
      "2018-09-16 17:49:40 Iter 328200 [Train]: loss=36.66, epe=2.31, lr=0.000025, samples/sec=31.5, sec/step=1.017, eta=3 days, 4:47:41\n",
      "2018-09-16 17:51:29 Iter 328300 [Train]: loss=37.40, epe=2.37, lr=0.000025, samples/sec=31.4, sec/step=1.018, eta=3 days, 4:51:46\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD: Here are the training curves for the run above:\n",
    "\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/loss.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/epe.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD: Here are the predictions issued by the model for a few validation samples:\n",
    "\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val1.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val2.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val3.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val4.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val5.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val6.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val7.png)\n",
    "![](img/pwcnet-lg-6-2-multisteps-chairsthingsmix/val8.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
